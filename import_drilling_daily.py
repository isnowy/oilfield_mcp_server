"""
å¯¼å…¥é’»äº•å·¥ç¨‹æ—¥æŠ¥æ•°æ®ï¼ˆdrilling_daily.xlsxï¼‰åˆ°PostgreSQLæ•°æ®åº“
"""

import pandas as pd
import psycopg2
from psycopg2 import sql, extras
from pathlib import Path
from datetime import datetime

# æ•°æ®åº“é…ç½®
DB_CONFIG = {
    'host': 'localhost',
    'port': 5432,
    'database': 'rag',
    'user': 'postgres',
    'password': 'postgres'
}

# Excelæ–‡ä»¶è·¯å¾„
EXCEL_FILE = "drilling_daily.xlsx"

# å­—æ®µæ˜ å°„ï¼šExcelåˆ—å -> æ•°æ®åº“å­—æ®µå
COLUMN_MAPPING = {
    'RQ': 'rq',           # æ—¥æœŸ
    'JH': 'jh',           # äº•å·
    'KZRQ': 'kzrq',       # å¼€é’»æ—¥æœŸ
    'DRJS': 'drjs',       # å½“æ—¥äº•æ·±
    'ZJRJC': 'zjrjc',     # æ—¥è¿›å°º
    'ZTLX': 'ztlx',       # é’»å¤´ç±»å‹
    'ZTZJ': 'ztzj',       # é’»å¤´ç›´å¾„
    'ZY': 'zy',           # é’»å‹
    'ZS': 'zs',           # é’»é€Ÿ
    'BYA': 'bya',         # æ³µå‹
    'BPL': 'bpl',         # æ’é‡
    'ZJYMD': 'zjymd',     # é’»äº•æ¶²å¯†åº¦
    'ZJYND': 'zjynd',     # é’»äº•æ¶²ç²˜åº¦
    'CZJLJSJ': 'czjljsj', # çº¯é’»è¿›ç´¯è®¡æ—¶é—´
    'BRZYGZ': 'brzygz',   # æœ¬æ—¥ä¸»è¦å·¥ä½œ
}


def read_excel_data(file_path):
    """è¯»å–Excelæ–‡ä»¶"""
    print(f"ğŸ“„ è¯»å–Excelæ–‡ä»¶: {file_path}")
    
    if not Path(file_path).exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return None
    
    try:
        # ç¬¬2è¡Œï¼ˆç´¢å¼•1ï¼‰ä½œä¸ºè¡¨å¤´
        df = pd.read_excel(file_path, header=1)
        
        # å»é™¤åˆ—åç©ºæ ¼
        df.columns = df.columns.str.strip()
        
        # åˆ é™¤ç¬¬ä¸€åˆ—ï¼ˆå¦‚æœæ˜¯Unnamedï¼‰
        if 'Unnamed: 0' in df.columns:
            df = df.drop(columns=['Unnamed: 0'])
        
        print(f"âœ“ æˆåŠŸè¯»å– {len(df)} è¡Œæ•°æ®")
        print(f"âœ“ åˆ—å: {list(df.columns)}")
        
        return df
        
    except Exception as e:
        print(f"âŒ è¯»å–Excelå¤±è´¥: {e}")
        return None


def clean_and_validate_data(df):
    """æ¸…æ´—å’ŒéªŒè¯æ•°æ®"""
    print("\nğŸ§¹ æ¸…æ´—å’ŒéªŒè¯æ•°æ®...")
    
    original_count = len(df)
    
    # åˆ é™¤äº•å·ä¸ºç©ºçš„è¡Œ
    before_jh = len(df)
    df = df.dropna(subset=['JH'])
    if before_jh != len(df):
        print(f"  - åˆ é™¤äº•å·ä¸ºç©ºçš„è¡Œ: {before_jh - len(df)} è¡Œ")
    
    # åˆ é™¤æ—¥æœŸä¸ºç©ºçš„è¡Œï¼ˆæ—¥æœŸæ˜¯å¿…é¡»çš„ï¼‰
    before_rq = len(df)
    df = df.dropna(subset=['RQ'])
    if before_rq != len(df):
        print(f"  - åˆ é™¤æ—¥æœŸä¸ºç©ºçš„è¡Œ: {before_rq - len(df)} è¡Œ")
    
    # å¤„ç†æ—¥æœŸæ ¼å¼
    try:
        df['RQ'] = pd.to_datetime(df['RQ'], errors='coerce')
        df['KZRQ'] = pd.to_datetime(df['KZRQ'], errors='coerce')
        
        # åˆ é™¤æ—¥æœŸè½¬æ¢å¤±è´¥çš„è¡Œ
        before = len(df)
        df = df.dropna(subset=['RQ'])
        if before != len(df):
            print(f"  - åˆ é™¤æ—¥æœŸæ ¼å¼é”™è¯¯çš„è¡Œ: {before - len(df)} è¡Œ")
        
        # å°†KZRQä¸­çš„NaTè½¬æ¢ä¸ºNoneï¼ˆå…è®¸å¼€é’»æ—¥æœŸä¸ºç©ºï¼‰
        df['KZRQ'] = df['KZRQ'].replace({pd.NaT: None})
        
    except Exception as e:
        print(f"  âš ï¸  æ—¥æœŸå¤„ç†è­¦å‘Š: {e}")
    
    # è½¬æ¢æ•°å€¼å­—æ®µ
    numeric_fields = ['DRJS', 'ZJRJC', 'ZTZJ', 'ZY', 'ZS', 'BYA', 'BPL', 'ZJYMD', 'ZJYND']
    for field in numeric_fields:
        if field in df.columns:
            df[field] = pd.to_numeric(df[field], errors='coerce')
    
    # å¤„ç†CZJLJSJå­—æ®µï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æ•°å€¼ï¼‰
    if 'CZJLJSJ' in df.columns:
        df['CZJLJSJ'] = pd.to_numeric(df['CZJLJSJ'], errors='coerce')
    
    # å°†NaNæ›¿æ¢ä¸ºNone
    df = df.where(pd.notnull(df), None)
    
    print(f"âœ“ æ•°æ®æ¸…æ´—å®Œæˆï¼Œæœ‰æ•ˆæ•°æ®: {len(df)} è¡Œ")
    
    return df


def create_table_if_not_exists(db_config):
    """å¦‚æœè¡¨ä¸å­˜åœ¨åˆ™åˆ›å»º"""
    print("\nğŸ”§ æ£€æŸ¥å¹¶åˆ›å»ºæ•°æ®è¡¨...")
    
    try:
        conn = psycopg2.connect(**db_config)
        cursor = conn.cursor()
        
        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        cursor.execute("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name = 'drilling_daily'
            );
        """)
        
        table_exists = cursor.fetchone()[0]
        
        if not table_exists:
            print("  è¡¨ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")
            
            # è¯»å–å¹¶æ‰§è¡Œå»ºè¡¨SQL
            sql_file = Path(__file__).parent / "drilling_daily_schema.sql"
            if sql_file.exists():
                with open(sql_file, 'r', encoding='utf-8') as f:
                    create_sql = f.read()
                cursor.execute(create_sql)
                conn.commit()
                print("  âœ“ è¡¨åˆ›å»ºæˆåŠŸ")
            else:
                print(f"  âŒ æ‰¾ä¸åˆ°å»ºè¡¨SQLæ–‡ä»¶: {sql_file}")
                return False
        else:
            print("  âœ“ è¡¨å·²å­˜åœ¨")
        
        cursor.close()
        conn.close()
        return True
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥/åˆ›å»ºè¡¨å¤±è´¥: {e}")
        return False


def prepare_insert_data(df):
    """å‡†å¤‡æ’å…¥æ•°æ®åº“çš„æ•°æ®"""
    print("\nğŸ“¦ å‡†å¤‡æ’å…¥æ•°æ®...")
    
    # é‡å‘½ååˆ—ä¸ºæ•°æ®åº“å­—æ®µå
    rename_map = {k: v for k, v in COLUMN_MAPPING.items() if k in df.columns}
    df = df.rename(columns=rename_map)
    
    # åªä¿ç•™æ˜ å°„çš„å­—æ®µ
    db_columns = list(rename_map.values())
    df = df[db_columns]
    
    # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
    data = df.to_dict('records')
    
    print(f"âœ“ å‡†å¤‡ {len(data)} æ¡æ•°æ®å¾…æ’å…¥")
    
    return data, db_columns


def insert_data_to_db(data, columns, db_config):
    """å°†æ•°æ®æ’å…¥æ•°æ®åº“"""
    print("\nğŸ’¾ æ’å…¥æ•°æ®åˆ°æ•°æ®åº“...")
    
    try:
        conn = psycopg2.connect(**db_config)
        cursor = conn.cursor()
        print(f"âœ“ æ•°æ®åº“è¿æ¥æˆåŠŸ")
        
        # æ„å»ºæ’å…¥SQL
        insert_query = sql.SQL("""
            INSERT INTO drilling_daily ({})
            VALUES ({})
        """).format(
            sql.SQL(', ').join(map(sql.Identifier, columns)),
            sql.SQL(', ').join(sql.Placeholder() * len(columns))
        )
        
        # æ‰¹é‡æ’å…¥
        inserted_count = 0
        error_count = 0
        
        for record in data:
            try:
                values = [record.get(col) for col in columns]
                cursor.execute(insert_query, values)
                inserted_count += 1
                
                # æ¯1000æ¡æäº¤ä¸€æ¬¡
                if inserted_count % 1000 == 0:
                    conn.commit()
                    print(f"  è¿›åº¦: {inserted_count}/{len(data)}")
                    
            except Exception as e:
                error_count += 1
                if error_count <= 5:  # åªæ‰“å°å‰5ä¸ªé”™è¯¯
                    print(f"  âš ï¸  æ’å…¥é”™è¯¯: {e} - äº•å·: {record.get('jh', 'N/A')}")
        
        conn.commit()
        
        print(f"âœ“ æˆåŠŸæ’å…¥ {inserted_count} æ¡æ•°æ®")
        if error_count > 0:
            print(f"  âš ï¸  å¤±è´¥ {error_count} æ¡æ•°æ®")
        
        cursor.close()
        conn.close()
        
        return inserted_count
        
    except Exception as e:
        print(f"âŒ æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
        return 0


def check_well_matching(db_config):
    """æ£€æŸ¥äº•å·åŒ¹é…æƒ…å†µ"""
    print("\nğŸ” æ£€æŸ¥äº•å·ä¸oil_wellsè¡¨çš„åŒ¹é…æƒ…å†µ...")
    
    try:
        conn = psycopg2.connect(**db_config)
        cursor = conn.cursor()
        
        # è·å–drilling_dailyä¸­çš„ä¸åŒäº•å·
        cursor.execute("""
            SELECT DISTINCT jh 
            FROM drilling_daily 
            WHERE jh IS NOT NULL
            ORDER BY jh
        """)
        drilling_wells = {row[0] for row in cursor.fetchall()}
        print(f"  âœ“ drilling_dailyè¡¨ä¸­ä¸åŒäº•å·: {len(drilling_wells)} ä¸ª")
        
        # è·å–oil_wellsä¸­çš„well_name
        cursor.execute("""
            SELECT DISTINCT well_name 
            FROM oil_wells 
            WHERE well_name IS NOT NULL
            ORDER BY well_name
        """)
        oil_wells = {row[0] for row in cursor.fetchall()}
        print(f"  âœ“ oil_wellsè¡¨ä¸­ä¸åŒwell_name: {len(oil_wells)} ä¸ª")
        
        # æ‰¾å‡ºåŒ¹é…çš„äº•å·
        matched_wells = drilling_wells.intersection(oil_wells)
        unmatched_wells = drilling_wells - oil_wells
        
        print(f"\n  âœ… åŒ¹é…æˆåŠŸçš„äº•å·: {len(matched_wells)} ä¸ª")
        print(f"  âš ï¸  åŒ¹é…å¤±è´¥çš„äº•å·: {len(unmatched_wells)} ä¸ª")
        
        if unmatched_wells:
            print(f"\n  åŒ¹é…å¤±è´¥çš„äº•å·åˆ—è¡¨ï¼ˆå‰20ä¸ªï¼‰:")
            for well in sorted(list(unmatched_wells))[:20]:
                # ç»Ÿè®¡è¯¥äº•å·çš„è®°å½•æ•°
                cursor.execute("""
                    SELECT COUNT(*) 
                    FROM drilling_daily 
                    WHERE jh = %s
                """, (well,))
                count = cursor.fetchone()[0]
                print(f"    - {well}: {count} æ¡è®°å½•")
            
            if len(unmatched_wells) > 20:
                print(f"    ... è¿˜æœ‰ {len(unmatched_wells) - 20} ä¸ª")
        
        # ç»Ÿè®¡è®°å½•æ•°åŒ¹é…æƒ…å†µ
        cursor.execute("""
            SELECT 
                COUNT(*) as total,
                COUNT(CASE WHEN EXISTS (
                    SELECT 1 FROM oil_wells WHERE oil_wells.well_name = drilling_daily.jh
                ) THEN 1 END) as matched,
                COUNT(CASE WHEN NOT EXISTS (
                    SELECT 1 FROM oil_wells WHERE oil_wells.well_name = drilling_daily.jh
                ) THEN 1 END) as unmatched
            FROM drilling_daily
            WHERE jh IS NOT NULL
        """)
        
        result = cursor.fetchone()
        total, matched_count, unmatched_count = result
        
        print(f"\n  ğŸ“Š è®°å½•åŒ¹é…ç»Ÿè®¡:")
        print(f"    æ€»è®°å½•æ•°: {total:,} æ¡")
        print(f"    åŒ¹é…æˆåŠŸ: {matched_count:,} æ¡ ({matched_count/total*100:.1f}%)")
        print(f"    åŒ¹é…å¤±è´¥: {unmatched_count:,} æ¡ ({unmatched_count/total*100:.1f}%)")
        
        cursor.close()
        conn.close()
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥åŒ¹é…å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("é’»äº•å·¥ç¨‹æ—¥æŠ¥æ•°æ®å¯¼å…¥å·¥å…·")
    print("=" * 70)
    print()
    
    # æ£€æŸ¥Excelæ–‡ä»¶
    if not Path(EXCEL_FILE).exists():
        print(f"âŒ æ‰¾ä¸åˆ°Excelæ–‡ä»¶: {EXCEL_FILE}")
        return False
    
    # åˆ›å»ºè¡¨
    if not create_table_if_not_exists(DB_CONFIG):
        return False
    
    # è¯»å–Excel
    df = read_excel_data(EXCEL_FILE)
    if df is None or len(df) == 0:
        print("âŒ æ²¡æœ‰æ•°æ®å¯å¯¼å…¥")
        return False
    
    # æ¸…æ´—æ•°æ®
    df = clean_and_validate_data(df)
    if len(df) == 0:
        print("âŒ æ¸…æ´—åæ²¡æœ‰æœ‰æ•ˆæ•°æ®")
        return False
    
    # å‡†å¤‡æ•°æ®
    data, columns = prepare_insert_data(df)
    
    # æ’å…¥æ•°æ®
    inserted = insert_data_to_db(data, columns, DB_CONFIG)
    
    # æ£€æŸ¥äº•å·åŒ¹é…
    check_well_matching(DB_CONFIG)
    
    print("\n" + "=" * 70)
    if inserted > 0:
        print(f"âœ… å¯¼å…¥å®Œæˆï¼æˆåŠŸå¯¼å…¥ {inserted} æ¡æ•°æ®")
    else:
        print("âŒ å¯¼å…¥å¤±è´¥")
    print("=" * 70)
    
    return inserted > 0


if __name__ == "__main__":
    import sys
    success = main()
    sys.exit(0 if success else 1)
