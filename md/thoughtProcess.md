æŒ‰ç”¨æˆ·æƒé™æŸ¥è¯¢çš„MCPæ–¹æ¡ˆ
1. æ¨èçš„ MCP å¼€å‘æ¡†æ¶
é’ˆå¯¹ä½ çš„éœ€æ±‚ï¼ˆæ•°æ®æŸ¥è¯¢ã€åç«¯é€»è¾‘ï¼‰ï¼ŒPythonæ˜¯é¦–é€‰ï¼Œå› ä¸ºæ²¹ç”°æ•°æ®åˆ†æã€Pandaså¤„ç†ä»¥åŠä¸ç°æœ‰ä¼ä¸šæ•°æ®åº“çš„è¿æ¥åœ¨ Python?
A. å®˜æ–¹ SDK (æœ€ç¨³å¥)
åç§°ï¼š mcp (Python SDK)
æ¥æºï¼š Anthropic / Model Context Protocol
ç‰¹ç‚¹ï¼šå®˜æ–¹ç»´æŠ¤ï¼Œåº•å±‚æ”¯æŒæœ€å…¨ï¼Œé€‚åˆéœ€è¦æ·±åº¦å®šåˆ¶åè®®ç»†èŠ‚çš„åœºæ™¯ã€‚
é€‚ç”¨ï¼šå¦‚æœä½ éœ€è¦å®Œå…¨æ§åˆ¶ç”Ÿå‘½å‘¨æœŸã€ä¼ è¾“å±‚ï¼ˆSSE/Stdioï¼‰ï¼Œé€‰æ‹©è¿™ä¸ªã€‚

B. FastMCP (å¼€å‘æ•ˆç‡æœ€é«˜-å¼ºçƒˆæ¨è)
åç§°ï¼š fastmcp
ç‰¹ç‚¹ï¼šç±»ä¼¼ FastAPIçš„ä½“éªŒï¼Œé€šè¿‡è£…é¥°å™¨å®šä¹‰å·¥å…·å’Œèµ„æºã€‚å®ƒå°è£…äº†åº•å±‚ç¹ççš„åè®®æ¡æ‰‹ï¼Œè®©ä½ ä¸“æ³¨äºä¸šåŠ¡é€»è¾‘ã€‚
Pythonä¸šåŠ¡é€»è¾‘ã€‚

C. Spring AI (å¦‚æœä½ æ˜¯ Java æŠ€æœ¯æ ˆ)
ç‰¹ç‚¹ï¼šå¦‚æœä½ ä»¬çš„ä¼ä¸šåå°æ˜¯åŸºäº Java/Spring Boot çš„ï¼ŒSpring AI æœ€è¿‘å¢åŠ äº†å¯¹ MCP Spring Security Service

2. ç³»ç»Ÿè®¾è®¡æ¶æ„
åœ¨è®¾è®¡è¿™ä¸ª MCP Server æ—¶ï¼Œæ ¸å¿ƒæŒ‘æˆ˜åœ¨äº**â€œæŒ‰ç”¨æˆ·æƒé™ (RBAC)â€**ã€‚MCPçš„æ‰§è¡Œå±‚ï¼Œè€Œä¸æ˜¯ Prompt

æ ¸å¿ƒè®¾è®¡ä¸‰è¦ç´ 
Resources (èµ„æº - ç”¨äºè¯»å–é™æ€/å®æ—¶ä¸Šä¸‹æ–‡)
  Reference: Resourceã€‚
  URI æ¨¡å¼ï¼š oilfield://wells/{well_id}/realtime
  LLM â€‹Context:
Tools (å·¥å…· - ç”¨äºæ‰§è¡ŒæŸ¥è¯¢)
  SQL Server 2018
  å·¥å…·ç¤ºä¾‹ï¼š
   search_wells_by_region(region_name)
   get_drilling_parameters(well_id, start_time, end_time, params=['rop', 'wob'])(é’»å‹ã€é’»é€Ÿç­‰)
   get_mud_logging_data(well_id, depth_range)
Prompts (æç¤ºè¯æ¨¡æ¿)
é¢„è®¾ä¸€äº›å¸¸ç”¨çš„åˆ†ææ¨¡æ¿ï¼Œä¾‹å¦‚ï¼šâ€œåˆ†æè¯¥äº•æ®µçš„å·¥ç¨‹å¼‚å¸¸â€ã€‚

3. å…³é”®éš¾ç‚¹ï¼šå¦‚ä½•è®¾è®¡â€œæƒé™æ§åˆ¶â€ï¼Ÿ
åœ¨ MCP ä¸­ï¼ŒAI å®¢æˆ·ç«¯ï¼ˆå¦‚ Claude Desktop æˆ– IDEï¼‰è¿æ¥åˆ°ä½ çš„ Serverã€‚é€šå¸¸è¿™æ˜¯ä¸€ä¸ªæœ¬åœ°è¿æ¥æˆ–é€šè¿‡ SSEçš„é•¿è¿æ¥ã€‚

é‰´æƒæ–¹æ¡ˆæ¨èï¼š

æ–¹æ¡ˆ Aï¼šåŸºäºç¯å¢ƒä¸Šä¸‹æ–‡çš„é‰´æƒ (Token Passing)
MCP Server User Manual
MCP Server page: Server page IAM (Identity and Access Management) page
Tool å†…éƒ¨é‰´æƒï¼š
  ä¸è¦åœ¨ Prompt é‡Œå†™â€œè¯·åªæŸ¥è¯¢æˆ‘æœ‰æƒé™çš„æ•°æ®â€ã€‚
  å¿…é¡»åœ¨ Python ä»£ç ä¸­æ‹¦æˆªï¼š
Python
@mcp.tool()
def get_drilling_data(well_id: str, ctx: Context) -> str:
    # 1. è·å–å½“å‰ç”¨æˆ·èº«ä»½ (é€šå¸¸é€šè¿‡ Server åˆå§‹åŒ–æ—¶çš„ Env æˆ– Header ä¼ é€’)
    current_user = ctx.request_context.meta.get("user_id")

    # 2. è°ƒç”¨å†…éƒ¨æƒé™æœåŠ¡æ£€æŸ¥
    if not permission_service.can_access(user_id=current_user, well_id=well_id):
        return "Error: Permission Denied. You do not have access to Well " + well_id

    # 3. æ‰§è¡ŒæŸ¥è¯¢
    return database.query(...)
æ–¹æ¡ˆ Bï¼šè¡Œçº§å®‰å…¨ (Row-Level Security) æ•°æ®åº“å±‚
Download MCP from PostgreSQL to RLS from MCP Serveræˆ·çš„æ•°æ®åº“è´¦å·ï¼ˆæˆ–é€šè¿‡ Sessionæ¨¡æ‹Ÿï¼‰è¿æ¥ï¼Œæ•°æ®æ®è¡Œã€‚

4. FastMCP
Python version

Python

from fastmcp import FastMCP
from pydantic import Field
from typing import List

# åˆå§‹åŒ– MCP Server
mcp = FastMCP("Oilfield Data Server")

# æ¨¡æ‹Ÿçš„æƒé™ç³»ç»Ÿ
def check_permission(user_role: str, well_id: str) -> bool:
    # å®é™…åœºæ™¯ä¸­è¿™é‡Œä¼šè°ƒç”¨ LDAP æˆ– æ•°æ®åº“
    if user_role == "admin":
        return True
    if user_role == "engineer" and well_id.startswith("OPEN_"):
        return True
    return False

# æ¨¡æ‹Ÿæ•°æ®åº“æ•°æ®
MOCK_DATA = {
    "OPEN_001": {"depth": 3500, "rop": 25.5, "status": "Drilling"},
    "SECURE_999": {"depth": 5200, "rop": 12.0, "status": "Casing"},
}

@mcp.tool()
def query_well_status(
    well_id: str = Field(..., description="The unique identifier of the oil well (e.g., OPEN_001)"),
    user_role: str = Field("engineer", description="Current user role context") # å®é™…éƒ¨ç½²æ—¶åº”ç”± System Prompt è‡ªåŠ¨æ³¨å…¥æˆ– Env æ³¨å…¥
) -> str:
    """
    æ ¹æ®äº•å·æŸ¥è¯¢å½“å‰çš„é’»äº•çŠ¶æ€ï¼ˆäº•æ·±ã€é’»é€Ÿã€å·¥å†µï¼‰ã€‚
    """
    
    # 1. æƒé™æ‹¦æˆª
    if not check_permission(user_role, well_id):
        return f"ğŸš« æƒé™æ‹’ç»: ç”¨æˆ· ({user_role}) æ— æƒè®¿é—®äº•å· {well_id} çš„æ•æ„Ÿæ•°æ®ã€‚"

    # 2. æ•°æ®è·å–
    data = MOCK_DATA.get(well_id)
    if not data:
        return f"æœªæ‰¾åˆ°äº•å· {well_id} çš„æ•°æ®ã€‚"

    # 3. è¿”å›ç»“æ„åŒ–æ–‡æœ¬
    return f"""
    === äº•å·: {well_id} ===
    å½“å‰äº•æ·±: {data['depth']} m
    æœºæ¢°é’»é€Ÿ: {data['rop']} m/h
    å½“å‰å·¥å†µ: {data['status']}
    """

if __name__ == "__main__":
    mcp.run()
5. é’ˆå¯¹æ²¹ç”°æ•°æ®çš„æœ€ä½³å®è·µå»ºè®®
å•ä½è½¬æ¢æ ‡å‡†åŒ–ï¼š

AI Toolçš„è¾“å‡ºä¸­ï¼Œå¼ºåˆ¶æ˜ç¡®å•ä½ã€‚ä¸è¦è¿”å›{"depth": 3000},è¦è¿”å›{"depth_meters": 3000}æˆ–åœ¨æè¿°ä¸­å†™æ˜ã€‚

Note:

ä¸è¦ä¸€æ¬¡æ€§è¿”å›æ•°ä¸‡æ¡æµ‹äº•æ›²çº¿æ•°æ®ç»™Windowã€‚

è®¾è®¡å·¥å…·æ”¯æŒ**â€œé™é‡‡æ ·â€æˆ–â€œç»Ÿè®¡ç‰¹å¾â€**ã€‚ä¾‹å¦‚ï¼šget_average_params(interval='1h')ã€‚

æ•°æ®è„±æ•ï¼š

åœ¨ MCP è¾“å‡ºå±‚å¢åŠ ä¸€ä¸ªMiddleware, Middleware

æ€»ç»“
Download FastMCP (Python ) version

User Manual SQL Tool

ä¸èƒ½ä¾èµ– AI çš„è‡ªè§‰æ€§ã€‚

WITSML æ ‡å‡†æˆ–è‡ªå®šä¹‰SQLFastMCP SQLAlchemy Guide
é’»äº•ä¸šåŠ¡æ•°æ®ç¹å¤šï¼Œæˆ‘åº”è¯¥æ€ä¹ˆåœ¨ä¸€ä¸ªMCPæœåŠ¡ä¸Šåˆç†è®¾è®¡å¤šä¸ªTOOLå¹¶æš´éœ²ç»™LLMï¼Ÿ

Drillingâ€‹ â€‹Data: Depth-based technologyä¸­è®¾è®¡ä¸å½“ï¼ˆä¾‹å¦‚æŠŠå‡ ç™¾ä¸ªå­—æ®µæ‹†æˆå‡ ç™¾ä¸ª Toolï¼Œæˆ–è€…æä¸€ä¸ªä¸‡èƒ½ Toolï¼‰ï¼ŒLLMä¼šé™·å…¥é€‰æ‹©å›°éš¾æˆ–ä¸Šä¸‹æ–‡çˆ†ç‚¸ã€‚
å»ºè®®é‡‡ç”¨â€œæŒ‰ä¸šåŠ¡ç»´åº¦åˆ†å±‚ + åŠ¨æ€èšåˆâ€çš„ç­–ç•¥æ¥è®¾è®¡ Toolã€‚ä»¥ä¸‹æ˜¯å…·ä½“çš„æ¶æ„å»ºè®®ï¼š

1. æ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼šä¸‰ä¸ªç»´åº¦
ä¸è¦æŒ‰ç…§æ•°æ®åº“è¡¨ç»“æ„è®¾è®¡Toolï¼Œè¦æŒ‰ç…§å·¥ç¨‹å¸ˆçš„æä¸‰ä¸ªç»´åº¦ï¼š

è¿”å›æ–‡æœ¬/æ‘˜è¦ï¼‰ã€‚

å·¥ç¨‹/æ·±åº¦ç»´åº¦ï¼šåœ°è´¨å¯¼å‘ã€é’»å…·ç»„åˆã€äº•èº«ç»“æ„ï¼ˆè¿”å›ç»“æ„åŒ–å¯¹è±¡ï¼‰ã€‚

Reference : WITS/WITSML (ROP, WOB, Torque)

2. æ¨èçš„ Tool æ¸…å•è®¾è®¡ (ç”±ç²—åˆ°ç»†)
90% çš„åœºæ™¯ã€‚

ç¬¬ä¸€å±‚ï¼šå‘ç°ä¸æ¦‚è§ˆ (Discovery)
Tool 1: search_wells(äº•å·æ£€ç´¢)

ç›®çš„ï¼šLLM é€šå¸¸ä¸çŸ¥é“å‡†ç¡®çš„äº•å·ï¼ˆå¦‚Zhong-102-3ï¼‰ï¼Œéœ€è¦æ¨¡ç³Šæœç´¢ã€‚

å‚æ•°ï¼š

keyword(string): äº•å·å…³é”®å­—æˆ–åŒºå—åã€‚

status(enum): 'Active' (åœ¨é’»), 'Completed' (å®Œäº•), 'All'.

è¿”å›ï¼šäº•å·åˆ—è¡¨ã€äº•å‹ã€å½“å‰äº•æ·±ã€æ‰€å±åŒºå—ã€‚

Tool 2: get_well_summary(å•äº•ç”»åƒ)

ç›®çš„ï¼šè·å–è¯¥äº•çš„â€œèº«ä»½è¯â€ä¿¡æ¯ã€‚

å‚æ•°ï¼šwell_idã€‚

è¿”å›ï¼šè®¾è®¡äº•æ·±ã€å½“å‰äº•æ·±ã€å¼€é’»æ—¥æœŸã€é’»äº•é˜Ÿã€å½“å‰å·¥å†µï¼ˆActivity Codeï¼‰ã€‚

ç¬¬äºŒå±‚ï¼šå·¥ç¨‹ä¸æ—¥æŠ¥ (Engineering & Reporting)
Tool 3: get_daily_report(æ—¥æŠ¥æŸ¥è¯¢ - DDR)

ç›®çš„ï¼šæŸ¥è¯¢æŸå¤©å‘ç”Ÿäº†ä»€ä¹ˆï¼ˆéç»“æ„åŒ–æ•°æ®çš„é‡ç¾åŒºï¼‰ã€‚

å‚æ•°ï¼š

well_id

date(YYYY-MM-DD)

section(enum, optional): 'mud' (æ³¥æµ†), 'bit' (é’»å¤´), 'npt' (éç”Ÿäº§æ—¶é—´), 'remarks' (å¤‡æ³¨).

æŠ€å·§ï¼šå¦‚æœ LLM é—®â€œä¸Šå‘¨æœ‰ä»€ä¹ˆäº‹æ•…â€ï¼Œå®ƒä¼šå¤šæ¬¡è°ƒç”¨æ­¤ Tool Note get_npt_events:

Tool 4: get_bha_config(é’»å…·ç»„åˆ)

ç›®çš„ï¼šBHAï¼‰

å‚æ•°ï¼šwell_id, depth_range(äº•æ®µ).

ç¬¬ä¸‰å±‚ï¼šæ›²çº¿ä¸å‚æ•° (Data Curves - æœ€éš¾ç‚¹)
Tool 5: fetch_drilling_curves(è·å–æ›²çº¿æ•°æ®)

ç—›ç‚¹ï¼šæ•°æ®é‡å¤ªå¤§ã€‚æ•°æ®åº“å¯èƒ½æœ‰ 10 ä¸‡ä¸ªç‚¹ã€‚

Downloaded from www.downsampling.com

å‚æ•°ï¼š

well_id

start_depth/ end_depth(å¯é€‰ï¼Œé»˜è®¤å½“å‰äº•æ®µ)

channels(list): ['ROP', 'WOB', 'Torque', 'RPM', 'Gamma'] (æ”¯æŒç®€å†™).

resolution(string): '1m' (æ¯ç±³ä¸€ä¸ªç‚¹), '10m', 'raw' (åŸå§‹æ•°æ®ï¼Œæ…ç”¨).

è¿”å›ï¼šJSON æ ¼å¼çš„åºåˆ—æ•°æ®ï¼Œé™åˆ¶æœ€å¤§è¿”å›ç‚¹æ•°ï¼ˆå¦‚ 500 ç‚¹ï¼‰ã€‚å¦‚æœè¶…è¿‡ï¼Œæç¤º LLMç¼©å°èŒƒå›´ã€‚

3. å¦‚ä½•è§£å†³â€œæ•°æ®å¤ªå¤šæ’‘çˆ† LLM ä¸Šä¸‹æ–‡â€ï¼Ÿ
ä¸è¦æŠŠåŸå§‹æ•°æ®ä¸¢ç»™ LLM å¤„ç†ã€‚

ç­–ç•¥ Aï¼šå†…ç½®ç»Ÿè®¡åˆ†æ Tool
ROP æ•°æ®è®© LLM ç®—ã€‚
 å¢åŠ Tool :analyze_interval_data
 é€»è¾‘ï¼šServer is SQL SELECT AVG(rop), MAX(torque) ...ã€‚
 è¿”å›ï¼š{"avg_rop": 25.4, "max_torque": 15000}ã€‚ç›´æ¥ç»™ç»“æœã€‚

ç­–ç•¥ Bï¼šåˆ©ç”¨ MCP Resources (èµ„æº)
ä¸è¦åšæˆâ€‹Toolï¼Œè¦åšæˆMCP Resourcesã€‚
 URI :oilfield://wells/{id}/geology_plan
 ç”¨æ³•ï¼šç”¨æˆ·åœ¨ Prompt ä¸­å¯ä»¥å¼•ç”¨è¿™äº›èµ„æºï¼ŒLLMè¯»å–ä¸€æ¬¡åä½œä¸ºèƒŒæ™¯çŸ¥è¯†ï¼Œä¸éœ€è¦åå¤è°ƒç”¨å·¥å…·æŸ¥è¯¢ã€‚
4. ç¤ºä¾‹ï¼šSchema å®šä¹‰ (FastMCP å†™æ³•)
from fastmcp import FastMCP
from pydantic import Field
from typing import List, Literal

mcp = FastMCP("DrillingDataService")

@mcp.tool()
def fetch_drilling_curves(
    well_id: str,
    channels: List[str] = Field(..., description="List of mnemonics to fetch. E.g. ['ROP', 'GR', 'HKLD']"),
    start_depth: float = Field(0.0, description="Start depth in meters"),
    end_depth: float = Field(..., description="End depth in meters"),
    step: int = Field(1, description="Resample step in meters. Increase this if range is large.")
):
    """
    Retrieve depth-based drilling log data. 
    IMPORTANT: Always specify a 'step' >= 10 if querying more than 1000m interval 
    to avoid context overflow.
    """
    # 1. æ ¡éªŒ channels æ˜¯å¦æœ‰æ•ˆ
    # 2. æ ¡éªŒ (end_depth - start_depth) / step æ˜¯å¦ > 2000 ç‚¹
    #    å¦‚æœå¤ªå¤§ï¼Œè‡ªåŠ¨è°ƒå¤§ step å¹¶è­¦å‘Šï¼Œæˆ–è€…è¿”å› Error æç¤º "Range too large, please increase step"
    # 3. SQL æŸ¥è¯¢å¹¶è¿”å› JSON
    pass

5. ç»™ LLM çš„â€œç³»ç»Ÿæç¤ºè¯â€ (System Prompt) é…åˆ
MCP Software Tool Softwareç«¯é…ç½®å¦‚ä¸‹ System Promptï¼š

"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é’»äº•æ•°æ®åŠ©æ‰‹ã€‚

å…ˆä½¿ç”¨search_wellsç¡®è®¤äº•å·ã€‚

æ•°æ®èŠ‚çº¦ï¼šæŸ¥è¯¢æ›²çº¿æ•°æ® ( fetch_drilling_curves)ä»¥step=10é¿å…æ•°æ®é‡è¿‡å¤§ã€‚

å•ä½ï¼šé»˜è®¤æ‰€æœ‰æ·±åº¦ä¸ºç±³ (m)ï¼Œå‹åŠ›ä¸º MPaï¼Œé™¤éç”¨æˆ·ç‰¹åˆ«æŒ‡å®šè‹±åˆ¶ã€‚"

æ€»ç»“è®¾è®¡æ€è·¯
1.å°‘å³æ˜¯å¤šï¼šæŠŠ Tool åˆå¹¶ï¼Œé€šè¿‡å‚æ•°ï¼ˆType/Categoryï¼‰
2.è®¡ç®—ä¸‹æ²‰ï¼šæŠŠâ€œæ±‚å¹³å‡â€ã€â€œæ‰¾æœ€å¤§å€¼â€ã€â€œç»Ÿè®¡è¿›å°ºâ€ç­‰é€»è¾‘å†™åœ¨ Tool å†…éƒ¨ï¼ˆSQL/Pandasï¼‰ï¼Œåªç»™ LLMè¿”å›ç»Ÿè®¡ç»“æœã€‚
3.é˜²å¾¡æ€§ç¼–ç¨‹ï¼šåœ¨ Tool ä¸€æ¬¡æ€§ç´¢è¦æ•´å£äº•çš„æ•°æ®å¯¼è‡´ Crashã€‚

ä¸ºäº†è¾¾åˆ°â€œç”Ÿäº§éƒ¨ç½²çº§â€çš„æ ‡å‡†ï¼Œæˆ‘åœ¨ä»£ç ä¸­å¢åŠ äº†ä»¥ä¸‹å…³é”®ç‰¹æ€§ï¼š
1.Pydantic School of Medicine LLM School of Medicine
2.é”™è¯¯å¤„ç† (Error Handling)ï¼Œè¿”å›å‹å¥½çš„é”™è¯¯æç¤ºï¼Œè€Œä¸æ˜¯è®© Server å´©æºƒã€‚
3.æ¨¡æ‹Ÿæ•°æ®åº“å±‚ (Mock DB Layer)ï¼šä½ åªéœ€åœ¨RealDatabaseç±»ä¸­å¡«å…¥ SQLæŸ¥è¯¢å³å¯æ— ç¼æ›¿æ¢ã€‚
4.Download Docstring : MCP:

1. ä¾èµ–å®‰è£…
pip install fastmcp pydantic
2. å®Œæ•´Python ä»£ç  ( oilfield_mcp.py)
from fastmcp import FastMCP
from pydantic import Field
from typing import List, Optional, Dict, Literal
from datetime import datetime

# ==========================================
# 1. æœåŠ¡åˆå§‹åŒ–
# ==========================================
mcp = FastMCP(
    "Oilfield Drilling Intel",
    description="ä¸“é—¨ç”¨äºæŸ¥è¯¢æ²¹ç”°é’»äº•æ•°æ®ã€æ—¥æŠ¥(DDR)åŠå·¥ç¨‹å‚æ•°çš„ MCP æœåŠ¡ã€‚",
    dependencies=["pandas", "sqlalchemy"] # å£°æ˜ä¾èµ–ï¼ˆä»…ä½œå…ƒæ•°æ®ï¼‰
)

# ==========================================
# 2. æ¨¡æ‹Ÿæ•°æ®å±‚ (ç”Ÿäº§ç¯å¢ƒè¯·æ›¿æ¢ä¸º SQL)
# ==========================================
class DatabaseService:
    """
    æ•°æ®è®¿é—®å±‚ (DAO)ã€‚
    åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œè¯·å°†è¿™é‡Œçš„å­—å…¸æŸ¥æ‰¾æ›¿æ¢ä¸º SQLAlchemy æˆ– SQL æŸ¥è¯¢ã€‚
    """
    def __init__(self):
        # æ¨¡æ‹Ÿäº•åŸºæœ¬ä¿¡æ¯è¡¨
        self.wells = {
            "ZT-102": {"id": "ZT-102", "name": "Zhong-102", "block": "Block A", "status": "Active", "type": "Horizontal", "current_depth": 3550.0, "design_depth": 4200.0, "spud_date": "2023-10-01", "team": "Team-701", "activity": "Drilling 8.5 inch section"},
            "ZT-105": {"id": "ZT-105", "name": "Zhong-105", "block": "Block A", "status": "Completed", "type": "Vertical", "current_depth": 3800.0, "design_depth": 3800.0, "spud_date": "2023-08-15", "team": "Team-702", "activity": "Rig Release"},
            "XJ-009": {"id": "XJ-009",  "name": "XinJiang-009", "block": "Block B", "status": "Active", "type": "Directional", "current_depth": 1200.0, "design_depth": 5000.0, "spud_date": "2023-11-20", "team": "Team-905", "activity": "Tripping out"},
        }
        
        # æ¨¡æ‹Ÿæ—¥æŠ¥è¡¨ (DDR)
        self.reports = {
            "ZT-102_2023-11-01": {
                "mud": "MW: 1.25 sg, Vis: 65s, PV/YP: 15/12. No losses observed.",
                "bit": "Bit #4, Type: PDC, Size: 8.5in. Grading: 1-1-WT-A-X-I-NO-TD.",
                "npt": "None. 24hrs productive time.",
                "remarks": "Drilling ahead smoothly. Formation change expected at 3600m."
            },
            "ZT-102_2023-11-02": {
                "mud": "MW: 1.28 sg. Increased density due to gas reading.",
                "bit": "Bit #4 continuing.",
                "npt": "2.5 hrs. Repairing top drive hydraulic hose.",
                "remarks": "Encountered high torque spikes around 04:00."
            }
        }

        # æ¨¡æ‹Ÿ BHA è¡¨
        self.bha_configs = {
            "ZT-102": [
                {"run": 1, "top_depth": 0, "bottom_depth": 1000, "components": ["Bit 17.5", "Motor 9.625", "MWD"]},
                {"run": 2, "top_depth": 1000, "bottom_depth": 3000, "components": ["Bit 12.25", "RSS", "LWD-GR-Res", "NMDC"]},
                {"run": 3, "top_depth": 3000, "bottom_depth": 4200, "components": ["Bit 8.5", "Motor", "MWD", "Stab"]}
            ]
        }

    def search_wells(self, keyword: str, status: str) -> List[Dict]:
        results = []
        for w in self.wells.values():
            # ç®€å•çš„åŒ…å«é€»è¾‘
            match_key = (keyword.lower() in w['name'].lower() or keyword.lower() in w['block'].lower())
            match_status = (status == "All" or w['status'] == status)
            if match_key and match_status:
                results.append(w)
        return results

    def get_well(self, well_id: str) -> Optional[Dict]:
        return self.wells.get(well_id)

    def get_report(self, well_id: str, date_str: str) -> Optional[Dict]:
        key = f"{well_id}_{date_str}"
        return self.reports.get(key)
    
    def get_bha(self, well_id: str) -> List[Dict]:
        return self.bha_configs.get(well_id, [])

# å®ä¾‹åŒ– DB æœåŠ¡
db = DatabaseService()

# ==========================================
# 3. Tool å®šä¹‰ (Layer 1: Discovery)
# ==========================================

@mcp.tool()
def search_wells(
    keyword: str = Field(..., description="Keywords for search, such as well name (e.g., 'ZT') or block name."),
    status: Literal["Active", "Completed", "All"] = Field("Active", description="Filter by well status. Defaults to 'Active'.")
) -> str:
    """
    Search for oil wells based on vague keywords. 
    Use this when the user does not provide a precise Well ID.
    """
    results = db.search_wells(keyword, status)
    
    if not results:
        return f"No wells found matching keyword '{keyword}' with status '{status}'."

    # æ ¼å¼åŒ–è¾“å‡ºä¸º Markdown è¡¨æ ¼ï¼Œæ–¹ä¾¿ LLM é˜…è¯»
    output = f"Found {len(results)} wells:\n\n"
    output += "| Well ID | Name | Block | Status | Current Depth |\n"
    output += "|---|---|---|---|---|\n"
    for r in results:
        output += f"| {r['id']} | {r['name']} | {r['block']} | {r['status']} | {r['current_depth']}m |\n"
    
    return output

@mcp.tool()
def get_well_summary(
    well_id: str = Field(..., description="The unique identifier of the well (e.g., 'ZT-102')")
) -> str:
    """
    Get the 'ID Card' or comprehensive summary of a specific well.
    Includes spud date, contractor, and current activity code.
    """
    well = db.get_well(well_id)
    if not well:
        return f"Error: Well ID '{well_id}' not found in database."

    return f"""
### Well Summary: {well['name']} ({well['id']})
- **Block**: {well['block']}
- **Status**: {well['status']}
- **Type**: {well['type']}
- **Current Depth**: {well['current_depth']} m
- **Design Depth**: {well['design_depth']} m
- **Spud Date**: {well['spud_date']}
- **Drilling Team**: {well['team']}
- **Current Activity**: {well['activity']}
    """

# ==========================================
# 4. Tool å®šä¹‰ (Layer 2: Engineering)
# ==========================================

@mcp.tool()
def get_daily_report(
    well_id: str = Field(..., description="Well ID"),
    date: str = Field(..., description="Report date in YYYY-MM-DD format"),
    section: Optional[Literal["mud", "bit", "npt", "remarks"]] = Field(None, description="Specific section to extract. If None, returns full report.")
) -> str:
    """
    Retrieve the Daily Drilling Report (DDR) text. 
    Use this to analyze events, accidents, or specifications for a specific day.
    """
    # ç®€å•çš„æ—¥æœŸæ ¼å¼æ ¡éªŒ
    try:
        datetime.strptime(date, "%Y-%m-%d")
    except ValueError:
        return "Error: Date must be in YYYY-MM-DD format."

    report = db.get_report(well_id, date)
    
    if not report:
        return f"No report found for well {well_id} on {date}."

    if section:
        # åªè¿”å›ç‰¹å®šéƒ¨åˆ†ï¼ŒèŠ‚çœ Token
        content = report.get(section, "N/A")
        return f"### DDR {section.upper()} ({date})\n{content}"
    else:
        # è¿”å›å…¨é‡
        return f"""
### Daily Report for {well_id} on {date}
- **Mud**: {report['mud']}
- **Bit**: {report['bit']}
- **NPT**: {report['npt']}
- **Remarks**: {report['remarks']}
        """

@mcp.tool()
def get_bha_config(
    well_id: str = Field(..., description="Well ID"),
    depth_range: str = Field(..., description="Depth range of interest, e.g., '2000-3000' or 'bottom'.")
) -> str:
    """
    Get Bottom Hole Assembly (BHA) configuration. 
    Shows what tools (Bit, Motor, MWD) were used in a specific depth interval.
    """
    bha_list = db.get_bha(well_id)
    if not bha_list:
        return f"No BHA records found for {well_id}."

    # è§£æè¯·æ±‚çš„æ·±åº¦èŒƒå›´ (ç®€å•é€»è¾‘)
    target_top = 0.0
    target_bottom = 99999.0
    
    if "-" in depth_range:
        try:
            parts = depth_range.split("-")
            target_top = float(parts[0])
            target_bottom = float(parts[1])
        except:
            return "Error: depth_range format should be 'start-end' (e.g. 2000-3000)."
    
    # ç­›é€‰é€»è¾‘ï¼šæŸ¥æ‰¾ä¸è¯·æ±‚åŒºé—´æœ‰é‡å çš„ BHA Run
    matched_runs = []
    for run in bha_list:
        # åˆ¤æ–­åŒºé—´é‡å  logic: max(start1, start2) < min(end1, end2)
        overlap_start = max(target_top, run['top_depth'])
        overlap_end = min(target_bottom, run['bottom_depth'])
        
        if overlap_start < overlap_end:
            matched_runs.append(run)

    if not matched_runs:
        return f"No BHA found overlapping depth {depth_range}."

    output = f"### BHA Configuration ({depth_range} m)\n"
    for run in matched_runs:
        components_str = " -> ".join(run['components'])
        output += f"- **Run #{run['run']}** ({run['top_depth']}-{run['bottom_depth']}m): {components_str}\n"
    
    return output

# ==========================================
# 5. å¯åŠ¨å…¥å£
# ==========================================
if __name__ == "__main__":
    # è¿è¡Œ MCP Server
    # å¼€å‘æ¨¡å¼ä¸‹å¯ä»¥ä½¿ç”¨ stdioï¼Œæˆ–è€… SSE
    print("Starting Oilfield Drilling Data MCP Server...")
    mcp.run()


è¿™æ˜¯ä¸€ä¸ªå¯ä»¥ç›´å®ç°æ–¹æ¡ˆã€‚

ä¸ºäº†è¾¾åˆ°â€œç”Ÿäº§éƒ¨ç½²çº§â€çš„æ ‡å‡†ï¼Œæˆ‘åœ¨ä»£ç ä¸­å¢åŠ äº†ä»¥ä¸‹å…³é”®ç‰¹æ€§ï¼š

Pydantic School of Medicine LLM School of Medicine

é”™è¯¯å¤„ç† (Error Handling)ï¼Œè¿”å›å‹å¥½çš„é”™è¯¯æç¤ºï¼Œè€Œä¸æ˜¯è®© Server å´©æºƒã€‚

æ¨¡æ‹Ÿæ•°æ®åº“å±‚ (Mock DB Layer)ï¼šä½ åªéœ€åœ¨RealDatabaseç±»ä¸­å¡«å…¥ SQLæŸ¥è¯¢å³å¯æ— ç¼æ›¿æ¢ã€‚

Download Docstring : MCP:

1. ä¾èµ–å®‰è£…
Bash

pip install fastmcp pydantic
2. å®Œæ•´Python ä»£ç  ( oilfield_mcp.py)
Python

from fastmcp import FastMCP
from pydantic import Field
from typing import List, Optional, Dict, Literal
from datetime import datetime

# ==========================================
# 1. æœåŠ¡åˆå§‹åŒ–
# ==========================================
mcp = FastMCP(
    "Oilfield Drilling Intel",
    description="ä¸“é—¨ç”¨äºæŸ¥è¯¢æ²¹ç”°é’»äº•æ•°æ®ã€æ—¥æŠ¥(DDR)åŠå·¥ç¨‹å‚æ•°çš„ MCP æœåŠ¡ã€‚",
    dependencies=["pandas", "sqlalchemy"] # å£°æ˜ä¾èµ–ï¼ˆä»…ä½œå…ƒæ•°æ®ï¼‰
)

# ==========================================
# 2. æ¨¡æ‹Ÿæ•°æ®å±‚ (ç”Ÿäº§ç¯å¢ƒè¯·æ›¿æ¢ä¸º SQL)
# ==========================================
class DatabaseService:
    """
    æ•°æ®è®¿é—®å±‚ (DAO)ã€‚
    åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œè¯·å°†è¿™é‡Œçš„å­—å…¸æŸ¥æ‰¾æ›¿æ¢ä¸º SQLAlchemy æˆ– SQL æŸ¥è¯¢ã€‚
    """
    def __init__(self):
        # æ¨¡æ‹Ÿäº•åŸºæœ¬ä¿¡æ¯è¡¨
        self.wells = {
            "ZT-102": {"id": "ZT-102", "name": "Zhong-102", "block": "Block A", "status": "Active", "type": "Horizontal", "current_depth": 3550.0, "design_depth": 4200.0, "spud_date": "2023-10-01", "team": "Team-701", "activity": "Drilling 8.5 inch section"},
            "ZT-105": {"id": "ZT-105", "name": "Zhong-105", "block": "Block A", "status": "Completed", "type": "Vertical", "current_depth": 3800.0, "design_depth": 3800.0, "spud_date": "2023-08-15", "team": "Team-702", "activity": "Rig Release"},
            "XJ-009": {"id": "XJ-009",  "name": "XinJiang-009", "block": "Block B", "status": "Active", "type": "Directional", "current_depth": 1200.0, "design_depth": 5000.0, "spud_date": "2023-11-20", "team": "Team-905", "activity": "Tripping out"},
        }
        
        # æ¨¡æ‹Ÿæ—¥æŠ¥è¡¨ (DDR)
        self.reports = {
            "ZT-102_2023-11-01": {
                "mud": "MW: 1.25 sg, Vis: 65s, PV/YP: 15/12. No losses observed.",
                "bit": "Bit #4, Type: PDC, Size: 8.5in. Grading: 1-1-WT-A-X-I-NO-TD.",
                "npt": "None. 24hrs productive time.",
                "remarks": "Drilling ahead smoothly. Formation change expected at 3600m."
            },
            "ZT-102_2023-11-02": {
                "mud": "MW: 1.28 sg. Increased density due to gas reading.",
                "bit": "Bit #4 continuing.",
                "npt": "2.5 hrs. Repairing top drive hydraulic hose.",
                "remarks": "Encountered high torque spikes around 04:00."
            }
        }

        # æ¨¡æ‹Ÿ BHA è¡¨
        self.bha_configs = {
            "ZT-102": [
                {"run": 1, "top_depth": 0, "bottom_depth": 1000, "components": ["Bit 17.5", "Motor 9.625", "MWD"]},
                {"run": 2, "top_depth": 1000, "bottom_depth": 3000, "components": ["Bit 12.25", "RSS", "LWD-GR-Res", "NMDC"]},
                {"run": 3, "top_depth": 3000, "bottom_depth": 4200, "components": ["Bit 8.5", "Motor", "MWD", "Stab"]}
            ]
        }

    def search_wells(self, keyword: str, status: str) -> List[Dict]:
        results = []
        for w in self.wells.values():
            # ç®€å•çš„åŒ…å«é€»è¾‘
            match_key = (keyword.lower() in w['name'].lower() or keyword.lower() in w['block'].lower())
            match_status = (status == "All" or w['status'] == status)
            if match_key and match_status:
                results.append(w)
        return results

    def get_well(self, well_id: str) -> Optional[Dict]:
        return self.wells.get(well_id)

    def get_report(self, well_id: str, date_str: str) -> Optional[Dict]:
        key = f"{well_id}_{date_str}"
        return self.reports.get(key)
    
    def get_bha(self, well_id: str) -> List[Dict]:
        return self.bha_configs.get(well_id, [])

# å®ä¾‹åŒ– DB æœåŠ¡
db = DatabaseService()

# ==========================================
# 3. Tool å®šä¹‰ (Layer 1: Discovery)
# ==========================================

@mcp.tool()
def search_wells(
    keyword: str = Field(..., description="Keywords for search, such as well name (e.g., 'ZT') or block name."),
    status: Literal["Active", "Completed", "All"] = Field("Active", description="Filter by well status. Defaults to 'Active'.")
) -> str:
    """
    Search for oil wells based on vague keywords. 
    Use this when the user does not provide a precise Well ID.
    """
    results = db.search_wells(keyword, status)
    
    if not results:
        return f"No wells found matching keyword '{keyword}' with status '{status}'."

    # æ ¼å¼åŒ–è¾“å‡ºä¸º Markdown è¡¨æ ¼ï¼Œæ–¹ä¾¿ LLM é˜…è¯»
    output = f"Found {len(results)} wells:\n\n"
    output += "| Well ID | Name | Block | Status | Current Depth |\n"
    output += "|---|---|---|---|---|\n"
    for r in results:
        output += f"| {r['id']} | {r['name']} | {r['block']} | {r['status']} | {r['current_depth']}m |\n"
    
    return output

@mcp.tool()
def get_well_summary(
    well_id: str = Field(..., description="The unique identifier of the well (e.g., 'ZT-102')")
) -> str:
    """
    Get the 'ID Card' or comprehensive summary of a specific well.
    Includes spud date, contractor, and current activity code.
    """
    well = db.get_well(well_id)
    if not well:
        return f"Error: Well ID '{well_id}' not found in database."

    return f"""
### Well Summary: {well['name']} ({well['id']})
- **Block**: {well['block']}
- **Status**: {well['status']}
- **Type**: {well['type']}
- **Current Depth**: {well['current_depth']} m
- **Design Depth**: {well['design_depth']} m
- **Spud Date**: {well['spud_date']}
- **Drilling Team**: {well['team']}
- **Current Activity**: {well['activity']}
    """

# ==========================================
# 4. Tool å®šä¹‰ (Layer 2: Engineering)
# ==========================================

@mcp.tool()
def get_daily_report(
    well_id: str = Field(..., description="Well ID"),
    date: str = Field(..., description="Report date in YYYY-MM-DD format"),
    section: Optional[Literal["mud", "bit", "npt", "remarks"]] = Field(None, description="Specific section to extract. If None, returns full report.")
) -> str:
    """
    Retrieve the Daily Drilling Report (DDR) text. 
    Use this to analyze events, accidents, or specifications for a specific day.
    """
    # ç®€å•çš„æ—¥æœŸæ ¼å¼æ ¡éªŒ
    try:
        datetime.strptime(date, "%Y-%m-%d")
    except ValueError:
        return "Error: Date must be in YYYY-MM-DD format."

    report = db.get_report(well_id, date)
    
    if not report:
        return f"No report found for well {well_id} on {date}."

    if section:
        # åªè¿”å›ç‰¹å®šéƒ¨åˆ†ï¼ŒèŠ‚çœ Token
        content = report.get(section, "N/A")
        return f"### DDR {section.upper()} ({date})\n{content}"
    else:
        # è¿”å›å…¨é‡
        return f"""
### Daily Report for {well_id} on {date}
- **Mud**: {report['mud']}
- **Bit**: {report['bit']}
- **NPT**: {report['npt']}
- **Remarks**: {report['remarks']}
        """

@mcp.tool()
def get_bha_config(
    well_id: str = Field(..., description="Well ID"),
    depth_range: str = Field(..., description="Depth range of interest, e.g., '2000-3000' or 'bottom'.")
) -> str:
    """
    Get Bottom Hole Assembly (BHA) configuration. 
    Shows what tools (Bit, Motor, MWD) were used in a specific depth interval.
    """
    bha_list = db.get_bha(well_id)
    if not bha_list:
        return f"No BHA records found for {well_id}."

    # è§£æè¯·æ±‚çš„æ·±åº¦èŒƒå›´ (ç®€å•é€»è¾‘)
    target_top = 0.0
    target_bottom = 99999.0
    
    if "-" in depth_range:
        try:
            parts = depth_range.split("-")
            target_top = float(parts[0])
            target_bottom = float(parts[1])
        except:
            return "Error: depth_range format should be 'start-end' (e.g. 2000-3000)."
    
    # ç­›é€‰é€»è¾‘ï¼šæŸ¥æ‰¾ä¸è¯·æ±‚åŒºé—´æœ‰é‡å çš„ BHA Run
    matched_runs = []
    for run in bha_list:
        # åˆ¤æ–­åŒºé—´é‡å  logic: max(start1, start2) < min(end1, end2)
        overlap_start = max(target_top, run['top_depth'])
        overlap_end = min(target_bottom, run['bottom_depth'])
        
        if overlap_start < overlap_end:
            matched_runs.append(run)

    if not matched_runs:
        return f"No BHA found overlapping depth {depth_range}."

    output = f"### BHA Configuration ({depth_range} m)\n"
    for run in matched_runs:
        components_str = " -> ".join(run['components'])
        output += f"- **Run #{run['run']}** ({run['top_depth']}-{run['bottom_depth']}m): {components_str}\n"
    
    return output

# ==========================================
# 5. å¯åŠ¨å…¥å£
# ==========================================
if __name__ == "__main__":
    # è¿è¡Œ MCP Server
    # å¼€å‘æ¨¡å¼ä¸‹å¯ä»¥ä½¿ç”¨ stdioï¼Œæˆ–è€… SSE
    print("Starting Oilfield Drilling Data MCP Server...")
    mcp.run() 


3. ä»£ç è®¾è®¡è§£è¯»ä¸éƒ¨ç½²å»ºè®®
A. ä¸ºä»€ä¹ˆç”¨fastmcp+ pydantic?
 Promptfastmcp Python Type DocstringHints LLM JSON Schema
    LLMget_daily_reportâ€‹sectionâ€‹Literalâ€‹
 Python version of Markdown
    åŸå› ï¼šJSON è™½ç„¶ç²¾ç¡®ï¼Œä½† Token æ¶ˆè€—å¤§ä¸”é˜…è¯»æ€§å·®ã€‚Markdown è¡¨æ ¼ï¼ˆå¦‚search_wellsçš„è¿”å›ï¼‰å¯¹äº Claude Token token
B. ç”Ÿäº§ç¯å¢ƒå¦‚ä½•å¯¹æ¥åº“ï¼Ÿ
DatabaseServiceOracle æˆ– PostgreSQL ä¸­ã€‚

SQLAlchemy æ”¹é€ ç¤ºä¾‹ï¼š
# æ›¿æ¢ DatabaseService.search_wells æ–¹æ³•
def search_wells(self, keyword: str, status: str) -> List[Dict]:
    with self.session_scope() as session:
        query = session.query(WellModel).filter(
            WellModel.name.ilike(f"%{keyword}%")
        )
        if status != "All":
            query = query.filter(WellModel.status == status)
        
        results = query.all()
        # è½¬æ¢ä¸º Dict è¿”å›
        return [row.to_dict() for row in results]
		
C.ä½ å¯ä»¥ä½¿ç”¨mcpå®˜æ–¹æä¾›çš„ Inspector,
# åœ¨ç»ˆç«¯ä¸­è¿è¡Œ inspector è¿›è¡Œäº¤äº’å¼è°ƒè¯•
npx @modelcontextprotocol/inspector python oilfield_mcp.py

åœ¨ Inspector ç•Œé¢ä¸­ï¼Œä½ å¯ä»¥æ¨¡æ‹Ÿ LLM å‘é€è¯·æ±‚ï¼š
Call Tool : search_wells-> Arguments:{"keyword": "ZT", "status": "All"}
Call Tool : get_daily_report-> Arguments:{"well_id": "ZT-102", "date": "2023-11-01", "section": "npt"}
Copilot çš„åç«¯æ ¸å¿ƒã€‚


é—®ï¼šæä¾›æ›´è¯¦ç»†çš„ä»£ç å®ç°ï¼ŒåŒ…å«æ•´ä¸ªè°ƒç”¨è¿‡ç¨‹çš„çŠ¶æ€è·Ÿè¸ª
â€œ State Tracking & Auditingâ€ MCP å®ç°ã€‚

åœ¨ä¼ä¸šçº§åº”ç”¨ä¸­ï¼Œå•çº¯çš„â€œè°ƒç”¨å·¥å…·â€æ˜¯ä¸å¤Ÿçš„ã€‚æˆ‘ä»¬éœ€è¦çŸ¥é“ï¼š

Who & When : è°åœ¨ä»€ä¹ˆæ—¶é—´è°ƒç”¨äº†å·¥å…·ï¼Ÿ

Input/Output : ä¼ å…¥äº†ä»€ä¹ˆå‚æ•°ï¼Ÿè¿”å›äº†ä»€ä¹ˆç»“æœï¼Ÿ

Performance : æŸ¥è¯¢è€—æ—¶å¤šä¹…ï¼Ÿï¼ˆç”¨äºä¼˜åŒ–æ…¢æŸ¥è¯¢ï¼‰

Error Trace : å¦‚æœæŠ¥é”™ï¼Œå †æ ˆæ˜¯ä»€ä¹ˆï¼Ÿ

Python çš„è£…é¥°å™¨æ¨¡å¼ (Decorator Pattern)æ¥åŒ…è£¹æ‰€æœ‰çš„ MCPå·¥å…·ã€‚è¿™æ ·å¯ä»¥å°†â€œä¸šåŠ¡é€»è¾‘â€ä¸â€œç›‘æ§é€»è¾‘â€è§£è€¦ã€‚
æ ¸å¿ƒæ¶æ„å›¾è§£
1.Request : LLM å‘èµ·è°ƒç”¨ã€‚
2.Trace IDAudit Layer :
3.Logic Layer : æ‰§è¡Œå…·ä½“çš„æ•°æ®åº“æŸ¥è¯¢ã€‚
4.Response : è¿”å›ç»“æœï¼ŒAudit Layer æ‹¦æˆªå¹¶è®°å½•â€œç»“æŸçŠ¶æ€â€å’Œè€—æ—¶ã€‚
å®Œæ•´ä»£ç å®ç° ( oilfield_advanced_mcp.py)
ä½ å¯ä»¥ç›´æ¥ä¿å­˜å¹¶è¿è¡Œæ­¤æ–‡ä»¶ã€‚
import time
import uuid
import json
import logging
import functools
from typing import List, Dict, Optional, Any, Literal
from datetime import datetime
from fastmcp import FastMCP, Context
from pydantic import Field

# ==========================================
# 1. åŸºç¡€è®¾æ–½å±‚ï¼šæ—¥å¿—ä¸çŠ¶æ€è¿½è¸ª
# ==========================================

# é…ç½®ç»“æ„åŒ–æ—¥å¿— (JSON Logs)ï¼Œæ–¹ä¾¿æ¥å…¥ ELK æˆ– Splunk
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("DrillingMCP")

class AuditTracker:
    """
    è´Ÿè´£è·Ÿè¸ªå·¥å…·è°ƒç”¨çš„çŠ¶æ€ã€è€—æ—¶å’Œç»“æœã€‚
    """
    @staticmethod
    def log_execution(tool_name: str):
        """
        è£…é¥°å™¨ï¼šç”¨äºåŒ…è£¹ MCP Toolï¼Œè‡ªåŠ¨å¤„ç†æ—¥å¿—å’Œé”™è¯¯è¿½è¸ª
        """
        def decorator(func):
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                # 1. ç”Ÿæˆå”¯ä¸€çš„è¿½è¸ª ID (Trace ID)
                trace_id = str(uuid.uuid4())[:8]
                start_time = time.time()
                
                # 2. è®°å½•è°ƒç”¨å¼€å§‹ (State: STARTED)
                # æ³¨æ„ï¼šå®é™…ç”Ÿäº§ä¸­è¿™é‡Œä¸è¦æ‰“å°æ•æ„Ÿå¯†ç /Token
                logger.info(json.dumps({
                    "event": "TOOL_START",
                    "trace_id": trace_id,
                    "tool": tool_name,
                    "params": str(kwargs)  # ç®€åŒ–å‚æ•°æ‰“å°
                }, ensure_ascii=False))

                try:
                    # 3. æ‰§è¡Œå®é™…ä¸šåŠ¡é€»è¾‘
                    result = func(*args, **kwargs)
                    
                    # 4. è®¡ç®—è€—æ—¶
                    duration = round((time.time() - start_time) * 1000, 2)
                    
                    # 5. è®°å½•è°ƒç”¨æˆåŠŸ (State: SUCCESS)
                    logger.info(json.dumps({
                        "event": "TOOL_SUCCESS",
                        "trace_id": trace_id,
                        "tool": tool_name,
                        "duration_ms": duration,
                        "result_preview": str(result)[:100] + "..." if len(str(result)) > 100 else str(result)
                    }, ensure_ascii=False))
                    
                    return result

                except Exception as e:
                    # 6. è®°å½•å¼‚å¸¸ (State: ERROR)
                    duration = round((time.time() - start_time) * 1000, 2)
                    logger.error(json.dumps({
                        "event": "TOOL_ERROR",
                        "trace_id": trace_id,
                        "tool": tool_name,
                        "duration_ms": duration,
                        "error": str(e)
                    }, ensure_ascii=False))
                    
                    # è¿”å›å‹å¥½çš„é”™è¯¯ä¿¡æ¯ç»™ LLMï¼Œè€Œä¸æ˜¯æŠ›å‡º Python å¼‚å¸¸å¯¼è‡´è¿æ¥æ–­å¼€
                    return f"âš ï¸ System Error (TraceID: {trace_id}): The tool failed to execute. Reason: {str(e)}"
            return wrapper
        return decorator

# ==========================================
# 2. æ•°æ®å±‚ï¼šæ¨¡æ‹Ÿä¼ä¸šæ•°æ®åº“ (Mock DB)
# ==========================================

class DrillingDatabase:
    def __init__(self):
        self.wells = [
            {"id": "ZT-102", "name": "Zhong-102", "block": "Block A", "status": "Active", "depth": 3550, "spud_date": "2023-10-01", "team": "Team-701"},
            {"id": "ZT-105", "name": "Zhong-105", "block": "Block A", "status": "Completed", "depth": 3800, "spud_date": "2023-08-15", "team": "Team-702"},
            {"id": "XJ-009", "name": "XinJiang-009", "block": "Block B", "status": "Active", "depth": 1200, "spud_date": "2023-11-20", "team": "Team-905"},
        ]
        self.reports = {
            "ZT-102_2023-11-01": {"mud": "MW: 1.25 sg", "bit": "Bit #4 PDC", "npt": "None", "remarks": "Drilling ahead."},
            "ZT-102_2023-11-02": {"mud": "MW: 1.28 sg", "bit": "Bit #4 PDC", "npt": "2.5 hrs repair", "remarks": "Torque spike."}
        }
        self.bha = {
            "ZT-102": [{"run": 1, "start": 0, "end": 1000, "comp": "Bit 17.5->Motor"}, {"run": 2, "start": 1000, "end": 3550, "comp": "Bit 12.25->RSS->LWD"}]
        }

    def query_wells(self, keyword, status):
        # æ¨¡æ‹Ÿ 0.1ç§’ å»¶è¿Ÿ
        time.sleep(0.1)
        return [w for w in self.wells if (keyword.lower() in w['name'].lower()) and (status == "All" or w['status'] == status)]

db = DrillingDatabase()

# ==========================================
# 3. MCP æœåŠ¡å®šä¹‰
# ==========================================

mcp = FastMCP("Advanced Oilfield Server")

# ==========================================
# 4. Tool å®ç° (åº”ç”¨äº†çŠ¶æ€è¿½è¸ª)
# ==========================================

# --- Layer 1: Discovery ---

@mcp.tool()
@AuditTracker.log_execution("search_wells") # <--- åº”ç”¨è¿½è¸ªè£…é¥°å™¨
def search_wells(
    keyword: str = Field(..., description="Keywords for search (e.g., 'ZT' or 'Block A')"),
    status: Literal["Active", "Completed", "All"] = "Active"
) -> str:
    """æ¨¡ç³Šæœç´¢äº•å·ã€‚è¿”å› Markdown æ ¼å¼åˆ—è¡¨ã€‚"""
    
    wells = db.query_wells(keyword, status)
    
    if not wells:
        return f"No wells found for '{keyword}' ({status})."
    
    # æ„é€  Markdown è¡¨æ ¼
    md = f"Found {len(wells)} wells:\n\n"
    md += "| Well ID | Name | Status | Depth |\n|---|---|---|---|\n"
    for w in wells:
        md += f"| {w['id']} | {w['name']} | {w['status']} | {w['depth']}m |\n"
    return md

@mcp.tool()
@AuditTracker.log_execution("get_well_summary")
def get_well_summary(well_id: str) -> str:
    """è·å–å•äº•è¯¦æƒ…ç”»åƒã€‚"""
    # æ¨¡æ‹ŸæŸ¥æ‰¾
    well = next((w for w in db.wells if w['id'] == well_id), None)
    
    if not well:
        # æŠ›å‡ºå¼‚å¸¸æµ‹è¯• Error Log æ˜¯å¦å·¥ä½œ
        raise ValueError(f"Well ID {well_id} does not exist in registry.")
    
    return f"""
    === ğŸ†” Well Profile: {well['name']} ===
    - ID: {well['id']}
    - Team: {well['team']}
    - Spud Date: {well['spud_date']}
    - Status: {well['status']}
    """

# --- Layer 2: Engineering ---

@mcp.tool()
@AuditTracker.log_execution("get_daily_report")
def get_daily_report(
    well_id: str, 
    date: str, 
    section: Optional[Literal["mud", "bit", "npt", "remarks"]] = None
) -> str:
    """è·å–æ—¥æŠ¥(DDR)ã€‚æ”¯æŒåªè·å–ç‰¹å®šæ®µè½ã€‚"""
    key = f"{well_id}_{date}"
    report = db.reports.get(key)
    
    if not report:
        return f"ğŸ“ No DDR found for {well_id} on {date}."
    
    if section:
        return f"**{section.upper()}**: {report.get(section, 'N/A')}"
    
    return json.dumps(report, indent=2)

@mcp.tool()
@AuditTracker.log_execution("get_bha_config")
def get_bha_config(well_id: str, depth_range: str) -> str:
    """æŸ¥è¯¢ BHA é’»å…·ç»„åˆã€‚"""
    bha_list = db.bha.get(well_id, [])
    if not bha_list: 
        return "No BHA data."
    
    # ç®€åŒ–çš„é€»è¾‘ï¼Œç›´æ¥è¿”å›æ‰€æœ‰ Run ä¾›å±•ç¤º
    return "\n".join([f"Run {b['run']} ({b['start']}-{b['end']}m): {b['comp']}" for b in bha_list])

# ==========================================
# 5. å¯åŠ¨
# ==========================================
if __name__ == "__main__":
    print("ğŸš€ Advanced Oilfield MCP Server Started with Audit Logging...")
    # åœ¨ç»ˆç«¯è¿è¡Œï¼ŒFastMCP é»˜è®¤ä½¿ç”¨ stdio æ¨¡å¼
    mcp.run()

ä»£ç æ·±åº¦è§£æï¼šçŠ¶æ€è¿½è¸ªæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ
AuditTrackerLLM è°ƒç”¨search_wellsæ—¶ï¼Œåå°å‘ç”Ÿäº†ä»€ä¹ˆï¼š

1. æ‹¦æˆªä¸ ID ç”Ÿæˆ
å½“è¯·æ±‚åˆ°è¾¾æ—¶ï¼Œè£…é¥°å™¨@AuditTracker.log_executioné¦–å…ˆè¢«è§¦å‘ã€‚å®ƒç”Ÿæˆä¸€ä¸ªTrace IDï¼ˆä¾‹å¦‚a1b2c3d4ï¼‰ã€‚
 Description : LLM
2. å¼€å§‹çŠ¶æ€ (STARTED)
Using JSON
{
  "event": "TOOL_START",
  "trace_id": "a1b2c3d4",
  "tool": "search_wells",
  "params": "{'keyword': 'ZT', 'status': 'Active'}"
}
ç”¨é€”ï¼šå¦‚æœç³»ç»Ÿå¡ä½äº†ï¼Œä½ å¯ä»¥é€šè¿‡è¿™ä¸ªæ—¥å¿—çŸ¥é“â€œè¯·æ±‚è¿›æ¥äº†ï¼Œä½†æ²¡å‡ºå»â€ï¼Œä»è€Œå®šä½æ˜¯æ•°æ®åº“æ­»é”è¿˜æ˜¯ç½‘ç»œè¶…æ—¶ã€‚
3. å¼‚å¸¸æ•è· (ERROR Handling)
ä»£ç get_well_summaryä¸ä¼šCrashtry...exceptâ€‹
{
  "event": "TOOL_ERROR",
  "trace_id": "x9y8z7w6",
  "tool": "get_well_summary",
  "duration_ms": 45.2,
  "error": "Well ID ZT-999 does not exist..."
}
LLM Programâš ï¸ System Error (TraceID: x9y8z7w6): The tool failed to execute...
æ„ä¹‰ï¼šLLMçœ‹åˆ°è¿™ä¸ªé”™è¯¯åï¼Œä¼šå°è¯•è‡ªæˆ‘ä¿®æ­£ï¼ˆä¾‹å¦‚ï¼šâ€œæŠ±æ­‰ï¼Œæˆ‘å¯èƒ½è¾“é”™äº†äº•å·ï¼Œæˆ‘å…ˆæœç´¢ä¸€ä¸‹â€ï¼‰ï¼Œè€Œä¸æ˜¯ç›´æ¥æ–­å¼€è¿æ¥ã€‚

4. æ€§èƒ½ç›‘æ§ (Performance)
æ—¥å¿—ä¸­åŒ…å«duration_msã€‚
Application : get_bha_config5000ms, 5000ms, 5000ms SQL Server


ä¸‹ä¸€æ­¥ä¼˜åŒ–å»ºè®®
1.Context ä¼ é€’ç”¨æˆ·ä¿¡æ¯ï¼š FastMCPä»ä¸­ctx: Contextæå– Request Header ä¸­çš„ User ctxIDï¼Œå¹¶è®°å½•åˆ°æ—¥å¿—ä¸­ã€‚è¿™æ ·å°±å®ç°äº†â€œå¼ ä¸‰åœ¨ 10:00 æŸ¥è¯¢äº† ZT-102 äº•â€çš„å®¡è®¡åŠŸèƒ½ã€‚
@mcp.tool()
def sensitive_query(ctx: Context, well_id: str):
    user = ctx.request_context.meta.get("user") # è·å–ç”¨æˆ·ä¿¡æ¯
    logger.info(f"User {user} accessing {well_id}")
2.å¼‚æ­¥æ—¥å¿—ï¼šç›®å‰çš„logger.infoæ˜¯åŒæ­¥çš„ã€‚å¦‚æœå¹¶å‘é‡æé«˜ï¼Œå»ºè®®å°†æ—¥å¿—å‘é€é€»è¾‘æ”¾å…¥asyncio.create_taskæˆ–ä½¿ç”¨æ¶ˆThis is how Kafka/RabbitMQ works.


ç°åœ¨æä¾›æ›´è¯¦ç»†é’»äº•ä¸šåŠ¡æ•°æ®çš„æŸ¥è¯¢ä»£ç å®ç°(æ›²çº¿æ•°æ®å’Œå®æ—¶çš„æ•°æ®è·å–é™¤å¤–)
è¿™æ˜¯ä¸€ä¸ªéå¸¸æ‰å®çš„å·¥ç¨‹éœ€æ±‚. Curvesï¼‰å’Œæ¯«ç§’çº§å®æ—¶æ•°æ®ï¼ˆWITS/ETPï¼‰åï¼Œâ€œé’»äº•ä¸šåŠ¡æ•°æ®â€çš„æ ¸å¿ƒå…¶å®æ˜¯å…³ç³»å‹æ•°æ®ï¼ˆRelational Dataï¼‰

Description Oracle/PostgreSQL Description

äº•èº«ç»“æ„ (Wellbore Geometry)ï¼šå¥—ç®¡ã€é’»å¤´ã€äº•å¾„ã€‚

æ—¥æŠ¥ (DDR - Daily Drilling Report)ï¼šæ—¶æ•ˆåˆ†æã€æ³¥æµ†æ€§èƒ½ã€é’»äº•æ¶²ã€æˆæœ¬ã€‚

éç”Ÿäº§æ—¶é—´ (NPT)ï¼šäº‹æ•…ã€å¤æ‚æƒ…å†µç»Ÿè®¡ã€‚

ä¸‹é¢æ˜¯ä¸€ä¸ªåŸºäº SQLAlchemy (ORM) + FastMCPçš„å®Œæ•´ç”Ÿäº§çº§å®ç°.

ç›®å½•ç»“æ„è§„åˆ’
Note:

æ•°æ®å±‚ ( models.py+ db_init.py)ï¼šå®šä¹‰è¡¨ç»“æ„å’Œæ¨¡æ‹Ÿæ•°æ®ã€‚

æœåŠ¡å±‚ ( main.py)ï¼šå®šä¹‰ MCP Tools å’Œä¸šåŠ¡é€»è¾‘ã€‚

ç¬¬ä¸€éƒ¨åˆ†ï¼šæ•°æ®æ¨¡å‹ä¸æ¨¡æ‹Ÿæ•°æ® (åŸºäº SQLAlchemy)
è¿™éƒ¨åˆ†æ¨¡æ‹Ÿäº†ä½ åœ¨ä¼ä¸šæ•°æ®åº“ä¸­ä¼šçœ‹åˆ°çš„è¡¨ç»“æ„ã€‚
from sqlalchemy import create_engine, Column, Integer, String, Float, Date, ForeignKey, Text, DateTime
from sqlalchemy.orm import declarative_base, sessionmaker, relationship
from datetime import date, datetime

# ==========================================
# 1. ORM æ¨¡å‹å®šä¹‰ (æ¨¡æ‹Ÿä¼ä¸šæ•°æ®åº“è¡¨ç»“æ„)
# ==========================================
Base = declarative_base()

class Well(Base):
    __tablename__ = 'wells'
    id = Column(String(50), primary_key=True)  # å¦‚ ZT-102
    name = Column(String(100))                 # å¦‚ Zhong-102
    block = Column(String(50))                 # åŒºå—
    spud_date = Column(Date)                   # å¼€é’»æ—¥æœŸ
    target_depth = Column(Float)               # è®¾è®¡äº•æ·±
    status = Column(String(20))                # Active, Completed
    
    # å…³è”
    reports = relationship("DailyReport", back_populates="well")
    casings = relationship("CasingProgram", back_populates="well")

class CasingProgram(Base):
    """äº•èº«ç»“æ„/å¥—ç®¡æ•°æ®"""
    __tablename__ = 'casing_programs'
    id = Column(Integer, primary_key=True)
    well_id = Column(String(50), ForeignKey('wells.id'))
    run_date = Column(Date)
    size_inch = Column(Float)       # å¥—ç®¡å°ºå¯¸ (e.g., 9.625)
    shoe_depth = Column(Float)      # ä¸‹å…¥æ·±åº¦
    cement_top = Column(Float)      # æ°´æ³¥è¿”é«˜
    
    well = relationship("Well", back_populates="casings")

class DailyReport(Base):
    """é’»äº•æ—¥æŠ¥ (DDR) æ ¸å¿ƒè¡¨"""
    __tablename__ = 'daily_reports'
    id = Column(Integer, primary_key=True)
    well_id = Column(String(50), ForeignKey('wells.id'))
    report_date = Column(Date)
    report_no = Column(Integer)
    
    # å…³é”®ä¸šåŠ¡æ•°æ®
    current_depth = Column(Float)       # å½“å‰äº•æ·±
    progress = Column(Float)            # æ—¥è¿›å°º
    operation_summary = Column(Text)    # 24å°æ—¶ä½œä¸šæ‘˜è¦
    next_24_plan = Column(Text)         # ä¸‹ä¸€æ­¥è®¡åˆ’
    
    # æ³¥æµ†æ€§èƒ½ (ä¸šåŠ¡é‡ç‚¹)
    mud_density = Column(Float)         # å¯†åº¦ (sg)
    mud_viscosity = Column(Float)       # ç²˜åº¦ (s)
    
    # å…³è”
    npt_events = relationship("NPTEvent", back_populates="report")
    well = relationship("Well", back_populates="reports")

class NPTEvent(Base):
    """éç”Ÿäº§æ—¶é—´/å¤æ‚äº‹æ•…"""
    __tablename__ = 'npt_events'
    id = Column(Integer, primary_key=True)
    report_id = Column(Integer, ForeignKey('daily_reports.id'))
    category = Column(String(50))       # e.g., "Equipment Failure", "Loss"
    duration_hours = Column(Float)      # æŸå¤±å·¥æ—¶
    description = Column(Text)          # è¯¦ç»†æè¿°
    
    report = relationship("DailyReport", back_populates="npt_events")

# ==========================================
# 2. æ•°æ®åº“åˆå§‹åŒ–ä¸æ•°æ®æ³¨å…¥ (Mock Data)
# ==========================================
engine = create_engine('sqlite:///:memory:', echo=False) # ç”Ÿäº§ç¯å¢ƒæ¢æˆ connection string
Session = sessionmaker(bind=engine)

def init_db():
    Base.metadata.create_all(engine)
    session = Session()
    
    # åˆ›å»ºäº•
    w1 = Well(id="ZT-102", name="Zhong-102", block="Block-A", spud_date=date(2023, 10, 1), target_depth=4500, status="Active")
    session.add(w1)
    
    # åˆ›å»ºå¥—ç®¡æ•°æ®
    c1 = CasingProgram(well_id="ZT-102", run_date=date(2023, 10, 5), size_inch=13.375, shoe_depth=800, cement_top=0)
    c2 = CasingProgram(well_id="ZT-102", run_date=date(2023, 10, 20), size_inch=9.625, shoe_depth=2500, cement_top=500)
    session.add_all([c1, c2])
    
    # åˆ›å»ºæ—¥æŠ¥ (æ­£å¸¸é’»è¿›)
    r1 = DailyReport(
        well_id="ZT-102", report_date=date(2023, 11, 1), report_no=30,
        current_depth=3200, progress=150,
        operation_summary="Drilling 8.5in hole section from 3050m to 3200m. Parameters stable.",
        mud_density=1.25, mud_viscosity=55
    )
    
    # åˆ›å»ºæ—¥æŠ¥ (å‘ç”Ÿäº‹æ•…)
    r2 = DailyReport(
        well_id="ZT-102", report_date=date(2023, 11, 2), report_no=31,
        current_depth=3220, progress=20, # è¿›å°ºå¾ˆå°‘
        operation_summary="Drilling to 3220m, experienced severe losses. POOH to shoe.",
        mud_density=1.20, mud_viscosity=60 # è°ƒæ•´æ³¥æµ†
    )
    
    # å…³è”äº‹æ•…
    npt = NPTEvent(
        category="Lost Circulation", duration_hours=12.5,
        description="Loss rate 20 m3/hr at 3220m. Pumped LCM pill."
    )
    r2.npt_events.append(npt)
    
    session.add_all([r1, r2])
    session.commit()
    session.close()

# åˆå§‹åŒ–
init_db()
ç¬¬äºŒéƒ¨åˆ†ï¼šMCP æœåŠ¡å®ç° ( main.py)
NPTçš„ç—›ç‚¹ã€‚
from fastmcp import FastMCP
from pydantic import Field
from typing import List, Optional, Literal
from sqlalchemy import func
# å¼•å…¥ä¸Šé¢çš„æ¨¡å‹
# from models import Session, Well, DailyReport, CasingProgram, NPTEvent 

# åˆå§‹åŒ– MCP
mcp = FastMCP("Drilling Business Intelligence")

# ==========================================
# è¾…åŠ©å‡½æ•°ï¼šæ ¼å¼åŒ– Markdown è¡¨æ ¼
# ==========================================
def to_markdown_table(data: List[dict]) -> str:
    if not data:
        return "No data available."
    headers = data[0].keys()
    header_row = "| " + " | ".join(headers) + " |"
    separator = "| " + " | ".join(["---"] * len(headers)) + " |"
    rows = []
    for row in data:
        rows.append("| " + " | ".join(str(v) for v in row.values()) + " |")
    return "\n".join([header_row, separator] + rows)

# ==========================================
# Tool 1: äº•èº«ç»“æ„æŸ¥è¯¢ (Engineering)
# ==========================================
@mcp.tool()
def get_well_casing_program(well_id: str) -> str:
    """
    Get the Casing and Cementing history (Wellbore Geometry).
    Use this to understand the physical structure of the well.
    """
    session = Session()
    try:
        casings = session.query(CasingProgram).filter_by(well_id=well_id).order_by(CasingProgram.shoe_depth).all()
        
        if not casings:
            return f"No casing records found for well {well_id}."
            
        data = []
        for c in casings:
            data.append({
                "Date": c.run_date,
                "Size (in)": c.size_inch,
                "Shoe Depth (m)": c.shoe_depth,
                "TOC (m)": c.cement_top
            })
            
        return f"### Wellbore Geometry: {well_id}\n\n" + to_markdown_table(data)
    finally:
        session.close()

# ==========================================
# Tool 2: æ—¥æŠ¥æ¦‚è§ˆæŸ¥è¯¢ (Reporting)
# ==========================================
@mcp.tool()
def get_daily_ops_summary(
    well_id: str, 
    date_start: str = Field(..., description="Start date YYYY-MM-DD"),
    date_end: str = Field(..., description="End date YYYY-MM-DD"),
) -> str:
    """
    Retrieve Daily Drilling Report (DDR) summaries for a date range.
    Includes depth progress, mud properties, and main operational summary.
    """
    session = Session()
    try:
        reports = session.query(DailyReport).filter(
            DailyReport.well_id == well_id,
            DailyReport.report_date >= date_start,
            DailyReport.report_date <= date_end
        ).order_by(DailyReport.report_date).all()
        
        if not reports:
            return f"No reports found for {well_id} between {date_start} and {date_end}."

        # é’ˆå¯¹ LLM ä¼˜åŒ–è¾“å‡ºï¼šä½¿ç”¨æ–‡æœ¬æ‘˜è¦æ ¼å¼ï¼Œè€Œä¸æ˜¯çº¯è¡¨æ ¼ï¼Œæ–¹ä¾¿ LLM ç†è§£ä¸Šä¸‹æ–‡
        output = [f"### Operations Log: {well_id} ({date_start} to {date_end})"]
        
        for r in reports:
            entry = f"""
**Date: {r.report_date} (Report #{r.report_no})**
* **Depth**: {r.current_depth}m (Progress: +{r.progress}m)
* **Mud**: {r.mud_density} sg / {r.mud_viscosity} sec
* **Summary**: {r.operation_summary}
* **Plan**: {r.next_24_plan}
---"""
            output.append(entry)
            
        return "\n".join(output)
    finally:
        session.close()

# ==========================================
# Tool 3: NPT (éç”Ÿäº§æ—¶é—´) æ™ºèƒ½åˆ†æ (Analysis)
# ==========================================
@mcp.tool()
def analyze_npt_events(well_id: str) -> str:
    """
    Analyze Non-Productive Time (NPT) events and accidents for a well.
    Returns a statistical summary and detailed event list.
    """
    session = Session()
    try:
        # è”è¡¨æŸ¥è¯¢ï¼šReport -> NPT
        results = session.query(DailyReport, NPTEvent).join(NPTEvent).filter(
            DailyReport.well_id == well_id
        ).all()
        
        if not results:
            return f"âœ… No NPT (Non-Productive Time) events recorded for {well_id}. Operations are efficient."
        
        # 1. ç»Ÿè®¡æ•°æ®
        total_lost_hours = sum([npt.duration_hours for _, npt in results])
        event_count = len(results)
        
        # 2. è¯¦æƒ…åˆ—è¡¨
        details = []
        for report, npt in results:
            details.append({
                "Date": report.report_date,
                "Depth (m)": report.current_depth,
                "Category": npt.category,
                "Lost Hours": npt.duration_hours,
                "Description": npt.description
            })
            
        summary = f"""
### âš ï¸ NPT Analysis: {well_id}
- **Total Incidents**: {event_count}
- **Total Lost Time**: {total_lost_hours} hours
        """
        
        return summary + "\n\n" + to_markdown_table(details)
    finally:
        session.close()

# ==========================================
# Tool 4: æ³¥æµ†æ€§èƒ½è¿½è¸ª (Fluids)
# ==========================================
@mcp.tool()
def track_mud_properties(well_id: str, property_name: Literal["density", "viscosity"]) -> str:
    """
    Track the evolution of specific mud properties over time.
    Useful for detecting wellbore stability issues (e.g., density increase).
    """
    session = Session()
    try:
        reports = session.query(DailyReport).filter_by(well_id=well_id).order_by(DailyReport.report_date).all()
        
        if not reports:
            return "No mud data found."
            
        data = []
        for r in reports:
            val = r.mud_density if property_name == "density" else r.mud_viscosity
            data.append({
                "Date": r.report_date,
                "Depth": r.current_depth,
                f"Value ({property_name})": val
            })
            
        return f"### Mud Property Tracking: {property_name}\n\n" + to_markdown_table(data)
    finally:
        session.close()

if __name__ == "__main__":
    # å¯ä»¥åœ¨è¿™é‡Œåšç®€å•çš„æµ‹è¯•
    print("Drilling Business Data MCP Server Started.")
    mcp.run()

è®¾è®¡æ€è·¯è§£æ
1.æ•°æ®å…³ç³»å¤„ç† (Relational Handling)ï¼š
 Join ï¼‰ã€‚analyze_npt_eventsâ€‹JOINâ€‹DailyReportNPTEvent
 LLMä¸éœ€è¦è‡ªå·±å»å…³è”æ—¥æœŸï¼Œè¿™ä¸ª Toolç›´æ¥è¿”å›äº†â€œæ—¥æœŸ-äº•æ·±-äº‹æ•…æè¿°-æŸå¤±æ—¶é—´â€çš„å®Œæ•´è§†å›¾ã€‚
2.Markdown è¡¨æ ¼è¾“å‡ºï¼š
 get_well_casing_programâ€‹track_mud_propertiesâ€‹to_markdown_tableâ€‹
 åŸå› ï¼šClaude/GPT é˜…è¯» Markdown è¡¨æ ¼çš„èƒ½åŠ›æå¼ºã€‚ç›¸æ¯”äºè¿”å›ä¸€å † JSONï¼Œè¡¨æ ¼èƒ½è®© LLM Downloaded by Claude Desktop
3.ç²’åº¦æ§åˆ¶ï¼š
  get_daily_ops_summaryè¿™å››ä¸ªæœ€æ ¸å¿ƒçš„ä¸šåŠ¡å­—æ®µDepthã€‚MudSummaryPlan
  è¿™é˜²æ­¢äº† Context Window è¢«æ— æ„ä¹‰çš„å­—æ®µã€
4.åœºæ™¯åŒ– Tool è®¾è®¡ï¼š
  query_database_table(table_name)æˆ‘æ²¡æœ‰è®¾è®¡ä¸€ä¸ªé€šç”¨å¼ã€‚
  ç›¸åï¼Œæˆ‘è®¾è®¡äº†track_mud_propertiesã€‚è¿™ç¬¦åˆå·¥ç¨‹å¸ˆçš„æ€ç»´ï¼šâ€œæˆ‘æƒ³çœ‹è¿™å£äº•çš„æ³¥æµ†å¯†åº¦å˜åŒ–è¶‹åŠ¿â€ã€‚

å¦‚æœè¦éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ,ä½ éœ€è¦åšçš„å”¯engineå­—ç¬¦ä¸²ï¼š
# ä¿®æ”¹å‰
engine = create_engine('sqlite:///:memory:')

# ä¿®æ”¹å (è¿æ¥ Oracle)
engine = create_engine('oracle+cx_oracle://user:password@host:1521/?service_name=orcl')

# ä¿®æ”¹å (è¿æ¥ PostgreSQL)
engine = create_engine('postgresql://user:password@localhost/drilling_db')

è¿™å¥—ä»£ç æ¶µç›–äº†é’»äº•ä¸šåŠ¡ä¸­æœ€æ ¸å¿ƒçš„**â€œäº•èº«ç»“æ„â€ã€â€œæ–½å·¥æ—¥æŠ¥â€å’Œâ€œå¤æ‚æ—¶æ•ˆâ€**ä¸‰å¤§æ¿å—ï¼Œè¶³ä»¥åº”å¯¹å¤§éƒ¨åˆ†éå®æ—¶æ•°æ®çš„ä¸šåŠ¡æŸ¥è¯¢éœ€æ±‚ã€‚

é—®ï¼šæˆ‘è¦åŠ å…¥ä¸€äº›å¤šäº•å¯¹æ¯”çš„åŠŸèƒ½ï¼Œåº”è¯¥æ€ä¹ˆå®ç°
è¿™æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„åŠŸèƒ½æ‰©å±•ã€‚â€œå¤šäº•å¯¹æ¯”â€ï¼ˆMulti-Well Comparisonï¼‰æˆ–è€…å«â€œé‚»äº•åˆ†æâ€ï¼ˆOffset Well Analysisï¼‰æ˜¯é’»é™©çš„æ ¸å¿ƒæ‰‹æ®µã€‚

åœ¨ MCP ä¸­å®ç°å¤šäº•å¯¹æ¯”ï¼Œåƒä¸‡ä¸è¦è®© LLM Context æ¶ˆè€—å·¨å¤§ã€‚

Pythonâ€‹ compare_â€‹Alignment Guide

ä»¥ä¸‹æ˜¯å®ç°å¤šäº•å¯¹å®ç°ï¼š
æ ¸å¿ƒåœºæ™¯è®¾è®¡
æ¦‚è§ˆå¯¹æ¯” (General Benchmarking)ï¼š

ç”¨æˆ·é—®ï¼šâ€œå¯¹æ¯” ZT-102 å’Œ ZT-105 çš„åŸºæœ¬æƒ…å†µã€‚â€

ç­–ç•¥ï¼šæ¨ªå‘è¡¨æ ¼ï¼Œåˆ—å‡ºäº•æ·±ã€å‘¨æœŸã€æˆæœ¬ã€é’»æœºå‹å·ã€‚

æ—¶æ•ˆ/è¿›åº¦å¯¹æ¯” (Drilling Pace/ROP)ï¼š

ç”¨æˆ·é—®ï¼šâ€œè¿™ä¸¤å£äº•è°é’»å¾—å¿«ï¼Ÿâ€

ç­–ç•¥ï¼šè®¡ç®—å…³é”®é‡Œç¨‹ç¢‘ï¼ˆå¦‚ï¼šå®Œé’»å‘¨æœŸã€é’»è‡³ 2000m ç”¨æ—¶ã€æœºæ¢°é’»é€Ÿ ROP å‡å€¼ï¼‰ã€‚

é£é™©å¯¹æ¯” (NPT Analysis)ï¼š

ç”¨æˆ·é—®ï¼šâ€œè¿™ä¸€åŒºå—å“ªå£äº•äº‹æ•…æœ€å°‘ï¼Ÿâ€

(NPT )

ä»£ç å®ç° ( comparison_tools.py)
Pandasmain.pyâ€‹sqlalchemyâ€‹pandasâ€‹åœ¨åšæ•°æ®å¯¹å¼ºå¤§ï¼‰ã€‚
from fastmcp import FastMCP
from pydantic import Field
from typing import List
import pandas as pd
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
# å‡è®¾ä½ å¤ç”¨äº†ä¸Šä¸€æ®µä»£ç çš„ models
# from models import Well, DailyReport, NPTEvent

mcp = FastMCP("Drilling Comparison Service")

# æ•°æ®åº“è¿æ¥ (å¤ç”¨ä¹‹å‰çš„é…ç½®)
engine = create_engine('sqlite:///:memory:') # ç”Ÿäº§ç¯å¢ƒè¯·æ›¿æ¢
Session = sessionmaker(bind=engine)

# ==========================================
# Tool 1: åŸºç¡€æ¦‚è§ˆå¯¹æ¯” (KPI Benchmarking)
# ==========================================
@mcp.tool()
def compare_wells_overview(
    well_ids: str = Field(..., description="Comma-separated list of Well IDs to compare. e.g. 'ZT-102,ZT-105'")
) -> str:
    """
    Compare high-level KPIs (Key Performance Indicators) between multiple wells.
    Includes: Target Depth, Actual Depth, Status, Spud Date.
    """
    # 1. è§£æå‚æ•°
    ids = [w.strip() for w in well_ids.split(',')]
    
    session = Session()
    try:
        # 2. æ‰¹é‡æŸ¥è¯¢
        wells = session.query(Well).filter(Well.id.in_(ids)).all()
        
        if not wells:
            return "No wells found with the provided IDs."
            
        # 3. ä½¿ç”¨ Pandas è¿›è¡Œè½¬ç½® (Transpose)ï¼Œé€‚åˆå¯¹æ¯”æŸ¥çœ‹
        data = []
        for w in wells:
            data.append({
                "Metric": "Well ID", "Value": w.id, "Well": w.id # è¾…åŠ©åˆ—
            })
            data.append({"Metric": "Block", "Value": w.block, "Well": w.id})
            data.append({"Metric": "Status", "Value": w.status, "Well": w.id})
            data.append({"Metric": "Target Depth (m)", "Value": w.target_depth, "Well": w.id})
            data.append({"Metric": "Spud Date", "Value": str(w.spud_date), "Well": w.id})
        
        df = pd.DataFrame(data)
        
        # é€è§†è¡¨ï¼šè¡Œæ˜¯æŒ‡æ ‡ï¼Œåˆ—æ˜¯äº•å·
        pivot_df = df.pivot(index="Metric", columns="Well", values="Value")
        
        return f"### ğŸ“Š Well Comparison Overview\n\n" + pivot_df.to_markdown()
    finally:
        session.close()

# ==========================================
# Tool 2: æé€Ÿåˆ†æ - é‡Œç¨‹ç¢‘å¯¹æ¯” (Performance)
# ==========================================
@mcp.tool()
def compare_drilling_pace(
    well_ids: str = Field(..., description="Comma-separated Well IDs, e.g. 'ZT-102,ZT-105'")
) -> str:
    """
    Compare drilling speed performance. 
    Calculates 'Days to Depth' milestones (e.g., Days to 1000m, 2000m) and Average ROP.
    """
    ids = [w.strip() for w in well_ids.split(',')]
    session = Session()
    try:
        # è·å–æ‰€æœ‰æ—¥æŠ¥
        reports = session.query(DailyReport).filter(DailyReport.well_id.in_(ids)).all()
        
        if not reports:
            return "No daily reports data found for comparison."
            
        # è½¬æ¢ä¸º DataFrame å¤„ç†
        data = [{"well_id": r.well_id, "date": r.report_date, "depth": r.current_depth, "progress": r.progress} for r in reports]
        df = pd.DataFrame(data)
        
        # è½¬æ¢æ—¥æœŸå¹¶æŒ‰äº•ã€æ—¥æœŸæ’åº
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values(['well_id', 'date'])
        
        comparison_results = []
        
        for wid in ids:
            well_df = df[df['well_id'] == wid]
            if well_df.empty:
                continue
                
            # è®¡ç®—å¼€é’»ä»¥æ¥çš„å¤©æ•° (Cumulative Days)
            start_date = well_df['date'].min()
            well_df['days_from_spud'] = (well_df['date'] - start_date).dt.days + 1
            
            # è®¡ç®—å…³é”®æŒ‡æ ‡
            total_days = well_df['days_from_spud'].max()
            final_depth = well_df['depth'].max()
            avg_rop = well_df['progress'].mean() # ç®€å•çš„æ—¥è¿›å°ºå¹³å‡
            
            # è®¡ç®—é‡Œç¨‹ç¢‘ (Milestones): é’»åˆ° 1000m, 2000m, 3000m èŠ±äº†å‡ å¤©
            milestones = {}
            for target in [1000, 2000, 3000, 4000]:
                # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæ·±åº¦å¤§äº target çš„è®°å½•
                hit = well_df[well_df['depth'] >= target].head(1)
                if not hit.empty:
                    milestones[f"Days to {target}m"] = hit['days_from_spud'].values[0]
                else:
                    milestones[f"Days to {target}m"] = "-"
            
            row = {
                "Well ID": wid,
                "Total Days": total_days,
                "Final Depth": final_depth,
                "Avg Daily ROP (m/d)": round(avg_rop, 1),
                **milestones
            }
            comparison_results.append(row)
            
        return "### ğŸï¸ Drilling Speed & Milestones Comparison\n\n" + pd.DataFrame(comparison_results).to_markdown(index=False)
        
    finally:
        session.close()

# ==========================================
# Tool 3: äº‹æ•…å¤æ‚å¯¹æ¯” (NPT Analysis)
# ==========================================
@mcp.tool()
def compare_npt_statistics(
    well_ids: str = Field(..., description="Comma-separated Well IDs")
) -> str:
    """
    Compare Non-Productive Time (NPT) statistics.
    Identifies which well had more accidents and what the primary causes were.
    """
    ids = [w.strip() for w in well_ids.split(',')]
    session = Session()
    try:
        # æŸ¥è¯¢ NPT
        npts = session.query(NPTEvent, DailyReport).join(DailyReport).filter(DailyReport.well_id.in_(ids)).all()
        
        if not npts:
            return "âœ… No NPT events found for these wells. Perfect operations!"
            
        data = []
        for npt, report in npts:
            data.append({
                "well_id": report.well_id,
                "category": npt.category,
                "hours": npt.duration_hours
            })
            
        df = pd.DataFrame(data)
        
        # 1. æ€»æ—¶æ•ˆå¯¹æ¯” (Pivot Table)
        # ç»Ÿè®¡æ¯å£äº•ã€æ¯ç§äº‹æ•…ç±»å‹çš„æ€»å°æ—¶æ•°
        summary = df.pivot_table(index="well_id", columns="category", values="hours", aggfunc="sum", fill_value=0)
        
        # æ·»åŠ æ€»è®¡åˆ—
        summary['Total NPT (Hours)'] = summary.sum(axis=1)
        
        return "### âš ï¸ NPT (Risk) Comparison Matrix\n\n" + summary.to_markdown()
        
    finally:
        session.close()
åŠŸèƒ½äº®ç‚¹ä¸è®¾è®¡å“²å­¦
1. â€œè½¬ç½®â€çš„è¡¨æ ¼ (The Transposed View)
åœ¨compare_wells_overviewä¸­ï¼Œæˆ‘ä½¿ç”¨äº†pivotã€‚
ä¸€è¡Œä¸€ä¸ªäº•ã€‚
Note :
äººçœ¼ä¹ æƒ¯å·¦å³æ‰«è§†ã€‚Markdown LLMæ— æ³•ç†è§£ã€‚å°†â€œæŒ‡æ ‡â€ä½œä¸ºè¡Œï¼Œå°†â€œäº•å·â€ä½œä¸ºåˆ—ï¼Œæ˜¯å¯¹æ¯” 2-4 å£äº•çš„æœ€ä½³å±•ç¤ºæ–¹å¼ã€‚
2. â€œé‡Œç¨‹ç¢‘â€è®¡ç®— (Milestone Calculation)
â€‚compare_drilling_pace
ç—›ç‚¹ï¼šäº• A æ‰“äº† 30 å¤©ï¼Œäº• B æ‰“äº† 45 å¤©ï¼Œç›´æ¥æŠŠä¸¤ç»„æ•°æ®æ‰”ç»™ LLMï¼Œå®ƒå¾ˆéš¾çœ‹å‡ºè°å¿«ã€‚
æ–¹æ¡ˆï¼šæˆ‘åœ¨ä»£ç é‡Œè®¡ç®—äº†â€œé’»åˆ° 1000ç±³ç”¨äº†å‡ å¤©â€ã€â€œé’»åˆ°2000ç”¨äº†å‡ å¤©â€ã€‚
ZT - 102 â€º 0-2000m â€º â€º â€º â€º 10 â€º â€º â€º â€º â€º â€ºè¿™å°±æ˜¯æˆ‘ä»¬æƒ³è¦çš„æ™ºèƒ½åˆ†æã€‚
3. çµæ´»çš„è¾“å…¥å¤„ç†
å‚æ•°è®¾è®¡ä¸ºwell_ids: str(é€—å·åˆ†éš”)ï¼Œè€Œä¸æ˜¯List[str]ã€‚
åŸå› ï¼šè™½ç„¶ FastMCP æ”¯æŒ Listï¼Œä½†éƒ¨åˆ† LLM å®¢æˆ·ç«¯åœ¨å¤„ç† JSON Pythonå†…split(',')æœ€å¼ºã€‚
å®¢æˆ·ç«¯ Prompt äº¤äº’ç¤ºä¾‹
å½“ä½ åœ¨ Cursor/Claude Desktop ä¸­åŠ è½½äº†è¿™ä¸ª MCP Server åï¼š
User : "å¸®æˆ‘åˆ†æä¸€ä¸‹ ZT-102 å’Œ ZT-105 è¿™ä¸¤å£äº•ï¼Œè°çš„è¡¨ç°æ›´å¥½ï¼Ÿ"
LLM (compare_wells_overview Thinking compare_drilling_pace) :
LLM (Tool Call) :compare_wells_overview(well_ids="ZT-102, ZT-105")
LLM (Tool Call) :compare_drilling_pace(well_ids="ZT-102, ZT-105")
LLM (Answer) : æ ¹æ®æ•°æ®å¯¹æ¯”åˆ†æï¼š
Distance : ZT-102 (4200m)
Note : ZT-102: 150m/d, ZT-105, 2000m, ZT-102 8-year-old ZT-105 3-year-old parts
ç»“è®ºï¼šZT-102 æ•´ä½“æœºæ¢°é’»é€Ÿæ›´é«˜ï¼Œæ˜¯ä¸€å£å…¸å‹çš„æé€Ÿæ ‡æ†äº•ã€‚

é—®ï¼šæˆ‘è¿˜è¦æ–°å¢ä¸€ä¸ªTOOLå®ç°æ ¹æ®é’»äº•æ—¥æŠ¥è‡ªåŠ¨æ€»ç»“é’»äº•å‘¨æŠ¥/æœˆæŠ¥
è¿™æ˜¯ä¸€ä¸ªéå¸¸å…¸å‹çš„RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ)åœºæ™¯ã€‚è¦ç”Ÿæˆé«˜è´¨é‡çš„å‘¨æŠ¥/æœˆæŠ¥ï¼Œä¸èƒ½åªæŠŠå‡ åå¤©çš„æ—¥æŠ¥åŸæ–‡å…¨éƒ¨æ‰”ç»™LLMï¼Œè€Œåº”è¯¥åœ¨Python æ¶¦è‰²ã€‚
ä»¥ä¸‹æ˜¯Toolâ€‹â€‹
1. è®¾è®¡æ€è·¯ï¼šä»â€œç½—åˆ—â€åˆ°â€œèšåˆâ€
æˆ‘ä»¬éœ€è¦è®¾è®¡ä¸€ä¸ªgenerate_period_summaryå·¥å…·ï¼Œå®ƒä¸åªæ˜¯æŸ¥æ•°æ®åº“ï¼Œå®ƒè¦åšä»¥ä¸‹**ETLï¼ˆæå–-è½¬æ¢-åŠ è½½ï¼‰**å·¥ä½œï¼š
  è‡ªåŠ¨è®¡ç®—æœ¬å‘¨/æœ¬æœˆçš„è¿›å°ºæ€»æ•°ã€å¹³å‡æœºæ¢°é’»é€Ÿã€æ€» NPT æ—¶é—´ã€‚
   Min -> Maxï¼‰ã€‚
   Key Activityï¼Œå¹¶é‡ç‚¹çªå‡º NPTï¼ˆäº‹æ•…ï¼‰
2. ä»£ç å®ç° ( reporting_tools.py)
Pandas æ¥å¤„ç†æ—¶é—´åºåˆ—models.pyèšåˆã€‚main.py
from fastmcp import FastMCP
from pydantic import Field
from typing import Optional
import pandas as pd
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from datetime import datetime, timedelta

# å‡è®¾å¤ç”¨ä¹‹å‰çš„æ•°æ®åº“è¿æ¥
# from models import DailyReport, NPTEvent, Well

mcp = FastMCP("Drilling Reporting Service")
engine = create_engine('sqlite:///:memory:') # ç”Ÿäº§ç¯å¢ƒè¯·æ›¿æ¢
Session = sessionmaker(bind=engine)

@mcp.tool()
def get_period_drilling_data(
    well_id: str,
    start_date: str = Field(..., description="Start date (YYYY-MM-DD)"),
    end_date: str = Field(..., description="End date (YYYY-MM-DD)")
) -> str:
    """
    Aggregates drilling data for a specific period (Weekly/Monthly) to generate reports.
    Returns statistical metrics, NPT summaries, and a daily activity timeline.
    """
    session = Session()
    try:
        # 1. è·å–èŒƒå›´å†…æ‰€æœ‰æ—¥æŠ¥
        reports = session.query(DailyReport).filter(
            DailyReport.well_id == well_id,
            DailyReport.report_date >= start_date,
            DailyReport.report_date <= end_date
        ).order_by(DailyReport.report_date).all()

        if not reports:
            return f"No reports found for {well_id} between {start_date} and {end_date}."

        # 2. è½¬æ¢ä¸º DataFrame ä»¥ä¾¿è¿›è¡Œç»Ÿè®¡è®¡ç®—
        data = []
        for r in reports:
            # è·å–å½“å¤©çš„ NPT è¯¦æƒ…
            npt_desc = []
            npt_hours = 0.0
            for npt in r.npt_events:
                npt_hours += npt.duration_hours
                npt_desc.append(f"{npt.category} ({npt.duration_hours}h)")
            
            data.append({
                "date": r.report_date,
                "depth": r.current_depth,
                "progress": r.progress,
                "mud_density": r.mud_density,
                "npt_hours": npt_hours,
                "npt_details": "; ".join(npt_desc),
                "summary": r.operation_summary
            })
        
        df = pd.DataFrame(data)
        
        # 3. æ ¸å¿ƒæŒ‡æ ‡ç»Ÿè®¡ (KPIs)
        total_days = len(df)
        start_depth = df.iloc[0]['depth'] - df.iloc[0]['progress'] # æ¨ç®—èµ·å§‹äº•æ·±
        end_depth = df.iloc[-1]['depth']
        total_footage = end_depth - start_depth
        avg_daily_progress = df['progress'].mean()
        
        total_npt = df['npt_hours'].sum()
        npt_days = df[df['npt_hours'] > 0]['date'].count() # å‘ç”Ÿ NPT çš„å¤©æ•°
        
        # æ³¥æµ†å˜åŒ–è¶‹åŠ¿
        mud_min = df['mud_density'].min()
        mud_max = df['mud_density'].max()
        mud_trend = "Stable" if (mud_max - mud_min) < 0.02 else f"Changed {mud_min}->{mud_max}"

        # 4. æ„å»ºæ¯æ—¥æ‘˜è¦æ—¶é—´è½´ (Timeline)
        # æŠ€å·§ï¼šåªä¿ç•™æ¯å¤©æœ€é‡è¦çš„åŠ¨ä½œï¼Œç»™ LLM æä¾›å†™ä½œç´ æ
        timeline = []
        for _, row in df.iterrows():
            date_str = row['date'].strftime("%Y-%m-%d")
            # å¦‚æœæœ‰ NPTï¼Œé‡ç‚¹æ ‡è®°
            status_icon = "âš ï¸" if row['npt_hours'] > 0 else "âœ…"
            npt_text = f"[NPT: {row['npt_details']}]" if row['npt_hours'] > 0 else ""
            
            line = f"- **{date_str}** {status_icon}: Depth {row['depth']}m (+{row['progress']}m). {row['summary'][:100]}... {npt_text}"
            timeline.append(line)
        
        timeline_str = "\n".join(timeline)

        # 5. ç»„è£…ç»™ LLM çš„ç»“æ„åŒ–æç¤º
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸ç›´æ¥å†™å‘¨æŠ¥ï¼Œè€Œæ˜¯è¿”å›â€œå‘¨æŠ¥æ‰€éœ€çš„æ‰€æœ‰ç´ æâ€
        return f"""
### ğŸ“Š Period Report Data Source: {well_id}
**Period**: {start_date} to {end_date}

#### 1. Executive Summary Metrics
| Metric | Value |
|---|---|
| **Days Drilled** | {total_days} days |
| **Footage Drilled** | {total_footage:.1f} m |
| **Depth Interval** | {start_depth:.1f} m -> {end_depth:.1f} m |
| **Avg ROP/Day** | {avg_daily_progress:.1f} m/day |
| **Total NPT** | {total_npt:.1f} hours ({npt_days} days with incidents) |
| **Mud Density** | {mud_trend} sg |

#### 2. Daily Timeline & Highlights
{timeline_str}

#### 3. Instructions for Report Generation
- Use the metrics above to write the "Performance Overview".
- Use the timeline to write the "Key Activities" section.
- Summarize any âš ï¸ items in a separate "HSE & Issues" section.
"""

    finally:
        session.close()
3. å¦‚ä½•ä½¿ç”¨ (Prompt Engineering)
LLM Toolâ€‹ä½¿ç”¨è¿™äº›ç´ æã€‚

ç”¨æˆ·æé—®ï¼š

â€œå¸®æˆ‘ç”Ÿæˆ ZT-102 äº•ä¸Šå‘¨ï¼ˆ2023-11-01 åˆ° 2023-11-07ï¼‰çš„é’»äº•å‘¨æŠ¥ã€‚â€

LLM Program
1.Identify Tool : ç”¨æˆ·æƒ³è¦æŠ¥è¡¨ -> è°ƒç”¨get_period_drilling_data(well_id="ZT-102", start_date="2023-11-01", end_date="2023-11-07")ã€‚
2.Receive Data : è·å–åˆ°ä¸Šé¢ä»£ç è¿”å›çš„ Markdown æ ¼å¼çš„ç»Ÿè®¡æ•°æ®å’Œæ—¶é—´è½´ã€‚
3.Generate Output : LLM åŸºäºç´ æç”Ÿæˆæœ€ç»ˆæ–‡æœ¬ã€‚

ç”Ÿæˆçš„å‘¨æŠ¥æ•ˆæœç¤ºä¾‹ (LLM è¾“å‡º)ï¼š

ğŸ“„é’»äº•å‘¨æŠ¥ (Weekly Drilling Report)
Name : ZT-102
å‘¨æœŸ: 2023-11-01 è‡³ 2023-11-07
1. ç»¼è¿° (Executive Summary)
æœ¬å‘¨é’»äº•ä½œä¸šæ•´ä½“è¿›å±•é¡ºåˆ©ã€‚æœŸé—´å…±ä½œä¸š7å¤©ï¼Œå®Œæˆè¿›å°º950ç±³ï¼Œå½“å‰äº•æ·±è¾¾åˆ°4150ç±³ã€‚å¹³å‡æ—¥è¿›å°ºä¸º135.7ç±³/å¤©ã€‚æœ¬å‘¨æ³¥æµ†å¯†åº¦ä»1.25 sg æè‡³ 1.28 sg ä»¥åº”å¯¹åœ°å±‚å‹åŠ›ã€‚
2. å…³é”®æ—¶æ•ˆ (Performance)
Distance : 3200.0 m
å½“å‰äº•æ·±: 4150.0 m
( NPT )
3. ä½œä¸šå›é¡¾ (Weekly Highlights)
11-01 : 3200m distance, 3200m distance
11-02 (é‡ç‚¹å…³æ³¨) : âš ï¸ é’»è¿›è‡³ 3220m æ—¶å‘ç”Ÿäº•æ¼ï¼ˆLost Circulationï¼‰ï¼ŒæŸå¤±æ—¶é—´ 12.5 ã€‚
11-03 è‡³ 11-07 : æ¢å¤æ­£å¸¸é’»è¿›ï¼Œæ³¥æµ†æ€§èƒ½ç¨³å®šï¼Œæ— å¤æ‚æƒ…å†µã€‚
4. é—®é¢˜ä¸å»ºè®® (Issues & Actions)
æœ¬å‘¨ä¸»è¦é£é™©ç‚¹ä¸º11å¯†åˆ‡ç›‘æµ‹ 4200må¤„åœ°å±‚æ‰¿å‹èƒ½åŠ›ï¼Œæ¬¡æ¼å¤±ã€‚
4. è¿›é˜¶ä¼˜åŒ–å»ºè®®
1.è‡ªåŠ¨è®¡ç®—æ—¥æœŸï¼š LLM æœ‰æ—¶æä¸æ¸…â€œä¸Šå‘¨â€å…·ä½“æ˜¯å‡ å·ã€‚ä½ å¯ä»¥åœ¨ Python ä»£ç é‡Œå¢åŠ ä¸€ä¸ªç®€å•çš„ NLP dateparserLLMï¼šâ€œGenerate dates based on current timeâ€ ã€‚
2.DailyCoståŠ å…¥æˆæœ¬ä¼°ç®— (Cost Estimate)ï¼štotal_cost = df['daily_cost'].sum()ã€‚å‘¨æŠ¥é‡ŒåŠ ä¸Šâ€œæœ¬å‘¨èŠ±è´¹â€æ˜¯é¢†å¯¼æœ€å…³å¿ƒçš„ã€‚
3.ä½ å¯ä»¥å¾ªç¯è°ƒç”¨get_period_drilling_dataè·å– Block Aä¸‹æ‰€æœ‰äº•çš„æ•°æ®ï¼Œç„¶åè®© LLM åˆå¹¶ç”Ÿæˆä¸€ä»½â€œåŒºå—ç»¼è¿°â€ã€‚

é—®ï¼šä¸Šé¢ç”Ÿæˆçš„æ˜¯å•äº•çš„é’»äº•å‘¨æŠ¥/æœˆæŠ¥ï¼Œæˆ‘éœ€è¦çš„æ˜¯æŸä¸ªåŒºå—æˆ–é‡‡æ²¹å‚çš„æ€»ç»“æŠ¥å‘Š
çº§åˆ«çš„æŠ¥å‘Šï¼Œæ ¸å¿ƒæŒ‘æˆ˜åœ¨äºæ•°æ®èšåˆï¼ˆAggregationï¼‰å’Œå¼‚å¸¸ç­›é€‰ï¼ˆOutlier Detectionï¼‰ã€‚

ä»–ä»¬å…³å¿ƒçš„æ˜¯ï¼š

å®è§‚æŒ‡æ ‡ï¼šæ•´ä¸ªåŒºå—æ€»è¿›å°ºå¤šå°‘ï¼ŸåŠ¨ç”¨äº†å‡ éƒ¨é’»æœºï¼Ÿ

æ•ˆç‡æ’åï¼šå“ªå£äº•æ‰“å¾—æœ€å¿«ï¼ˆæé€Ÿæ ‡æ†ï¼‰ï¼Ÿ

é—®é¢˜èšç„¦ï¼šå“ªå£äº•æ‹–äº†åè…¿ï¼ˆNPT æœ€é«˜ï¼‰ï¼Ÿ

ä»¥ä¸‹æ˜¯ä¸“é—¨é’ˆå¯¹å¤šäº•èšåˆæŠ¥è¡¨çš„ Tool è®¾è®¡ä¸ä»£ç å®ç°ã€‚
1. Server-Side Aggregation
ä¸è¦è®© LLM å¾ªç¯è°ƒç”¨å•äº•å·¥å…·ï¼Œget_block_period_summaryåœ¨ Python å†…éƒ¨å®Œæˆ SQL Panda Pandasâ€‹

2. ä»£ç å®ç° ( block_reporting_tools.py)
åœ¨ä¹‹å‰çš„models.pyåŸºç¡€ä¸Šæ‰©å±•ã€‚
from fastmcp import FastMCP
from pydantic import Field
import pandas as pd
from sqlalchemy import create_engine, func
from sqlalchemy.orm import sessionmaker
# å‡è®¾å¤ç”¨ä¹‹å‰çš„æ¨¡å‹
# from models import DailyReport, NPTEvent, Well, Session

mcp = FastMCP("Block Reporting Service")
engine = create_engine('sqlite:///:memory:') # ç”Ÿäº§ç¯å¢ƒè¯·æ›¿æ¢
Session = sessionmaker(bind=engine)

@mcp.tool()
def get_block_period_summary(
    block_name: str = Field(..., description="Name of the Block or Plant (e.g., 'Block-A', 'No.3 Plant')"),
    start_date: str = Field(..., description="Start date (YYYY-MM-DD)"),
    end_date: str = Field(..., description="End date (YYYY-MM-DD)")
) -> str:
    """
    Generate a high-level summary report for an entire Block or Oil Plant.
    Aggregates metrics across all active wells, identifies top performers, and highlights systemic risks.
    """
    session = Session()
    try:
        # 1. æŸ¥æ‰¾è¯¥åŒºå—ä¸‹çš„æ‰€æœ‰äº•
        wells = session.query(Well).filter(Well.block == block_name).all()
        well_ids = [w.id for w in wells]
        
        if not well_ids:
            return f"âŒ No wells found in block '{block_name}'."

        # 2. è·å–è¿™äº›äº•åœ¨æŒ‡å®šæ—¶é—´æ®µå†…çš„æ—¥æŠ¥
        reports = session.query(DailyReport).filter(
            DailyReport.well_id.in_(well_ids),
            DailyReport.report_date >= start_date,
            DailyReport.report_date <= end_date
        ).all()
        
        if not reports:
            return f"No drilling activities found in {block_name} between {start_date} and {end_date}."

        # 3. æ•°æ®å¤„ç† (Pandas ETL)
        data = []
        for r in reports:
            # è®¡ç®—å½“æ—¥ NPT
            daily_npt = sum([n.duration_hours for n in r.npt_events])
            data.append({
                "well_id": r.well_id,
                "date": r.report_date,
                "progress": r.progress,
                "npt": daily_npt,
                "depth": r.current_depth
            })
        
        df = pd.DataFrame(data)
        
        # --- æ ¸å¿ƒæŒ‡æ ‡è®¡ç®— ---
        
        # A. å®è§‚ç»Ÿè®¡
        active_wells_count = df['well_id'].nunique() # åŠ¨ç”¨äº•æ•°
        total_footage = df['progress'].sum()         # æ€»è¿›å°º
        total_npt = df['npt'].sum()                  # æ€»éç”Ÿäº§æ—¶é—´
        avg_rop_block = df.groupby('well_id')['progress'].mean().mean() # åŒºå—å¹³å‡æ—¥è¿›å°º
        
        # B. å•äº•ç»©æ•ˆæ’å (Performance Ranking)
        # æŒ‰è¿›å°ºæ€»æ•°æ’å (æ‰¾å‡ºåŠŸå‹‹äº•)
        top_producers = df.groupby('well_id')['progress'].sum().sort_values(ascending=False).head(3)
        
        # æŒ‰ NPT æ’å (æ‰¾å‡ºé—®é¢˜äº•)
        top_trouble_wells = df.groupby('well_id')['npt'].sum().sort_values(ascending=False)
        top_trouble_wells = top_trouble_wells[top_trouble_wells > 0].head(3) # åªçœ‹æœ‰äº‹æ•…çš„
        
        # C. äº‹æ•…ç±»å‹åˆ†å¸ƒ (Pareto Analysis)
        # è¿™éœ€è¦å†æŸ¥ä¸€æ¬¡ NPT è¡¨åšç»†åˆ†ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå‡è®¾æˆ‘ä»¬ä» report ä¸­èƒ½æå–
        
        # 4. æ„å»ºè¿”å›ç»™ LLM çš„ç»“æ„åŒ–ç´ æ
        
        summary_md = f"""
### ğŸ­ Block Summary: {block_name}
**Period**: {start_date} to {end_date}

#### 1. KPI Overview (å…³é”®ç»©æ•ˆ)
| Metric | Value |
|---|---|
| **Active Rigs/Wells** | {active_wells_count} |
| **Total Footage** | {total_footage:.1f} m |
| **Total NPT** | {total_npt:.1f} hours |
| **Block Avg ROP** | {avg_rop_block:.1f} m/day |

#### 2. Star Performers (æé€Ÿæ ‡æ†)
The following wells contributed the most footage:
{top_producers.to_markdown(header=["Total Footage (m)"])}

#### 3. Focus Areas (é‡ç‚¹å…³æ³¨/é—®é¢˜äº•)
Wells with highest Non-Productive Time:
{top_trouble_wells.to_markdown(header=["Lost Hours"])}

#### 4. Activity Summary
- **Rig Count**: {active_wells_count} active rigs operating in this period.
- **Efficiency**: The block average speed is {avg_rop_block:.1f} m/day.
- **Risk**: {len(top_trouble_wells)} wells experienced operational issues.
"""
        return summary_md

    finally:
        session.close()
3. LLM äº¤äº’ä¸æŠ¥å‘Šç”Ÿæˆç¤ºä¾‹
æœˆä»½çš„ç”Ÿäº§æœˆæŠ¥â€æ—¶ã€‚

LLM æ¥æ”¶åˆ°çš„æ•°æ® (Tool Output):
### ğŸ­ Block Summary: Block-A
**Period**: 2023-11-01 to 2023-11-30

#### 1. KPI Overview
| Metric | Value |
|---|---|
| **Active Rigs/Wells** | 5 |
| **Total Footage** | 4500.0 m |
| **Total NPT** | 45.5 hours |
| **Block Avg ROP** | 120.5 m/day |

#### 2. Star Performers
| well_id | Total Footage (m) |
|---|---|
| ZT-102 | 1500.0 |
| ZT-105 | 1200.0 |
| ZT-108 | 900.0 |

#### 3. Focus Areas
| well_id | Lost Hours |
|---|---|
| ZT-102 | 25.5 |
| ZT-109 | 10.0 |
4. ä¼˜åŒ–å»ºè®®ï¼šè®©æŠ¥å‘Šæ›´â€œæ‡‚è¡Œâ€
Python ä»£ç ä¸­å¢åŠ ä»¥ä¸‹é€»è¾‘ï¼š
1.åŒç¯æ¯”åˆ†æ (YoY / MoM) :
  Tool å‚æ•°å¢åŠ compare_with_last_month=Trueã€‚
  PythonTotal Footage: 4500m (â†‘10% vs last month)â€‹
  è¿™æ · LLM å°±èƒ½å†™å‡ºï¼šâ€œæœ¬æœˆè¿›å°ºè¾ƒä¸Šæœˆå¢é•¿ 10%ï¼Œç”Ÿäº§åŠ¿å¤´è‰¯å¥½ã€‚â€
2.é¢„ç®—/æˆæœ¬èšåˆ:
  ç±³å‡æˆæœ¬ï¼ŒDailyCostèšåˆè¿”å›Total Costå’ŒCost per Meter
  KPI
3.é˜Ÿä¼ï¼ˆRig Teamï¼‰æ’å:
  é€šå¸¸æ²¹ç”°æ˜¯æŒ‰â€œé’»äº•é˜Ÿâ€è€ƒæ ¸çš„ã€‚
  æ•°æ®å¤„ç†æ—¶ï¼Œæ”¹ä¸ºdf.groupby('team_name')è€Œä¸æ˜¯well_idã€‚
  è¾“å‡ºï¼šâ€œ701é˜Ÿæœ¬æœˆè¿›å°ºç¬¬ä¸€ï¼Œ705é˜Ÿäº‹æ•…ç‡æœ€é«˜ã€‚â€
æ€»ç»“
MCP Toolã€‚å®ƒè´Ÿè´£å®Œæˆæ‰€æœ‰çš„ Sum, Count, GroupBy å’Œ Sort æ“ä½œï¼ŒåªæŠŠç»“è®ºæ€§æ•°æ®å–‚ç»™ LLMï¼Œè¿™æ ·æ—¢èŠ‚çœäº†Tokenï¼Œäº†æŠ¥å‘Šæ•°æ®çš„å‡†ç¡®æ€§ï¼ˆLLM ä¸ä¼šï¼‰ã€‚

é—®ï¼šæ€ä¹ˆå¢å¼ºæ„å›¾è¯†åˆ«

æŠŠ Toolçš„å®šä¹‰å†™å¾—åƒâ€œæ“ä½œæ‰‹å†Œâ€ä¸€æ ·è¯¦ç»†ï¼Œå¹¶åœ¨ System Prompt é‡Œç»™å®ƒå‡ é“â€œä¾‹é¢˜â€ã€‚
åœ¨å¼€å‘ MCP æœåŠ¡æ—¶ï¼Œæ„å›¾è¯†åˆ«ï¼ˆIntent Recognitionï¼‰ä½“éªŒç”Ÿæ­»çš„å…³é”®ã€‚å¦‚æœ LLM é€‰é”™äº†Toolï¼ŒChinese tool
çš„é€šç”¨èƒ½åŠ›æ˜¯ä¸å¤Ÿçš„ã€‚ä½ éœ€è¦é€šè¿‡ä»¥ä¸‹5ä¸ªå±‚çº§çš„ç­–ç•¥æ¥å¼ºåˆ¶æé«˜åŒ¹é…ç²¾åº¦ã€‚

ç¬¬ä¸€å±‚ï¼šç²¾å‡†çš„ Tool å®šä¹‰ (The Foundation)
LLM Documentation (æ–‡æ¡£å­—ç¬¦ä¸²)çš„ä¸€éƒ¨åˆ†ã€‚
âŒ é”™è¯¯çš„å†™æ³•(æ¨¡ç³Š)ï¼š
@mcp.tool()
def query_data(id: str, type: str):
    """Query data from database."""
    pass
LLM å›°æƒ‘ç‚¹ï¼šä»€ä¹ˆæ˜¯ typeï¼Ÿ

âœ… æ­£ç¡®çš„å†™æ³• (åœºæ™¯åŒ– + å‚æ•°æšä¸¾)ï¼š
@mcp.tool()
def get_daily_drilling_report(
    well_id: str,
    date: str,
    section: Literal["mud", "npt", "cost", "full"] = "full"
):
    """
    [Scenario]: Use this tool when the user asks about daily activities, accidents (NPT), 
    fluid properties (mud weight/viscosity), or what happened on a specific day.
    
    [Keywords]: 'DDR', 'Daily Report', 'Operations', 'Mud', 'Accident'.
    """
    pass
ä¼˜åŒ–æŠ€å·§ï¼š
1.Scenario-Based Description : åœ¨æ–‡æ¡£ä¸­æ˜ç¡®å†™å‡ºâ€œå½“ç”¨æˆ·é—®...æ—¶ä½¿ç”¨æ­¤å·¥å…·â€.
2.Keywords Tagging : DDR, NPT, BHAï¼‰
ç¬¬äºŒå±‚ï¼šç³»ç»Ÿæç¤ºè¯å¢å¼º (System Prompt Engineering)
åœ¨ MCP Client ç«¯ï¼ˆå¦‚ Claude Desktop æˆ–ä½ çš„è‡ªå®šä¹‰å‰ç«¯ï¼‰é…ç½® System Promptï¼Œæ¤å…¥**â€œé¢†åŸŸè®¤çŸ¥â€**ã€‚
æ¨èçš„ System Prompt æ¨¡æ¿ï¼š
ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è½¬åŒ–ä¸ºç²¾å‡†çš„å·¥å…·è°ƒç”¨ã€‚

1. æœ¯è¯­æ˜ å°„è§„åˆ™ (Domain Dictionary) :

å½“ç”¨æˆ·è¯´ "æé€Ÿ"ã€"é’»å¾—å¿«ä¸å¿«" -> æ„å›¾æ˜¯ROP (æœºæ¢°é’»é€Ÿ) -> è°ƒç”¨compare_drilling_paceã€‚

å½“ç”¨æˆ·è¯´ "äº•èº«ç»“æ„"ã€"å¥—ç®¡" -> æ„å›¾æ˜¯Wellbore Geometry -> è°ƒç”¨get_well_casing_programã€‚

å½“ç”¨æˆ·è¯´ "éç”Ÿäº§æ—¶é—´"ã€"äº‹æ•…"ã€"å¤æ‚" -> æ„å›¾æ˜¯NPT -> è°ƒç”¨analyze_npt_eventsã€‚

2. æ€è€ƒé“¾ (Chain of Thought) :åœ¨è°ƒç”¨å·¥å…·å‰ï¼Œå…ˆåˆ†æç”¨æˆ·æƒ³è¦çš„æ˜¯â€œå•ç‚¹æ•°æ®â€è¿˜æ˜¯â€œå¯¹æ¯”åˆ†æâ€è¿˜æ˜¯â€œè¶‹åŠ¿æ€»ç»“â€ã€‚

3. é»˜è®¤è¡Œä¸º:

æœ€è¿‘ä¸€å¤©â€çš„æ•°æ®ã€‚

å¦‚æœç”¨æˆ·æ²¡æä¾›äº•å·ï¼Œå…ˆè°ƒç”¨search_wellsã€‚
ç¬¬ä¸‰å±‚ï¼šFew-Shot Learning (å°‘æ ·æœ¬ç¤ºä¾‹)
System Prompt ä¸­ç›´æ¥ç»™å‡ºUser Query -> Tool Callçš„æ ‡å‡†èŒƒä¾‹ã€‚

ç¤ºä¾‹é…ç½®ï¼š
[Examples]
User: "ZT-102 æ˜¨å¤©æ³¥æµ†å¯†åº¦æ˜¯å¤šå°‘ï¼Ÿ"
Assistant: get_daily_report(well_id="ZT-102", date="2023-11-05", section="mud")

User: "æ¯”è¾ƒä¸€ä¸‹ Block A å“ªå£äº•æœ€è¿‘è·‘å¾—æœ€å¿«ï¼Ÿ"
Assistant: compare_drilling_pace(well_id="ZT-102,ZT-105,ZT-108") 
(æ³¨æ„ï¼šå…ˆæ ¹æ® Block A æ‰¾åˆ°äº†è¿™å‡ å£äº•ï¼Œæˆ–è€…ç›´æ¥è°ƒç”¨ get_block_period_summary)

User: "çœ‹çœ‹è¿™å£äº•æœ‰ä»€ä¹ˆäº‹æ•…æ²¡"
Assistant: analyze_npt_events(well_id="ZT-102")

ç¬¬å››å±‚ï¼šå¢åŠ ä¸€ä¸ªâ€œæ€è€ƒå·¥å…·â€ (Router/Planner Tool)
20ä¸ªï¼‰ï¼Œç›´æ¥åŒ¹é…å®¹æ˜“é”™ã€‚ä½ å¯ä»¥è®¾è®¡ä¸€ä¸ªçº¯é€»è¾‘å·¥å…·ï¼Œä¸æŸ¥æ•°æ®åº“ï¼Œåªç”¨æ¥è¾…åŠ©è§„åˆ’ã€‚

è®¾è®¡ä¸€ä¸ªclarify_intentå·¥å…·ï¼š
@mcp.tool()
def plan_data_retrieval(
    intent_category: Literal["single_well_status", "multi_well_compare", "historical_report", "realtime_monitor"],
    entities: List[str],
    time_range: str
) -> str:
    """
    è¿™æ˜¯ä¸€ä¸ªè™šæ‹Ÿå·¥å…·ã€‚å½“ç”¨æˆ·çš„é—®é¢˜æ¯”è¾ƒå¤æ‚ï¼Œæ¶‰åŠå¤šä¸ªæ­¥éª¤æ—¶ï¼Œå…ˆè°ƒç”¨æ­¤å·¥å…·è¿›è¡Œè§„åˆ’ã€‚
    """
    return f"Plan confirmed: Category={intent_category}, Entities={entities}. Next step: Call specific tools."
	æ•ˆæœï¼š LLMä¼šè¢«è¿«å…ˆè¿›è¡Œä¸€æ¬¡â€œåˆ†ç±»â€ï¼Œä¸€æ—¦åˆ†ç±»ä¸ºmulti_well_compareï¼Œå®ƒå°±ä»è€Œç¼©å°compare_æœç´¢èŒƒå›´ã€‚

ç¬¬äº”å±‚ï¼šå‚æ•°å½’ä¸€åŒ–ä¸æ¨¡ç³ŠåŒ¹é… (Robustness)
Python ä»£ç éœ€è¦åšå®¹é”™å¤„ç†ï¼Œåè¿‡æ¥è¾…åŠ© LLMã€‚

åœºæ™¯ 1ï¼šç”¨æˆ·è¯´çš„æ˜¯ä¸­æ–‡äº•å·ï¼Œæ•°æ®åº“æ˜¯è‹±æ–‡ ID
  ç”¨æˆ·è¯´ï¼šâ€œæŸ¥ä¸€ä¸‹ä¸­102äº•çš„æ—¥æŠ¥â€
  LLM ä¼ å‚ï¼šwell_id="ä¸­102"

ä»£ç å±‚å¤„ç†ï¼š
def get_daily_report(well_id: str, ...):
    # è‡ªåŠ¨æ¸…æ´—ï¼šä¸­102 -> ZT-102
    normalized_id = normalize_well_id(well_id) 
    # ...
åœºæ™¯ 2ï¼šæ¨¡ç³Šçš„æ—¶é—´æè¿°
 ç”¨æˆ·è¯´ï¼šâ€œä¸Šå‘¨â€
 LLM ä¼ ä»¥æ¥å—date="last_week"è¿™ç§ç‰¹æ®Šå­—ç¬¦ä¸²ï¼Œç„¶ååœ¨ Python å†…éƒ¨è®¡ç®—datetime.now() - timedelta(days=7)ã€‚
 YYYY-MM-DDSystem Prompt é‡Œå¼ºåˆ¶è¦æ±‚
 
é—®ï¼šæ˜¯å¦åº”è¯¥å¯¹ç”¨æˆ·è¾“å…¥çš„æŸ¥è¯¢å†…å®¹æ”¹å†™æˆæ›´æ ‡å‡†çš„é—®é¢˜ï¼Œä»¥ä½¿å¾—LLMæ›´ç²¾ç¡®çš„è°ƒç”¨MCP TOOL
è¿™æ˜¯ä¸€ä¸ªéå¸¸å…³é”®çš„æ¶æ„å†³ç­–ã€‚ç­”æ¡ˆæ˜¯ï¼šå¿…é¡»æ”¹å†™ï¼ˆRewriting/Refiningï¼‰ï¼Œä½†å»ºè®®åœ¨ LLM çš„â€œæ€ç»´é“¾ï¼ˆChain of Thoughtï¼‰â€

åœ¨é’»äº•è¿™ç§ä¸“ä¸šé¢†åŸŸï¼Œç”¨æˆ·çš„æé—®å¾€å¾€æ˜¯å£è¯­åŒ–ã€å«ç³Šä¸”å¸¦æœ‰è¡Œä¸šé»‘è¯çš„ï¼Œç›´æ¥æ‹¿å»åŒ¹é…Tool çš„ Schema æˆåŠŸç‡å¾ˆä½ã€‚

æˆ‘ä»¬å°†è¿™ä¸ªè¿‡ç¨‹ç§°ä¸ºâ€œæŸ¥è¯¢å¯¹é½ (Query Alignment)â€ã€‚ä»¥ä¸‹æ˜¯ 3 ç§æ¨èçš„å®æ–½ç­–ç•¥ï¼ŒæŒ‰æ¨èç¨‹åº¦æ’åºï¼š

ç­–ç•¥ä¸€ï¼šåŸºäºæ€ç»´é“¾çš„éšå¼æ”¹å†™ (Chain of Thought Rewrite) â€”â€”æœ€æ¨è
ä¸è¦ä¿®æ”¹ç”¨æˆ·å‘ç»™ LLM ?åœ¨è°ƒç”¨å·¥å…·å‰,å…ˆç”Ÿæˆä¸€ä¸ªâ€œæ ‡å‡†åŒ–çš„æ€è€ƒæ­¥éª¤â€ã€‚
å®ç°æ–¹å¼
åœ¨ System Prompt ä¸­åŠ å…¥å¦‚ä¸‹æŒ‡ä»¤ï¼š
"Chinese:

å®ä½“æå–ï¼šå°†ç”¨æˆ·å£è¯­ä¸­çš„äº•å·ï¼ˆå¦‚'ä¸­102'ï¼‰è½¬æ¢ä¸ºæ ‡å‡† IDï¼ˆ'ZT-102'ï¼‰ã€‚

æœ¯è¯­ç¿»è¯‘ï¼šå°†è¡Œä¸šé»‘è¯ï¼ˆå¦‚'æ†‹æ³µ'ã€'èµ·ä¸‹é’»'ï¼‰è½¬æ¢ä¸ºå·¥å…·å¯¹åº”çš„å‚æ•°ï¼ˆ'Pump Pressure Spike', 'Tripping'ï¼‰ã€‚

é—®é¢˜é‡æ„ï¼šå°†ç”¨æˆ·æ¨¡ç³Šçš„â€œæ€ä¹ˆå›äº‹â€é‡å†™ä¸ºå…·ä½“çš„â€œæŸ¥è¯¢æ—¥æŠ¥æ‘˜è¦â€æˆ–â€œåˆ†æ NPTâ€ã€‚

"
æ•ˆæœå¯¹æ¯”
ç”¨æˆ·è¾“å…¥ï¼šâ€œZT-102 æ˜¨å¤©æ³¥æµ†æ˜¯ä¸æ˜¯åŠ é‡äº†ï¼Ÿâ€

LLM å†…éƒ¨æ€è€ƒ (éšå¼æ”¹å†™)ï¼š

Original : "ZT-102 æ˜¨å¤©æ³¥æµ†æ˜¯ä¸æ˜¯åŠ é‡äº†ï¼Ÿ"

Standardized : "Retrieve mud density data for ZT-102 on [Yesterday's Date] and check for density increase trend."

Tool Decision : track_mud_properties(well_id='ZT-102', property='density')Yes get_daily_report(..., section='mud').

ç­–ç•¥äºŒï¼šå‰ç½®â€œæ¾„æ¸…å·¥å…·â€ (The Clarifier Tool)
å¦‚æœç”¨æˆ·çš„æŸ¥è¯¢ç¡®å®å¤ªæ¨¡ç³Šï¼ˆä¾‹å¦‚åªè¯´äº†ä¸€ä¸ªâ€œçœ‹ä¸‹ZT-102â€ï¼Œå•çº¯æ”¹å†™å¯èƒ½ä¼šå¯¼è‡´â€œå¹»è§‰â€ã€‚æ­¤æ—¶åº”è®¾è®¡ä¸€ä¸ªä¸éœ€è¦å‚æ•°çš„çº¯é€»è¾‘å·¥å…·ï¼Œæˆ–è€…åˆ©ç”¨LLM çš„åé—®èƒ½åŠ›ã€‚

ä½†ä¸ºäº†è‡ªåŠ¨åŒ–ï¼Œä½ å¯ä»¥å¼•å…¥ä¸€ä¸ªsearch_knowledge_baseæˆ–lookup_glossaryå·¥å…·ä½œä¸ºä¸­é—´è·³æ¿ã€‚

åœºæ™¯
ç”¨æˆ·è¾“å…¥ï¼šâ€œZT-102 äº•æ¼äº†å—ï¼Ÿâ€

Theanalyze_npt_events book "Lost Circulation "

æµç¨‹ï¼š

LLMlookup_terminology(term="äº•æ¼")â€‹

Tool è¿”å›ï¼š{"standard_term": "Lost Circulation", "category": "NPT"}ã€‚

LLM å†è°ƒç”¨analyze_npt_events(category="Lost Circulation")ã€‚

ç­–ç•¥ä¸‰ï¼šæŸ¥è¯¢åˆ†è§£ (Query Decomposition) â€”â€” é’ˆå¯¹å¤æ‚é—®é¢˜
ç”¨æˆ·ç»å¸¸ä¼šæŠŠå¤šä¸ªé—®é¢˜æ‰åœ¨ä¸€èµ·ã€‚è¿™æ—¶å€™â€œæ”¹å†™â€å®é™…ä¸Šæ˜¯â€œæ‹†è§£â€ã€‚

åœºæ™¯
ç”¨æˆ·è¾“å…¥ï¼šâ€œå¯¹æ¯”ä¸€ä¸‹ A å’Œ B è°æ‰“å¾—å¿«ï¼Œæ˜¯ä¸æ˜¯å› ä¸ºæ³¥æµ†æ²¡é…å¥½ï¼Ÿâ€

æ”¹å†™/æ‹†è§£é€»è¾‘ï¼š è¿™å®é™…ä¸Šæ˜¯ä¸¤ä¸ªç‹¬ç«‹çš„æ ‡å‡†æŸ¥è¯¢ï¼š

Q1 (Performance) : "Compare ROP/Speed â€‹â€‹between Well A and Well B." ->compare_drilling_pace

Q2 (Fluids) : â€œRetrieve Mud Properties for Well A and B.â€ ->track_mud_properties

å®æˆ˜ï¼šé’ˆå¯¹é’»äº•ä¸šåŠ¡çš„ System Prompt
æŠŠè¿™æ®µ Prompt ä»£ç å»æ­£åˆ™æ›¿æ¢è¦æ™ºèƒ½å¾—å¤šï¼š
# Role
ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„é’»äº•æ•°æ®åˆ†æä¸“å®¶ã€‚ä½ è¿æ¥äº†ä¸€ä¸ªåŸºäº MCP çš„æ•°æ®æœåŠ¡ã€‚

# Query Alignment Protocol (æŸ¥è¯¢å¯¹é½åè®®)
ç”¨æˆ·çš„è¾“å…¥é€šå¸¸æ˜¯éæ ‡å‡†çš„ã€‚åœ¨è°ƒç”¨å·¥å…·å‰ï¼Œä½ å¿…é¡»è¿›è¡Œä»¥ä¸‹æ€ç»´è½¬æ¢ï¼š

1. **Date Normalization (æ—¥æœŸå½’ä¸€åŒ–)**
   - User: "ä¸Šå‘¨" -> Standard: "2023-XX-XX to 2023-XX-XX" (calculated based on current date).
   - User: "æ˜¨å¤©" -> Standard: "YYYY-MM-DD".

2. **Entity Resolution (å®ä½“è§£æ)**
   - User: "ä¸­102", "102äº•" -> Standard: "ZT-102".
   - User: "Block A", "AåŒº" -> Standard: "Block-A".

3. **Intent Mapping (æ„å›¾æ˜ å°„)**
   - "é’»å¾—æ…¢", "æ‰“ä¸åŠ¨" -> Intent: Check ROP/NPT -> Tool: `compare_drilling_pace` or `analyze_npt_events`.
   - "æ³¥æµ†", "ç²˜åº¦", "æ¯”é‡" -> Intent: Fluid Properties -> Tool: `track_mud_properties` or `get_daily_report(section='mud')`.
   - "äº•èº«", "å¥—ç®¡", "ä¸‹å¾—æ·±ä¸æ·±" -> Intent: Well Structure -> Tool: `get_well_casing_program`.

# Execution Rule
ä¸è¦è¯¢é—®ç”¨æˆ·â€œä½ æƒ³æŸ¥å…·ä½“çš„å“ªä¸ªæ—¥æœŸï¼Ÿâ€ï¼Œé™¤éä¿¡æ¯å®Œå…¨ç¼ºå¤±ã€‚å°½å¯èƒ½æ ¹æ®ä¸Šä¸‹æ–‡æ¨æ–­é»˜è®¤å€¼ï¼ˆä¾‹å¦‚ï¼šé»˜è®¤æœ€è¿‘ä¸€å¤©ï¼Œé»˜è®¤å…¨äº•æ®µï¼‰ã€‚
æ€»ç»“
æ˜¯å¦åº”è¯¥æ”¹å†™ï¼Ÿæ˜¯çš„ã€‚

System Prompt ( System Prompt)

Python å­—å…¸å†™ä¸å®Œï¼Œä½†LLMåŸç”Ÿå°±æ‡‚ã€‚

è¿™ç§æ–¹æ³•è¢«ç§°ä¸ºReflective Pattern (åæ€æ¨¡å¼)ï¼Œå®ƒèƒ½æ˜¾è‘—æé«˜ MCP Slot Filling