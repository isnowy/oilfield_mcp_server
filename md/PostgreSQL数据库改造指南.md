# PostgreSQL æ•°æ®åº“æ”¹é€ æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜å¦‚ä½•å°† `oilfield_mcp_server.py` ä»å†…å­˜SQLiteæ•°æ®åº“æ”¹é€ ä¸ºä½¿ç”¨çœŸå®çš„PostgreSQLæ•°æ®åº“ã€‚

## ğŸ“‹ ç›®å½•

1. [æ”¹åŠ¨æ¦‚è§ˆ](#æ”¹åŠ¨æ¦‚è§ˆ)
2. [ä¾èµ–é…ç½®ä¿®æ”¹](#ä¾èµ–é…ç½®ä¿®æ”¹)
3. [æ•°æ®åº“é…ç½®æ–‡ä»¶](#æ•°æ®åº“é…ç½®æ–‡ä»¶)
4. [ä»£ç ä¿®æ”¹æ¸…å•](#ä»£ç ä¿®æ”¹æ¸…å•)
5. [æ•°æ®è¿ç§»æ–¹æ¡ˆ](#æ•°æ®è¿ç§»æ–¹æ¡ˆ)
6. [PostgreSQLæ•°æ®åº“å‡†å¤‡](#postgresqlæ•°æ®åº“å‡†å¤‡)
7. [æµ‹è¯•éªŒè¯](#æµ‹è¯•éªŒè¯)
8. [ç”Ÿäº§éƒ¨ç½²æ³¨æ„äº‹é¡¹](#ç”Ÿäº§éƒ¨ç½²æ³¨æ„äº‹é¡¹)

---

## æ”¹åŠ¨æ¦‚è§ˆ

### éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶

| æ–‡ä»¶ | ä¿®æ”¹ç±»å‹ | è¯´æ˜ |
|------|---------|------|
| `requirements.txt` | æ–°å¢ä¾èµ– | æ·»åŠ PostgreSQLé©±åŠ¨ |
| `oilfield_mcp_server.py` | æ ¸å¿ƒä¿®æ”¹ | æ•°æ®åº“è¿æ¥ã€é…ç½®åŠ è½½ã€æ•°æ®åˆå§‹åŒ– |
| `db_config.json` | æ–°å¢æ–‡ä»¶ | æ•°æ®åº“è¿æ¥é…ç½®ï¼ˆä¸æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶ï¼‰ |
| `.env` | æ–°å¢æ–‡ä»¶ | æ•°æ®åº“æ•æ„Ÿä¿¡æ¯ï¼ˆä¸æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶ï¼‰ |
| `.gitignore` | æ›´æ–° | æ’é™¤æ•æ„Ÿé…ç½®æ–‡ä»¶ |
| `data_migration.py` | æ–°å¢æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰ | å°†æ¨¡æ‹Ÿæ•°æ®å¯¼å…¥çœŸå®æ•°æ®åº“ |

---

## ä¾èµ–é…ç½®ä¿®æ”¹

### 1. ä¿®æ”¹ `requirements.txt`

**å½“å‰å†…å®¹ï¼š**

```txt
# Core framework
fastmcp>=0.2.0
pydantic>=2.0.0
pydantic-settings>=2.0.0

# Database
sqlalchemy>=2.0.0

# Data processing
pandas>=2.0.0
tabulate>=0.9.0

# Logging and utilities
python-dateutil>=2.8.0
```

**éœ€è¦æ·»åŠ çš„æ–°ä¾èµ–ï¼š**

```txt
# Core framework
fastmcp>=0.2.0
pydantic>=2.0.0
pydantic-settings>=2.0.0

# Database
sqlalchemy>=2.0.0
psycopg2-binary>=2.9.0        # â† æ–°å¢ï¼šPostgreSQLé©±åŠ¨
python-dotenv>=1.0.0          # â† æ–°å¢ï¼šç¯å¢ƒå˜é‡ç®¡ç†

# Data processing
pandas>=2.0.0
tabulate>=0.9.0

# Logging and utilities
python-dateutil>=2.8.0
```

**å®‰è£…å‘½ä»¤ï¼š**

```bash
pip install psycopg2-binary python-dotenv
```

---

## æ•°æ®åº“é…ç½®æ–‡ä»¶

### 2. æ–°å»º `.env` æ–‡ä»¶ï¼ˆæ ¹ç›®å½•ï¼‰

ç”¨äºå­˜å‚¨æ•æ„Ÿçš„æ•°æ®åº“è¿æ¥ä¿¡æ¯ï¼Œ**ä¸æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶**ã€‚

```env
# PostgreSQL æ•°æ®åº“è¿æ¥é…ç½®
DB_HOST=localhost
DB_PORT=5432
DB_NAME=oilfield_db
DB_USER=postgres
DB_PASSWORD=your_password_here

# åº”ç”¨é…ç½®
DEV_MODE=false
LOG_LEVEL=INFO

# è¿æ¥æ± é…ç½®ï¼ˆå¯é€‰ï¼‰
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=10
DB_POOL_TIMEOUT=30
```

### 3. æ–°å»º `db_config.example.json`ï¼ˆç¤ºä¾‹é…ç½®ï¼‰

ç”¨äºå›¢é˜Ÿå‚è€ƒï¼Œå¯ä»¥æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶ã€‚

```json
{
  "database": {
    "type": "postgresql",
    "host": "localhost",
    "port": 5432,
    "database": "oilfield_db",
    "user": "postgres",
    "password": "ä½¿ç”¨ .env æ–‡ä»¶é…ç½®",
    "pool_size": 5,
    "max_overflow": 10,
    "pool_timeout": 30,
    "echo_sql": false
  },
  "app": {
    "dev_mode": false,
    "log_level": "INFO"
  }
}
```

### 4. æ›´æ–° `.gitignore`

ç¡®ä¿æ•æ„Ÿé…ç½®ä¸è¢«æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶ï¼š

```gitignore
# ç¯å¢ƒé…ç½®
.env
db_config.json

# Python
__pycache__/
*.py[cod]
*$py.class
venv/
.venv/

# IDE
.vscode/
.idea/

# æ•°æ®åº“
*.db
*.sqlite
*.sqlite3
```

---

## ä»£ç ä¿®æ”¹æ¸…å•

### 5. ä¿®æ”¹ `oilfield_mcp_server.py`

#### 5.1 æ·»åŠ é…ç½®åŠ è½½åŠŸèƒ½ï¼ˆæ–‡ä»¶å¼€å¤´éƒ¨åˆ†ï¼‰

**ä½ç½®ï¼š** ç¬¬ 1-20 è¡Œé™„è¿‘ï¼Œå¯¼å…¥éƒ¨åˆ†ä¹‹å

**å½“å‰ä»£ç ï¼š**

```python
import os
import re
import time
import json
import logging
import functools
import pandas as pd
from typing import List, Optional, Literal, Dict, Any
from datetime import date, datetime, timedelta
from fastmcp import FastMCP, Context
from pydantic import Field
from sqlalchemy import create_engine, Column, Integer, String, Float, Date, ForeignKey, Text, DateTime
from sqlalchemy.orm import declarative_base, sessionmaker, relationship
```

**ä¿®æ”¹ä¸ºï¼š**

```python
import os
import re
import time
import json
import logging
import functools
import pandas as pd
from typing import List, Optional, Literal, Dict, Any
from datetime import date, datetime, timedelta
from fastmcp import FastMCP, Context
from pydantic import Field
from sqlalchemy import create_engine, Column, Integer, String, Float, Date, ForeignKey, Text, DateTime
from sqlalchemy.orm import declarative_base, sessionmaker, relationship
from dotenv import load_dotenv  # â† æ–°å¢

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()  # â† æ–°å¢
```

#### 5.2 æ·»åŠ æ•°æ®åº“é…ç½®ç±»

**ä½ç½®ï¼š** ç¬¬ 22-29 è¡Œé™„è¿‘ï¼Œæ—¥å¿—é…ç½®ä¹‹å

**æ·»åŠ ä»¥ä¸‹ä»£ç ï¼š**

```python
# ==========================================
# æ•°æ®åº“é…ç½®åŠ è½½
# ==========================================

class DatabaseConfig:
    """æ•°æ®åº“é…ç½®ç®¡ç†ç±»"""
    
    @staticmethod
    def load_from_env() -> Dict[str, Any]:
        """ä»ç¯å¢ƒå˜é‡åŠ è½½æ•°æ®åº“é…ç½®"""
        return {
            "host": os.getenv("DB_HOST", "localhost"),
            "port": int(os.getenv("DB_PORT", "5432")),
            "database": os.getenv("DB_NAME", "oilfield_db"),
            "user": os.getenv("DB_USER", "postgres"),
            "password": os.getenv("DB_PASSWORD", ""),
            "pool_size": int(os.getenv("DB_POOL_SIZE", "5")),
            "max_overflow": int(os.getenv("DB_MAX_OVERFLOW", "10")),
            "pool_timeout": int(os.getenv("DB_POOL_TIMEOUT", "30")),
            "echo_sql": os.getenv("DB_ECHO_SQL", "false").lower() == "true"
        }
    
    @staticmethod
    def build_connection_string(config: Dict[str, Any]) -> str:
        """æ„å»ºPostgreSQLè¿æ¥å­—ç¬¦ä¸²"""
        return (
            f"postgresql://{config['user']}:{config['password']}@"
            f"{config['host']}:{config['port']}/{config['database']}"
        )
```

#### 5.3 ä¿®æ”¹æ•°æ®åº“è¿æ¥éƒ¨åˆ†

**ä½ç½®ï¼š** ç¬¬ 224-231 è¡Œï¼Œæ•°æ®åº“åˆå§‹åŒ–éƒ¨åˆ†

**å½“å‰ä»£ç ï¼ˆç¬¬ 228-231 è¡Œï¼‰ï¼š**

```python
# ä½¿ç”¨å†…å­˜æ•°æ®åº“ï¼ˆç”Ÿäº§ç¯å¢ƒæ›¿æ¢ä¸ºå®é™…æ•°æ®åº“è¿æ¥ï¼‰
engine = create_engine('sqlite:///:memory:', echo=False)
Session = sessionmaker(bind=engine)
Base.metadata.create_all(engine)
```

**ä¿®æ”¹ä¸ºï¼š**

```python
# ==========================================
# æ•°æ®åº“è¿æ¥åˆå§‹åŒ–
# ==========================================

def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
    try:
        # åŠ è½½æ•°æ®åº“é…ç½®
        db_config = DatabaseConfig.load_from_env()
        connection_string = DatabaseConfig.build_connection_string(db_config)
        
        logger.info(f"æ­£åœ¨è¿æ¥æ•°æ®åº“: {db_config['host']}:{db_config['port']}/{db_config['database']}")
        
        # åˆ›å»ºæ•°æ®åº“å¼•æ“
        global engine, Session
        engine = create_engine(
            connection_string,
            pool_size=db_config['pool_size'],
            max_overflow=db_config['max_overflow'],
            pool_timeout=db_config['pool_timeout'],
            echo=db_config['echo_sql'],
            pool_pre_ping=True,  # è¿æ¥å‰æ£€æŸ¥æœ‰æ•ˆæ€§
            pool_recycle=3600    # æ¯å°æ—¶å›æ”¶è¿æ¥
        )
        
        # åˆ›å»ºä¼šè¯å·¥å‚
        Session = sessionmaker(bind=engine)
        
        # åˆ›å»ºæ‰€æœ‰è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        Base.metadata.create_all(engine)
        
        logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼Œè¡¨ç»“æ„å·²åˆå§‹åŒ–")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        raise

# åˆå§‹åŒ–æ•°æ®åº“
init_database()
```

#### 5.4 ä¿®æ”¹æ¨¡æ‹Ÿæ•°æ®å‡½æ•°ï¼ˆå¯é€‰ï¼‰

**ä½ç½®ï¼š** ç¬¬ 233-371 è¡Œï¼Œ`seed_mock_data()` å‡½æ•°

**æ–¹æ¡ˆ Aï¼šä¿ç•™ç”¨äºå¼€å‘ç¯å¢ƒ**

```python
def seed_mock_data():
    """æ³¨å…¥æ¨¡æ‹Ÿæ•°æ®ï¼ˆä»…ç”¨äºå¼€å‘å’Œæµ‹è¯•ç¯å¢ƒï¼‰"""
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
    session = Session()
    try:
        existing_count = session.query(Well).count()
        if existing_count > 0:
            logger.info(f"æ•°æ®åº“å·²æœ‰ {existing_count} å£äº•çš„æ•°æ®ï¼Œè·³è¿‡æ¨¡æ‹Ÿæ•°æ®æ³¨å…¥")
            return
        
        logger.info("å¼€å§‹æ³¨å…¥æ¨¡æ‹Ÿæ•°æ®...")
        
        # åˆ›å»ºäº•ä¿¡æ¯
        wells = [
            Well(id="ZT-102", name="ä¸­å¡”-102", block="Block-A", target_depth=4500, 
                 spud_date=date(2023, 10, 1), status="Active", well_type="Horizontal",
                 team="Team-701", rig="Rig-50"),
            # ... å…¶ä»–äº•æ•°æ®ä¿æŒä¸å˜ ...
        ]
        session.add_all(wells)
        
        # ... å…¶ä½™æ¨¡æ‹Ÿæ•°æ®ä»£ç ä¿æŒä¸å˜ ...
        
        session.commit()
        logger.info("âœ… Mock data seeded successfully.")
        
    except Exception as e:
        session.rollback()
        logger.error(f"âŒ Error seeding data: {e}")
        raise
    finally:
        session.close()


# ä»…åœ¨å¼€å‘æ¨¡å¼ä¸‹åˆå§‹åŒ–æ¨¡æ‹Ÿæ•°æ®
if DEV_MODE:
    logger.info("ğŸ”“ å¼€å‘æ¨¡å¼ï¼šæ³¨å…¥æ¨¡æ‹Ÿæ•°æ®")
    seed_mock_data()
else:
    logger.info("ğŸ”’ ç”Ÿäº§æ¨¡å¼ï¼šä½¿ç”¨çœŸå®æ•°æ®åº“")
```

**æ–¹æ¡ˆ Bï¼šå®Œå…¨ç§»é™¤ï¼ˆç”Ÿäº§ç¯å¢ƒæ¨èï¼‰**

```python
# åˆ é™¤ seed_mock_data() å‡½æ•°
# åˆ é™¤ç¬¬ 371 è¡Œçš„ seed_mock_data() è°ƒç”¨
# ç”Ÿäº§ç¯å¢ƒä¸­æ•°æ®ç”±çœŸå®ä¸šåŠ¡ç³»ç»Ÿå½•å…¥
```

#### 5.5 æ·»åŠ å¥åº·æ£€æŸ¥å·¥å…·ï¼ˆå¯é€‰ä½†æ¨èï¼‰

**ä½ç½®ï¼š** åœ¨ MCP å·¥å…·å®šä¹‰éƒ¨åˆ†ï¼ˆç¬¬ 830 è¡Œä¹‹å‰ï¼‰

**æ·»åŠ ä»¥ä¸‹ä»£ç ï¼š**

```python
@mcp.tool()
@AuditLog.trace("database_health_check")
def database_health_check() -> str:
    """
    [åœºæ™¯] æ£€æŸ¥æ•°æ®åº“è¿æ¥çŠ¶æ€å’Œæ•°æ®æ¦‚è§ˆ
    [å…³é”®è¯] å¥åº·æ£€æŸ¥ã€è¿æ¥çŠ¶æ€ã€ç³»ç»ŸçŠ¶æ€
    """
    session = Session()
    try:
        # æµ‹è¯•è¿æ¥
        session.execute("SELECT 1")
        
        # ç»Ÿè®¡æ•°æ®
        well_count = session.query(Well).count()
        report_count = session.query(DailyReport).count()
        npt_count = session.query(NPTEvent).count()
        
        # æœ€æ–°æ—¥æŠ¥æ—¥æœŸ
        latest_report = session.query(DailyReport)\
            .order_by(DailyReport.report_date.desc())\
            .first()
        
        latest_date = latest_report.report_date if latest_report else "æ— æ•°æ®"
        
        return f"""
### âœ… æ•°æ®åº“å¥åº·æ£€æŸ¥

**è¿æ¥çŠ¶æ€**: æ­£å¸¸

**æ•°æ®ç»Ÿè®¡**:
- äº•æ•°é‡: {well_count} å£
- æ—¥æŠ¥è®°å½•: {report_count} æ¡
- NPTäº‹ä»¶: {npt_count} æ¡
- æœ€æ–°æ—¥æŠ¥æ—¥æœŸ: {latest_date}

**æ•°æ®åº“ä¿¡æ¯**:
- ç±»å‹: PostgreSQL
- è¿æ¥æ± : {engine.pool.size()} / {engine.pool.overflow()}
"""
    except Exception as e:
        return f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}"
    finally:
        session.close()
```

#### 5.6 æ”¹è¿›é”™è¯¯å¤„ç†ï¼ˆæ•°æ®åº“è¿æ¥ç›¸å…³ï¼‰

åœ¨æ¯ä¸ªæ•°æ®åº“æ“ä½œçš„ `try-except` å—ä¸­ï¼Œæ·»åŠ è¿æ¥é‡è¯•é€»è¾‘ï¼ˆå¯é€‰ï¼‰ï¼š

```python
from sqlalchemy.exc import OperationalError, DBAPIError

def with_retry(max_retries=3, delay=1):
    """æ•°æ®åº“æ“ä½œé‡è¯•è£…é¥°å™¨"""
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except (OperationalError, DBAPIError) as e:
                    if attempt == max_retries - 1:
                        raise
                    logger.warning(f"æ•°æ®åº“æ“ä½œå¤±è´¥ï¼Œé‡è¯• {attempt + 1}/{max_retries}: {e}")
                    time.sleep(delay * (attempt + 1))
            return func(*args, **kwargs)
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹ï¼š
@mcp.tool()
@AuditLog.trace("get_well_summary")
@with_retry(max_retries=3, delay=1)  # â† æ·»åŠ é‡è¯•é€»è¾‘
def get_well_summary(well_id: str, user_role: str = "default") -> str:
    # ... åŸæœ‰ä»£ç  ...
```

---

## æ•°æ®è¿ç§»æ–¹æ¡ˆ

### 6. åˆ›å»ºæ•°æ®è¿ç§»è„šæœ¬ï¼ˆå¯é€‰ï¼‰

å¦‚æœéœ€è¦å°†æ¨¡æ‹Ÿæ•°æ®å¯¼å…¥PostgreSQLè¿›è¡Œæµ‹è¯•ï¼Œåˆ›å»º `data_migration.py`ï¼š

```python
"""
æ•°æ®è¿ç§»è„šæœ¬ï¼šå°†æ¨¡æ‹Ÿæ•°æ®å¯¼å…¥ PostgreSQL æ•°æ®åº“
è¿è¡Œå‘½ä»¤: python data_migration.py
"""

import os
from datetime import date, timedelta
from dotenv import load_dotenv
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥æ•°æ®æ¨¡å‹
from oilfield_mcp_server import Base, Well, DailyReport, NPTEvent, CasingProgram

def migrate_data():
    """æ‰§è¡Œæ•°æ®è¿ç§»"""
    # æ„å»ºè¿æ¥å­—ç¬¦ä¸²
    db_user = os.getenv("DB_USER", "postgres")
    db_password = os.getenv("DB_PASSWORD", "")
    db_host = os.getenv("DB_HOST", "localhost")
    db_port = os.getenv("DB_PORT", "5432")
    db_name = os.getenv("DB_NAME", "oilfield_db")
    
    connection_string = f"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}"
    
    print(f"è¿æ¥æ•°æ®åº“: {db_host}:{db_port}/{db_name}")
    
    # åˆ›å»ºå¼•æ“
    engine = create_engine(connection_string, echo=False)
    Session = sessionmaker(bind=engine)
    
    # åˆ›å»ºè¡¨ç»“æ„
    print("åˆ›å»ºè¡¨ç»“æ„...")
    Base.metadata.create_all(engine)
    
    session = Session()
    
    try:
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
        existing_count = session.query(Well).count()
        if existing_count > 0:
            print(f"âš ï¸  æ•°æ®åº“å·²æœ‰ {existing_count} å£äº•çš„æ•°æ®")
            response = input("æ˜¯å¦æ¸…ç©ºå¹¶é‡æ–°å¯¼å…¥ï¼Ÿ(yes/no): ")
            if response.lower() != 'yes':
                print("å–æ¶ˆè¿ç§»")
                return
            
            # æ¸…ç©ºæ•°æ®
            print("æ¸…ç©ºç°æœ‰æ•°æ®...")
            session.query(NPTEvent).delete()
            session.query(CasingProgram).delete()
            session.query(DailyReport).delete()
            session.query(Well).delete()
            session.commit()
        
        print("å¼€å§‹å¯¼å…¥æ¨¡æ‹Ÿæ•°æ®...")
        
        # åˆ›å»ºäº•ä¿¡æ¯
        wells = [
            Well(id="ZT-102", name="ä¸­å¡”-102", block="Block-A", target_depth=4500, 
                 spud_date=date(2023, 10, 1), status="Active", well_type="Horizontal",
                 team="Team-701", rig="Rig-50"),
            Well(id="ZT-105", name="ä¸­å¡”-105", block="Block-A", target_depth=4200,
                 spud_date=date(2023, 10, 5), status="Active", well_type="Vertical",
                 team="Team-702", rig="Rig-51"),
            Well(id="ZT-108", name="ä¸­å¡”-108", block="Block-A", target_depth=5000,
                 spud_date=date(2023, 9, 20), status="Completed", well_type="Directional",
                 team="Team-701", rig="Rig-50"),
            Well(id="XY-009", name="æ–°ç–†-009", block="Block-B", target_depth=5500,
                 spud_date=date(2023, 9, 15), status="Active", well_type="Horizontal",
                 team="Team-808", rig="Rig-88"),
        ]
        session.add_all(wells)
        print(f"âœ“ å¯¼å…¥ {len(wells)} å£äº•")
        
        # åˆ›å»ºæ—¥æŠ¥æ•°æ®
        base_date = date(2023, 11, 1)
        report_count = 0
        
        # ZT-102: 10å¤©æ•°æ®
        for i in range(10):
            report_date = base_date + timedelta(days=i)
            is_npt_day = (i == 5)
            
            progress = 50 if is_npt_day else 150
            current_depth = 3000 + sum([50 if j == 5 else 150 for j in range(i + 1)])
            
            r = DailyReport(
                well_id="ZT-102",
                report_date=report_date,
                report_no=25 + i,
                current_depth=current_depth,
                progress=progress,
                mud_density=1.25 if i < 5 else 1.28,
                mud_viscosity=55 + i * 0.5,
                mud_ph=9.5,
                avg_rop=25.0 if not is_npt_day else 8.0,
                bit_number=3 if i < 7 else 4,
                operation_summary=f"é’»è¿›8.5å¯¸äº•æ®µï¼Œ{'é‡äº•æ¼ï¼Œå¾ªç¯å‹äº•' if is_npt_day else 'ä½œä¸šæ­£å¸¸'}ã€‚å½“å‰äº•æ·±{current_depth}ç±³ã€‚",
                next_plan="ç»§ç»­é’»è¿›" if not is_npt_day else "è§‚å¯Ÿäº•å†µï¼Œå‡†å¤‡å¤„ç†äº•æ¼"
            )
            
            if is_npt_day:
                npt = NPTEvent(
                    category="Lost Circulation",
                    duration=12.5,
                    severity="High",
                    description="äº•æ·±3750ç±³å¤„å‘ç”Ÿäº•æ¼ï¼Œæ¼å¤±é€Ÿç‡15ç«‹æ–¹ç±³/å°æ—¶ï¼Œæ³µæ³¨å µæ¼ææ–™å¤„ç†ã€‚"
                )
                r.npt_events.append(npt)
            
            session.add(r)
            report_count += 1
        
        # å…¶ä»–äº•çš„æ•°æ®...ï¼ˆçœç•¥ï¼Œå‚è€ƒåŸ seed_mock_data å‡½æ•°ï¼‰
        
        # å¥—ç®¡æ•°æ®
        casings = [
            CasingProgram(well_id="ZT-102", run_number=1, run_date=date(2023, 10, 5),
                         size=13.375, shoe_depth=800, cement_top=0),
            CasingProgram(well_id="ZT-102", run_number=2, run_date=date(2023, 10, 20),
                         size=9.625, shoe_depth=2500, cement_top=500),
            CasingProgram(well_id="ZT-105", run_number=1, run_date=date(2023, 10, 8),
                         size=13.375, shoe_depth=850, cement_top=0),
        ]
        session.add_all(casings)
        print(f"âœ“ å¯¼å…¥ {len(casings)} æ¡å¥—ç®¡è®°å½•")
        
        session.commit()
        print(f"\nâœ… æ•°æ®è¿ç§»å®Œæˆï¼å…±å¯¼å…¥ {report_count} æ¡æ—¥æŠ¥è®°å½•")
        
    except Exception as e:
        session.rollback()
        print(f"\nâŒ è¿ç§»å¤±è´¥: {e}")
        raise
    finally:
        session.close()

if __name__ == "__main__":
    migrate_data()
```

**è¿è¡Œæ–¹æ³•ï¼š**

```bash
python data_migration.py
```

---

## PostgreSQLæ•°æ®åº“å‡†å¤‡

### 7. åˆ›å»ºPostgreSQLæ•°æ®åº“

#### æ–¹æ³• 1ï¼šä½¿ç”¨å‘½ä»¤è¡Œ

```bash
# ç™»å½• PostgreSQL
psql -U postgres

# åˆ›å»ºæ•°æ®åº“
CREATE DATABASE oilfield_db WITH ENCODING 'UTF8';

# åˆ›å»ºä¸“ç”¨ç”¨æˆ·ï¼ˆæ¨èï¼‰
CREATE USER oilfield_user WITH PASSWORD 'secure_password';

# æˆæƒ
GRANT ALL PRIVILEGES ON DATABASE oilfield_db TO oilfield_user;

# é€€å‡º
\q
```

#### æ–¹æ³• 2ï¼šä½¿ç”¨ pgAdmin

1. æ‰“å¼€ pgAdmin
2. å³é”®ç‚¹å‡» "Databases" â†’ "Create" â†’ "Database"
3. æ•°æ®åº“åï¼š`oilfield_db`
4. ç¼–ç ï¼š`UTF8`
5. ç‚¹å‡» "Save"

#### æ–¹æ³• 3ï¼šä½¿ç”¨ Dockerï¼ˆæ¨èå¼€å‘ç¯å¢ƒï¼‰

åˆ›å»º `docker-compose.yml`:

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15
    container_name: oilfield_postgres
    environment:
      POSTGRES_DB: oilfield_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres123
      POSTGRES_HOST_AUTH_METHOD: trust
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped

volumes:
  postgres_data:
```

å¯åŠ¨æ•°æ®åº“ï¼š

```bash
docker-compose up -d
```

### 8. éªŒè¯æ•°æ®åº“è¿æ¥

åˆ›å»ºæµ‹è¯•è„šæœ¬ `test_db_connection.py`ï¼š

```python
"""æµ‹è¯• PostgreSQL æ•°æ®åº“è¿æ¥"""
import os
from dotenv import load_dotenv
from sqlalchemy import create_engine, text

load_dotenv()

def test_connection():
    db_user = os.getenv("DB_USER", "postgres")
    db_password = os.getenv("DB_PASSWORD", "")
    db_host = os.getenv("DB_HOST", "localhost")
    db_port = os.getenv("DB_PORT", "5432")
    db_name = os.getenv("DB_NAME", "oilfield_db")
    
    connection_string = f"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}"
    
    try:
        print(f"æ­£åœ¨è¿æ¥: {db_host}:{db_port}/{db_name}")
        engine = create_engine(connection_string, echo=True)
        
        with engine.connect() as conn:
            result = conn.execute(text("SELECT version()"))
            version = result.fetchone()
            print(f"\nâœ… è¿æ¥æˆåŠŸï¼")
            print(f"PostgreSQL ç‰ˆæœ¬: {version[0]}")
            
    except Exception as e:
        print(f"\nâŒ è¿æ¥å¤±è´¥: {e}")

if __name__ == "__main__":
    test_connection()
```

è¿è¡Œæµ‹è¯•ï¼š

```bash
python test_db_connection.py
```

---

## æµ‹è¯•éªŒè¯

### 9. æµ‹è¯•æ­¥éª¤

#### 9.1 ç¯å¢ƒå‡†å¤‡

```bash
# 1. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 2. é…ç½®ç¯å¢ƒå˜é‡ï¼ˆç¼–è¾‘ .env æ–‡ä»¶ï¼‰
# DB_HOST=localhost
# DB_PORT=5432
# DB_NAME=oilfield_db
# DB_USER=postgres
# DB_PASSWORD=your_password

# 3. æµ‹è¯•æ•°æ®åº“è¿æ¥
python test_db_connection.py

# 4. è¿è¡Œæ•°æ®è¿ç§»ï¼ˆå¦‚æœéœ€è¦ï¼‰
python data_migration.py
```

#### 9.2 å¯åŠ¨æœåŠ¡æµ‹è¯•

```bash
# å¯åŠ¨ MCP æœåŠ¡
python oilfield_mcp_server.py
```

åº”è¯¥çœ‹åˆ°ç±»ä¼¼è¾“å‡ºï¼š

```
============================================================
ğŸš€ æ²¹ç”°é’»äº•æ™ºèƒ½æŸ¥è¯¢ MCP Server å·²å¯åŠ¨
============================================================

ğŸ“Œ ç³»ç»ŸåŠŸèƒ½ï¼š
  âœ“ é‰´æƒç®¡ç†ï¼ˆåŸºäºè§’è‰²çš„æƒé™æ§åˆ¶ï¼‰
  âœ“ å•äº•æ•°æ®æŸ¥è¯¢ï¼ˆæ¦‚è§ˆã€æ—¥æŠ¥ã€NPTåˆ†æï¼‰
  âœ“ å¤šäº•å¯¹æ¯”åˆ†æï¼ˆé€Ÿåº¦ã€äº‹æ•…ã€ç»©æ•ˆï¼‰
  âœ“ å‘¨æŠ¥/æœˆæŠ¥ç”Ÿæˆï¼ˆå•äº•å’ŒåŒºå—çº§åˆ«ï¼‰
  âœ“ æ³¥æµ†å‚æ•°è¿½è¸ªï¼ˆå¯†åº¦ã€ç²˜åº¦ã€pHï¼‰

ğŸ”’ æƒé™æ¨¡å¼ï¼šç”Ÿäº§æ¨¡å¼ (ä¸¥æ ¼æƒé™æ§åˆ¶)
INFO:OilfieldMCP:æ­£åœ¨è¿æ¥æ•°æ®åº“: localhost:5432/oilfield_db
INFO:OilfieldMCP:âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼Œè¡¨ç»“æ„å·²åˆå§‹åŒ–
```

#### 9.3 åŠŸèƒ½æµ‹è¯•ï¼ˆé€šè¿‡ Claude Desktopï¼‰

é…ç½® Claude Desktop çš„ `config_example.json`ï¼š

```json
{
  "mcpServers": {
    "oilfield-intel": {
      "command": "python",
      "args": [
        "d:/work/joyagent/gemini-ge/oilfield_mcp_server.py"
      ],
      "env": {
        "USER_ROLE": "admin",
        "DEV_MODE": "false"
      }
    }
  }
}
```

æµ‹è¯•å¯¹è¯ï¼š

1. "æ£€æŸ¥æ•°æ®åº“å¥åº·çŠ¶æ€" â†’ è°ƒç”¨ `database_health_check`
2. "æŸ¥è¯¢ZT-102äº•çš„æ¦‚å†µ" â†’ è°ƒç”¨ `get_well_summary`
3. "æŸ¥è¯¢ZT-102äº•æ˜¨å¤©çš„æ—¥æŠ¥" â†’ è°ƒç”¨ `get_daily_report`

---

## ç”Ÿäº§éƒ¨ç½²æ³¨æ„äº‹é¡¹

### 10. å®‰å…¨æœ€ä½³å®è·µ

#### 10.1 ç¯å¢ƒå˜é‡å®‰å…¨

```bash
# âŒ é”™è¯¯ï¼šç¡¬ç¼–ç å¯†ç 
DB_PASSWORD=admin123

# âœ… æ­£ç¡®ï¼šä½¿ç”¨å¼ºå¯†ç 
DB_PASSWORD=$(openssl rand -base64 32)

# ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨å¯†é’¥ç®¡ç†æœåŠ¡ï¼ˆå¦‚ AWS Secrets Managerã€Azure Key Vaultï¼‰
```

#### 10.2 æ•°æ®åº“è¿æ¥å®‰å…¨

åœ¨ç”Ÿäº§ç¯å¢ƒçš„ `.env` æ–‡ä»¶ä¸­ï¼š

```env
# ä½¿ç”¨ SSL è¿æ¥
DB_SSLMODE=require
DB_SSLROOTCERT=/path/to/root.crt
DB_SSLCERT=/path/to/client.crt
DB_SSLKEY=/path/to/client.key

# è¿æ¥å­—ç¬¦ä¸²ç¤ºä¾‹ï¼ˆæ”¯æŒSSLï¼‰
# postgresql://user:password@host:port/dbname?sslmode=require
```

ä¿®æ”¹ `DatabaseConfig.build_connection_string()`:

```python
@staticmethod
def build_connection_string(config: Dict[str, Any]) -> str:
    """æ„å»ºPostgreSQLè¿æ¥å­—ç¬¦ä¸²ï¼ˆæ”¯æŒSSLï¼‰"""
    connection_string = (
        f"postgresql://{config['user']}:{config['password']}@"
        f"{config['host']}:{config['port']}/{config['database']}"
    )
    
    # æ·»åŠ SSLå‚æ•°
    ssl_mode = os.getenv("DB_SSLMODE")
    if ssl_mode:
        connection_string += f"?sslmode={ssl_mode}"
    
    return connection_string
```

#### 10.3 æƒé™ç®¡ç†

```sql
-- åˆ›å»ºåªè¯»ç”¨æˆ·ï¼ˆç”¨äºæŠ¥è¡¨æŸ¥è¯¢ï¼‰
CREATE USER oilfield_readonly WITH PASSWORD 'readonly_password';
GRANT CONNECT ON DATABASE oilfield_db TO oilfield_readonly;
GRANT USAGE ON SCHEMA public TO oilfield_readonly;
GRANT SELECT ON ALL TABLES IN SCHEMA public TO oilfield_readonly;

-- åˆ›å»ºè¯»å†™ç”¨æˆ·ï¼ˆç”¨äºåº”ç”¨ç¨‹åºï¼‰
CREATE USER oilfield_app WITH PASSWORD 'app_password';
GRANT CONNECT ON DATABASE oilfield_db TO oilfield_app;
GRANT USAGE ON SCHEMA public TO oilfield_app;
GRANT SELECT, INSERT, UPDATE ON ALL TABLES IN SCHEMA public TO oilfield_app;
```

#### 10.4 å¤‡ä»½ç­–ç•¥

```bash
# è‡ªåŠ¨å¤‡ä»½è„šæœ¬ (backup.sh)
#!/bin/bash
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backups/oilfield"
DB_NAME="oilfield_db"

pg_dump -U postgres -h localhost $DB_NAME | gzip > $BACKUP_DIR/oilfield_${DATE}.sql.gz

# ä¿ç•™æœ€è¿‘30å¤©çš„å¤‡ä»½
find $BACKUP_DIR -name "oilfield_*.sql.gz" -mtime +30 -delete
```

æ·»åŠ åˆ° crontabï¼š

```bash
# æ¯å¤©å‡Œæ™¨2ç‚¹è‡ªåŠ¨å¤‡ä»½
0 2 * * * /path/to/backup.sh
```

#### 10.5 ç›‘æ§å’Œå‘Šè­¦

æ·»åŠ æ•°æ®åº“ç›‘æ§ï¼ˆå¯é€‰ï¼‰ï¼š

```python
# åœ¨ oilfield_mcp_server.py ä¸­æ·»åŠ 
import psutil

@mcp.tool()
def system_monitor() -> str:
    """ç³»ç»Ÿèµ„æºç›‘æ§"""
    cpu_percent = psutil.cpu_percent(interval=1)
    memory = psutil.virtual_memory()
    
    session = Session()
    try:
        # æ•°æ®åº“è¿æ¥æ± çŠ¶æ€
        pool_size = engine.pool.size()
        pool_overflow = engine.pool.overflow()
        
        return f"""
### ğŸ“Š ç³»ç»Ÿç›‘æ§

**ç³»ç»Ÿèµ„æº**:
- CPU ä½¿ç”¨ç‡: {cpu_percent}%
- å†…å­˜ä½¿ç”¨ç‡: {memory.percent}%

**æ•°æ®åº“è¿æ¥æ± **:
- å½“å‰è¿æ¥æ•°: {pool_size}
- æº¢å‡ºè¿æ¥æ•°: {pool_overflow}
"""
    finally:
        session.close()
```

---

## é™„å½•

### A. å®Œæ•´çš„ç›®å½•ç»“æ„ï¼ˆæ”¹é€ åï¼‰

```
gemini-ge/
â”œâ”€â”€ oilfield_mcp_server.py       # ä¸»ç¨‹åºï¼ˆå·²ä¿®æ”¹ï¼‰
â”œâ”€â”€ requirements.txt              # ä¾èµ–é…ç½®ï¼ˆå·²æ›´æ–°ï¼‰
â”œâ”€â”€ .env                          # ç¯å¢ƒå˜é‡ï¼ˆæ–°å¢ï¼Œä¸æäº¤ï¼‰
â”œâ”€â”€ .env.example                  # ç¯å¢ƒå˜é‡ç¤ºä¾‹ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ .gitignore                    # Gitå¿½ç•¥é…ç½®ï¼ˆå·²æ›´æ–°ï¼‰
â”œâ”€â”€ db_config.example.json        # æ•°æ®åº“é…ç½®ç¤ºä¾‹ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ data_migration.py             # æ•°æ®è¿ç§»è„šæœ¬ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ test_db_connection.py         # è¿æ¥æµ‹è¯•è„šæœ¬ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ docker-compose.yml            # Dockeré…ç½®ï¼ˆæ–°å¢ï¼Œå¯é€‰ï¼‰
â”œâ”€â”€ config_example.json           # MCPé…ç½®ç¤ºä¾‹
â”œâ”€â”€ md/
â”‚   â”œâ”€â”€ PostgreSQLæ•°æ®åº“æ”¹é€ æŒ‡å—.md  # æœ¬æ–‡æ¡£
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ ...
â””â”€â”€ venv/                         # è™šæ‹Ÿç¯å¢ƒ
```

### B. å¿«é€Ÿæ£€æŸ¥æ¸…å•

å®Œæˆæ”¹é€ åï¼Œä½¿ç”¨æ­¤æ¸…å•éªŒè¯ï¼š

- [ ] å·²å®‰è£… `psycopg2-binary` å’Œ `python-dotenv`
- [ ] å·²åˆ›å»º `.env` æ–‡ä»¶å¹¶é…ç½®æ•°æ®åº“è¿æ¥
- [ ] å·²åˆ›å»º PostgreSQL æ•°æ®åº“ `oilfield_db`
- [ ] å·²ä¿®æ”¹ `oilfield_mcp_server.py` çš„æ•°æ®åº“è¿æ¥ä»£ç 
- [ ] å·²æµ‹è¯•æ•°æ®åº“è¿æ¥ï¼ˆè¿è¡Œ `test_db_connection.py`ï¼‰
- [ ] å·²åˆ›å»ºæ•°æ®åº“è¡¨ç»“æ„ï¼ˆè‡ªåŠ¨æˆ–æ‰‹åŠ¨ï¼‰
- [ ] å·²å¯¼å…¥åˆå§‹æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
- [ ] å·²æµ‹è¯• MCP æœåŠ¡å¯åŠ¨
- [ ] å·²é€šè¿‡ Claude Desktop æµ‹è¯•å·¥å…·è°ƒç”¨
- [ ] å·²é…ç½® `.gitignore` æ’é™¤æ•æ„Ÿæ–‡ä»¶
- [ ] å·²åˆ›å»ºæ•°æ®åº“å¤‡ä»½ç­–ç•¥ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰

### C. æ•…éšœæ’æŸ¥

#### é—®é¢˜ 1ï¼šè¿æ¥å¤±è´¥ "could not connect to server"

**åŸå› **ï¼šPostgreSQL æœåŠ¡æœªå¯åŠ¨æˆ–é˜²ç«å¢™é˜»æ­¢

**è§£å†³**ï¼š

```bash
# Windows
net start postgresql-x64-15

# Linux
sudo systemctl start postgresql

# macOS
brew services start postgresql
```

#### é—®é¢˜ 2ï¼šè®¤è¯å¤±è´¥ "password authentication failed"

**åŸå› **ï¼šç”¨æˆ·åæˆ–å¯†ç é”™è¯¯

**è§£å†³**ï¼š

```bash
# é‡ç½® PostgreSQL å¯†ç 
psql -U postgres
ALTER USER postgres PASSWORD 'new_password';
```

#### é—®é¢˜ 3ï¼šæ•°æ®åº“ä¸å­˜åœ¨ "database does not exist"

**åŸå› **ï¼šæ•°æ®åº“æœªåˆ›å»º

**è§£å†³**ï¼š

```sql
CREATE DATABASE oilfield_db;
```

#### é—®é¢˜ 4ï¼šè¡¨ä¸å­˜åœ¨ "relation does not exist"

**åŸå› **ï¼šè¡¨ç»“æ„æœªåˆ›å»º

**è§£å†³**ï¼š

è¿è¡Œè¿ç§»è„šæœ¬æˆ–ç¡®ä¿ `Base.metadata.create_all(engine)` è¢«æ‰§è¡Œã€‚

---

## æ€»ç»“

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜äº†ä» SQLite å†…å­˜æ•°æ®åº“è¿ç§»åˆ° PostgreSQL çš„å®Œæ•´æµç¨‹ã€‚å…³é”®æ”¹åŠ¨ç‚¹ï¼š

1. **ä¾èµ–**: æ·»åŠ  `psycopg2-binary` å’Œ `python-dotenv`
2. **é…ç½®**: åˆ›å»º `.env` æ–‡ä»¶ç®¡ç†æ•°æ®åº“è¿æ¥
3. **ä»£ç **: ä¿®æ”¹è¿æ¥å­—ç¬¦ä¸²å’Œåˆå§‹åŒ–é€»è¾‘
4. **æ•°æ®**: å¯é€‰çš„æ•°æ®è¿ç§»è„šæœ¬
5. **å®‰å…¨**: ç”Ÿäº§ç¯å¢ƒçš„å®‰å…¨æœ€ä½³å®è·µ

å®Œæˆæ”¹é€ åï¼Œç³»ç»Ÿå°†ä½¿ç”¨çœŸå®çš„ PostgreSQL æ•°æ®åº“ï¼Œæ”¯æŒæŒä¹…åŒ–å­˜å‚¨å’Œç”Ÿäº§çº§åˆ«çš„å¹¶å‘è®¿é—®ã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**åˆ›å»ºæ—¥æœŸ**: 2026-01-27  
**ç»´æŠ¤è€…**: [ä½ çš„åå­—]
