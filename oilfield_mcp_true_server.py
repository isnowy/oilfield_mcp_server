"""
æ²¹ç”°é’»äº•æ•°æ®MCP Server - HTTP/SSEç‰ˆæœ¬ï¼ˆçœŸå®æ•°æ®åº“ï¼‰
æ”¯æŒåŠ¨æ€ç”¨æˆ·æƒé™æ§åˆ¶ï¼Œè¿æ¥PostgreSQLæ•°æ®åº“æŸ¥è¯¢çœŸå®æ•°æ®

ç‰¹æ€§ï¼š
- ä½¿ç”¨FastAPIå®ç°HTTPç«¯ç‚¹
- æ”¯æŒSSE (Server-Sent Events) ä¼ è¾“
- ä»HTTP headersåŠ¨æ€è·å–ç”¨æˆ·è§’è‰²
- æ¯ä¸ªè¯·æ±‚ç‹¬ç«‹éªŒè¯æƒé™
- å•ä¸ªMCP Serverå®ä¾‹æœåŠ¡æ‰€æœ‰ç”¨æˆ·
- è¿æ¥PostgreSQLæ•°æ®åº“æŸ¥è¯¢çœŸå®æ²¹äº•æ•°æ®
"""
from mcp.server import Server
from mcp.server.sse import SseServerTransport  
from mcp.types import Tool, TextContent
from starlette.requests import Request as StarletteRequest
from starlette.responses import Response
import os
import re
import json
import time
import logging
import functools
import pandas as pd
from datetime import date, datetime, timedelta
from typing import Optional, List, Dict, Any, Literal
from contextlib import asynccontextmanager

from fastapi import FastAPI, Header, HTTPException, Request, Depends
from fastapi.responses import StreamingResponse, JSONResponse
from starlette.routing import Mount, Route
from starlette.applications import Starlette
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import uvicorn

from sqlalchemy import create_engine, Column, Integer, String, Float, Date, ForeignKey, Text, DateTime, Boolean, Numeric
from sqlalchemy.orm import declarative_base, sessionmaker, relationship
import psycopg2
from psycopg2.extras import RealDictCursor

# ==========================================
# æ—¥å¿—é…ç½®
# ==========================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("OilfieldMCP_TRUE")

# å¼€å‘æ¨¡å¼é…ç½®ï¼šè®¾ç½® DEV_MODE=true å¯è·³è¿‡æƒé™æ£€æŸ¥ï¼ˆæ–¹ä¾¿æµ‹è¯•ï¼‰
DEV_MODE = os.getenv("DEV_MODE", "true").lower() in ["true", "1", "yes"]

# æ•°æ®åº“é…ç½® - ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œé»˜è®¤è¿æ¥åˆ°æœ¬åœ°PostgreSQL
DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': int(os.getenv('DB_PORT', '5432')),
    'database': os.getenv('DB_NAME', 'rag'),
    'user': os.getenv('DB_USER', 'postgres'),
    'password': os.getenv('DB_PASSWORD', 'postgres')
}

# æƒé™é…ç½® - å¯ä»¥ä»é…ç½®æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡åŠ è½½
USER_PERMISSIONS = {
    "ADMIN": {
        "wells": "*",           # æ‰€æœ‰äº•
        "blocks": "*",          # æ‰€æœ‰åŒºå—
        "role": "admin",
        "description": "ç®¡ç†å‘˜ - å®Œå…¨è®¿é—®æƒé™"
    },
    "ENGINEER": {
        "wells": ["ZT-102", "ZT-105"],  # æŒ‡å®šäº•åˆ—è¡¨
        "blocks": ["Block-A"],
        "role": "engineer",
        "description": "å·¥ç¨‹å¸ˆ - Block-Açš„éƒ¨åˆ†äº• + å…¬å…±æ•°æ®"
    },
    "VIEWER": {
        "wells": ["ZT-102"],    # æŒ‡å®šäº•åˆ—è¡¨
        "blocks": ["Block-A"],
        "role": "viewer",
        "description": "æŸ¥çœ‹è€… - ZT-102åªè¯» + å…¬å…±æ•°æ®"
    },
    "USER": {
        "wells": [],            # ç©ºåˆ—è¡¨è¡¨ç¤ºåªèƒ½çœ‹å…¬å…±æ•°æ®
        "blocks": [],
        "role": "user",
        "description": "æ™®é€šç”¨æˆ· - ä»…å…¬å…±æ•°æ®"
    },
    "GUEST": {
        "wells": [],            # ç©ºåˆ—è¡¨è¡¨ç¤ºåªèƒ½çœ‹å…¬å…±æ•°æ®
        "blocks": [],
        "role": "guest",
        "description": "è®¿å®¢ - ä»…å…¬å…±æ•°æ®"
    }
}

# ==========================================
# æƒé™ç®¡ç†æœåŠ¡
# ==========================================

class PermissionService:
    """æƒé™ç®¡ç†æœåŠ¡"""
    
    @staticmethod
    def check_well_access(user_role: str, well_id: str) -> bool:
        """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æƒé™è®¿é—®ç‰¹å®šäº•"""
        if DEV_MODE:
            return True
        
        perms = USER_PERMISSIONS.get(user_role.upper(), USER_PERMISSIONS["GUEST"])
        
        if perms["role"] == "admin":
            return True
        
        if perms["wells"] == "*" or well_id in perms["wells"]:
            return True
        
        return False
    
    @staticmethod
    def check_block_access(user_role: str, block_name: str) -> bool:
        """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æƒé™è®¿é—®ç‰¹å®šåŒºå—"""
        if DEV_MODE:
            return True
        
        perms = USER_PERMISSIONS.get(user_role.upper(), USER_PERMISSIONS["GUEST"])
        
        if perms["role"] == "admin":
            return True
        
        if perms["blocks"] == "*" or block_name in perms["blocks"]:
            return True
        
        return False
    
    @staticmethod
    def get_accessible_wells(user_role: str) -> List[str]:
        """è·å–ç”¨æˆ·å¯è®¿é—®çš„æ‰€æœ‰äº•å·"""
        if DEV_MODE:
            return "*"
        
        perms = USER_PERMISSIONS.get(user_role.upper(), USER_PERMISSIONS["GUEST"])
        if perms["wells"] == "*":
            return "*"
        return perms["wells"]

def filter_wells_by_permission(wells: List[Dict], user_role: str, user_id: str = "", user_email: str = "") -> List[Dict]:
    """
    æ ¹æ®ç”¨æˆ·è§’è‰²è¿‡æ»¤äº•æ•°æ®ï¼ˆåŸºäºè§’è‰²æƒé™ï¼‰
    
    æƒé™è§„åˆ™ï¼š
    - ADMIN: å¯ä»¥æŸ¥çœ‹æ‰€æœ‰äº•
    - ENGINEER/VIEWER: æ ¹æ®USER_PERMISSIONSé…ç½®çš„äº•åˆ—è¡¨
    - USER/GUEST: æ‰€æœ‰å…¬å…±æ•°æ®
    
    æ³¨æ„ï¼šçœŸå®æ•°æ®åº“ä¸­çš„oil_wellsè¡¨æ²¡æœ‰owner_user_idå­—æ®µï¼Œæ‰€ä»¥æ‰€æœ‰æ•°æ®éƒ½æ˜¯å…¬å…±æ•°æ®
    """
    if DEV_MODE:
        logger.info(f"ğŸ”“ å¼€å‘æ¨¡å¼ï¼šç”¨æˆ· {user_email} ({user_role}) è®¿é—®æ‰€æœ‰æ•°æ®")
        return wells
    
    role_upper = user_role.upper() if user_role else "GUEST"
    
    # ADMINè§’è‰²ï¼šæŸ¥çœ‹æ‰€æœ‰äº•
    if role_upper == "ADMIN":
        logger.info(f"âœ… ADMINç”¨æˆ· {user_email} è®¿é—®æ‰€æœ‰ {len(wells)} å£äº•")
        return wells
    
    # è·å–è§’è‰²æƒé™é…ç½®
    perms = USER_PERMISSIONS.get(role_upper, USER_PERMISSIONS["GUEST"])
    allowed_wells = perms.get("wells", [])
    
    # å¦‚æœé…ç½®äº†ç‰¹å®šçš„äº•åˆ—è¡¨
    if allowed_wells == "*":
        logger.info(f"âœ… {role_upper}ç”¨æˆ· {user_email} è®¿é—®æ‰€æœ‰ {len(wells)} å£äº•")
        return wells
    elif allowed_wells:
        # è¿‡æ»¤å‡ºæƒé™åˆ—è¡¨ä¸­çš„äº•ï¼ˆçœŸå®æ•°æ®éƒ½æ˜¯å…¬å…±æ•°æ®ï¼Œæ‰€ä»¥åªéœ€æ£€æŸ¥äº•å·ï¼‰
        filtered = [
            well for well in wells
            if well.get('well_name') in allowed_wells or well.get('id') in allowed_wells
        ]
        logger.info(f"ğŸ”’ {role_upper}ç”¨æˆ· {user_email} è®¿é—® {len(filtered)}/{len(wells)} å£äº•ï¼ˆæƒé™é…ç½®ï¼‰")
        return filtered
    else:
        # æ™®é€šUSERæˆ–GUESTï¼šå¯ä»¥çœ‹æ‰€æœ‰å…¬å…±æ•°æ®ï¼ˆçœŸå®æ•°æ®åº“ä¸­éƒ½æ˜¯å…¬å…±æ•°æ®ï¼‰
        logger.info(f"âœ… {role_upper}ç”¨æˆ· {user_email} è®¿é—®æ‰€æœ‰å…¬å…±æ•°æ® {len(wells)} å£äº•")
        return wells

class AuditLog:
    """è£…é¥°å™¨ï¼šç”¨äºè®°å½•å·¥å…·è°ƒç”¨çš„è¾“å…¥ã€è¾“å‡ºã€è€—æ—¶å’ŒçŠ¶æ€"""
    
    @staticmethod
    def trace(tool_name: str):
        def decorator(func):
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                start_ts = time.time()
                trace_id = f"{int(time.time() * 1000)}"[-8:]
                
                try:
                    user_role = kwargs.get('user_role', 'GUEST')
                    logger.info(json.dumps({
                        "event": "TOOL_START",
                        "trace_id": trace_id,
                        "tool": tool_name,
                        "user": user_role,
                        "params": {k: v for k, v in kwargs.items() if k != 'user_role'}
                    }, ensure_ascii=False))
                    
                    result = func(*args, **kwargs)
                    duration = round((time.time() - start_ts) * 1000, 2)
                    
                    logger.info(json.dumps({
                        "event": "TOOL_SUCCESS",
                        "trace_id": trace_id,
                        "tool": tool_name,
                        "duration_ms": duration,
                        "result_length": len(str(result))
                    }, ensure_ascii=False))
                    
                    return result
                    
                except Exception as e:
                    duration = round((time.time() - start_ts) * 1000, 2)
                    logger.error(json.dumps({
                        "event": "TOOL_ERROR",
                        "trace_id": trace_id,
                        "tool": tool_name,
                        "duration_ms": duration,
                        "error": str(e)
                    }, ensure_ascii=False))
                    
                    return f"âš ï¸ ç³»ç»Ÿé”™è¯¯ (TraceID: {trace_id}): {str(e)}"
            
            return wrapper
        return decorator

# ==========================================
# æ•°æ®åº“è¿æ¥ç®¡ç†
# ==========================================

def get_db_connection():
    """è·å–PostgreSQLæ•°æ®åº“è¿æ¥"""
    try:
        conn = psycopg2.connect(**DB_CONFIG, cursor_factory=RealDictCursor)
        return conn
    except Exception as e:
        logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        raise

def test_db_connection():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) as count FROM oil_wells")
        result = cursor.fetchone()
        count = result['count']
        cursor.close()
        conn.close()
        logger.info(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼Œå…±æœ‰ {count} å£äº•")
        return True
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return False

# ==========================================
# è¾…åŠ©å·¥å…·å‡½æ•°
# ==========================================

def df_to_markdown(df: pd.DataFrame) -> str:
    """å°†DataFrameè½¬æ¢ä¸ºMarkdownè¡¨æ ¼"""
    if df.empty:
        return "æ— æ•°æ®"
    return df.to_markdown(index=False)

def normalize_well_id(well_id: str) -> str:
    """å½’ä¸€åŒ–äº•å·ï¼ˆå¤„ç†ä¸­æ–‡äº•å·å’Œå„ç§åˆ«åï¼‰"""
    # è¿™é‡Œæ ¹æ®å®é™…æ•°æ®è°ƒæ•´
    return well_id.strip()

def normalize_date(time_desc: str) -> str:
    """å½’ä¸€åŒ–æ—¥æœŸæè¿°ä¸ºISOæ ¼å¼"""
    today = date.today()
    
    if "ä»Šå¤©" in time_desc or "today" in time_desc.lower():
        return str(today)
    elif "æ˜¨å¤©" in time_desc or "yesterday" in time_desc.lower():
        return str(today - timedelta(days=1))
    elif "å‰å¤©" in time_desc:
        return str(today - timedelta(days=2))
    
    date_match = re.search(r'(\d{4})[å¹´\-/](\d{1,2})[æœˆ\-/](\d{1,2})', time_desc)
    if date_match:
        y, m, d = date_match.groups()
        return f"{y}-{int(m):02d}-{int(d):02d}"
    
    return time_desc

def parse_date_range(time_desc: str) -> tuple:
    """è§£ææ—¶é—´èŒƒå›´æè¿°"""
    today = date.today()
    
    if "æœ¬å‘¨" in time_desc or "this week" in time_desc.lower():
        start = today - timedelta(days=today.weekday())
        end = start + timedelta(days=6)
        return str(start), str(end)
    
    if "æœ¬æœˆ" in time_desc or "this month" in time_desc.lower():
        start = today.replace(day=1)
        if today.month == 12:
            end = date(today.year + 1, 1, 1) - timedelta(days=1)
        else:
            end = date(today.year, today.month + 1, 1) - timedelta(days=1)
        return str(start), str(end)
    
    if "ä¸Šæœˆ" in time_desc or "last month" in time_desc.lower():
        if today.month == 1:
            start = date(today.year - 1, 12, 1)
            end = date(today.year, 1, 1) - timedelta(days=1)
        else:
            start = date(today.year, today.month - 1, 1)
            end = today.replace(day=1) - timedelta(days=1)
        return str(start), str(end)
    
    match = re.search(r'(\d{4})[å¹´\-/](\d{1,2})', time_desc)
    if match:
        y, m = match.groups()
        y, m = int(y), int(m)
        start = date(y, m, 1)
        if m == 12:
            end = date(y + 1, 1, 1) - timedelta(days=1)
        else:
            end = date(y, m + 1, 1) - timedelta(days=1)
        return str(start), str(end)
    
    return str(today), str(today)

# ==========================================
# ç”¨æˆ·ä¸Šä¸‹æ–‡ç®¡ç†
# ==========================================

class UserContext(BaseModel):
    """ç”¨æˆ·ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    role: str = "GUEST"
    email: str = "unknown"
    user_id: str = "unknown"

# ä½¿ç”¨contextvarsæ¥å­˜å‚¨æ¯ä¸ªè¯·æ±‚çš„ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
from contextvars import ContextVar
current_user_context: ContextVar[UserContext] = ContextVar('current_user_context', default=UserContext())

def extract_user_context(
    x_user_role: Optional[str] = Header(None),
    x_user_email: Optional[str] = Header(None),
    x_user_id: Optional[str] = Header(None)
) -> UserContext:
    """ä»HTTPè¯·æ±‚å¤´ä¸­æå–ç”¨æˆ·ä¸Šä¸‹æ–‡"""
    role = x_user_role or "GUEST"
    email = x_user_email or "unknown"
    user_id = x_user_id or "unknown"
    
    logger.info("=" * 60)
    logger.info("ğŸ“‹ æå–ç”¨æˆ·ä¸Šä¸‹æ–‡")
    logger.info(f"  è§’è‰²: {role}")
    logger.info(f"  é‚®ç®±: {email}")
    logger.info(f"  ç”¨æˆ·ID: {user_id}")
    logger.info("=" * 60)
    
    return UserContext(role=role, email=email, user_id=user_id)

# ==========================================
# MCP Serverå®ä¾‹
# ==========================================

# åˆ›å»ºæ ‡å‡† MCP Server
mcp_server = Server("oilfield-drilling-true")

# åˆ›å»º SSE Transport
sse_transport = SseServerTransport("/sse")

# FastAPIåº”ç”¨
@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    logger.info("ğŸš€ æ²¹ç”°é’»äº•æ•°æ®MCP Server (çœŸå®æ•°æ®åº“) å¯åŠ¨ä¸­...")
    logger.info(f"ğŸ“ ç›‘å¬åœ°å€: http://0.0.0.0:8081")
    logger.info(f"ğŸ”’ æƒé™æ¨¡å¼: {'å¼€å‘æ¨¡å¼(è·³è¿‡æƒé™)' if DEV_MODE else 'ç”Ÿäº§æ¨¡å¼(ä¸¥æ ¼æƒé™)'}")
    logger.info(f"ğŸ—„ï¸  æ•°æ®åº“: PostgreSQL @ {DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}")
    
    # æµ‹è¯•æ•°æ®åº“è¿æ¥
    if test_db_connection():
        logger.info("âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸")
    else:
        logger.warning("âš ï¸  æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
    
    yield
    logger.info("ğŸ‘‹ MCP Server å…³é—­")

app = FastAPI(
    title="æ²¹ç”°é’»äº•æ•°æ®MCP Server (çœŸå®æ•°æ®)",
    description="åŸºäºHTTP/SSEçš„MCPæœåŠ¡å™¨ï¼Œè¿æ¥PostgreSQLçœŸå®æ•°æ®åº“",
    version="2.0.0-real",
    lifespan=lifespan
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============ å¥åº·æ£€æŸ¥ç«¯ç‚¹ ============

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "service": "æ²¹ç”°é’»äº•æ•°æ®MCP Server (çœŸå®æ•°æ®)",
        "version": "2.0.0-real",
        "status": "running",
        "database": f"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}"
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    db_ok = test_db_connection()
    return {
        "status": "healthy" if db_ok else "degraded",
        "database": "connected" if db_ok else "disconnected",
        "timestamp": datetime.now().isoformat()
    }

# ============ SSE Endpoint ============

@app.get("/sse")
async def handle_sse_get(request: Request):
    """SSE GET endpoint - å»ºç«‹SSEè¿æ¥"""
    logger.info("ğŸŒŠ SSE GETè¯·æ±‚ - å»ºç«‹è¿æ¥")
    
    try:
        return await sse_transport.connect_sse(request, mcp_server)
    except Exception as e:
        logger.error(f"âŒ SSE GETé”™è¯¯: {e}", exc_info=True)
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )

@app.head("/sse")
async def handle_sse_head():
    """SSE HEAD endpoint - æ£€æŸ¥æœåŠ¡å¯ç”¨æ€§"""
    return Response(status_code=200)

@app.post("/sse")
async def handle_sse_post(request: Request):
    """SSE POST endpoint - å¤„ç†JSON-RPCæ¶ˆæ¯ï¼ˆæ— çŠ¶æ€æ¨¡å¼ï¼‰"""
    session_id = request.query_params.get("sessionId") or request.query_params.get("session_id")
    
    # æå–ç”¨æˆ·ä¿¡æ¯
    user_role = request.headers.get("x-user-role", "GUEST")
    user_email = request.headers.get("x-user-email", "unknown")
    user_id = request.headers.get("x-user-id", "unknown")
    
    # è®¾ç½®å…¨å±€ç”¨æˆ·ä¸Šä¸‹æ–‡
    user_ctx = UserContext(role=user_role, email=user_email, user_id=user_id)
    current_user_context.set(user_ctx)
    
    logger.info(f"ğŸŒŠ SSE POSTè¯·æ±‚ - session_id: {session_id}")
    logger.info(f"ğŸ‘¤ ç”¨æˆ·ä¿¡æ¯: {user_email} ({user_role}) [ID: {user_id}]")
    
    try:
        # è¯»å–è¯·æ±‚ä½“
        body = await request.body()
        body_json = json.loads(body.decode())
        logger.info(f"ğŸ“ POSTè¯·æ±‚ä½“: {body_json}")
        
        # æ— çŠ¶æ€æ¨¡å¼ï¼šç›´æ¥å¤„ç† JSON-RPC è¯·æ±‚
        if not session_id:
            logger.info("ğŸ”§ æ— çŠ¶æ€æ¨¡å¼ - ç›´æ¥å¤„ç†JSON-RPCè¯·æ±‚")
            
            # å¤„ç† initialize è¯·æ±‚
            if body_json.get("method") == "initialize":
                response = {
                    "jsonrpc": "2.0",
                    "id": body_json.get("id"),
                    "result": {
                        "protocolVersion": "2024-11-05",
                        "capabilities": {
                            "tools": {},
                            "prompts": {},
                            "resources": {}
                        },
                        "serverInfo": {
                            "name": "oilfield-drilling-true",
                            "version": "2.0.0-real"
                        }
                    }
                }
                logger.info(f"âœ… Initializeå“åº”: {response}")
                return JSONResponse(content=response)
            
            # å¤„ç† initialized é€šçŸ¥
            elif body_json.get("method") == "notifications/initialized":
                logger.info("âœ… Initializedé€šçŸ¥å·²æ¥æ”¶")
                return JSONResponse(content={})
            
            # å¤„ç† tools/list è¯·æ±‚
            elif body_json.get("method") == "tools/list":
                # è¿”å›å·¥å…·åˆ—è¡¨
                tools_list = [
                    {
                        "name": "search_wells",
                        "description": "æœç´¢æ²¹äº•ä¿¡æ¯ï¼ˆçœŸå®æ•°æ®åº“ï¼‰ï¼Œæ”¯æŒæ‰¹é‡æœç´¢å¤šä¸ªå…³é”®è¯ã€åŒºå—ã€‚ğŸ’¡é‡è¦ï¼šæŸ¥è¯¢æ‰€æœ‰æ²¹äº•æ—¶ï¼Œå°†keywordè®¾ä¸ºç©ºå­—ç¬¦ä¸²''æˆ–ä¸ä¼ é€’keywordå‚æ•°å³å¯ã€‚",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "keywords": {"type": "array", "items": {"type": "string"}, "description": "æœç´¢å…³é”®è¯åˆ—è¡¨ï¼ˆäº•å·ã€åŒºå—ç­‰ï¼‰ã€‚ç•™ç©ºè¿”å›æ‰€æœ‰æ²¹äº•"},
                                "keyword": {"type": "string", "description": "å•ä¸ªæœç´¢å…³é”®è¯ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰ã€‚ç©ºå­—ç¬¦ä¸²''è¿”å›æ‰€æœ‰æ²¹äº•"},
                                "limit": {"type": "integer", "default": 500, "description": "è¿”å›ç»“æœæ•°é‡é™åˆ¶ï¼ˆé»˜è®¤500ï¼Œæœ€å¤§10000ï¼‰"}
                            },
                            "required": []
                        }
                    },
                    {
                        "name": "get_well_details",
                        "description": "è·å–å•äº•æˆ–å¤šäº•è¯¦ç»†ä¿¡æ¯ï¼ˆçœŸå®æ•°æ®ï¼‰ï¼ŒåŒ…æ‹¬æ‰€æœ‰å­—æ®µ",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "well_ids": {"type": "array", "items": {"type": "string"}, "description": "äº•ååˆ—è¡¨"},
                                "well_id": {"type": "string", "description": "å•ä¸ªäº•åï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"}
                            },
                            "required": []
                        }
                    },
                    {
                        "name": "get_wells_by_block",
                        "description": "æŒ‰åŒºå—æŸ¥è¯¢æ²¹äº•ï¼ˆçœŸå®æ•°æ®ï¼‰",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "block": {"type": "string", "description": "åŒºå—åç§°"},
                                "limit": {"type": "integer", "default": 50}
                            },
                            "required": ["block"]
                        }
                    },
                    {
                        "name": "get_wells_by_project",
                        "description": "æŒ‰é¡¹ç›®æŸ¥è¯¢æ²¹äº•ï¼ˆçœŸå®æ•°æ®ï¼‰",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "project": {"type": "string", "description": "é¡¹ç›®åç§°ï¼ˆktxmå­—æ®µï¼‰"},
                                "limit": {"type": "integer", "default": 50}
                            },
                            "required": ["project"]
                        }
                    },
                    {
                        "name": "get_statistics",
                        "description": "è·å–æ²¹äº•ç»Ÿè®¡ä¿¡æ¯ï¼ˆçœŸå®æ•°æ®ï¼‰",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "group_by": {"type": "string", "enum": ["block", "project", "well_type"], "default": "block"}
                            },
                            "required": []
                        }
                    },
                    {
                        "name": "get_drilling_daily",
                        "description": "æŸ¥è¯¢é’»äº•å·¥ç¨‹æ—¥æŠ¥æ•°æ® - æ”¯æŒæŒ‰äº•å·ã€æ—¥æœŸèŒƒå›´æŸ¥è¯¢",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "well_id": {"type": "string", "description": "äº•å·"},
                                "start_date": {"type": "string", "description": "å¼€å§‹æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰"},
                                "end_date": {"type": "string", "description": "ç»“æŸæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰"},
                                "limit": {"type": "integer", "default": 100, "description": "è¿”å›ç»“æœæ•°é‡é™åˆ¶"}
                            },
                            "required": []
                        }
                    },
                    {
                        "name": "get_drilling_pre_daily",
                        "description": "æŸ¥è¯¢é’»å‰å·¥ç¨‹æ—¥æŠ¥æ•°æ® - æ”¯æŒæŒ‰é¡¹ç›®ã€å¹´åº¦ã€äº•å·æŸ¥è¯¢",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "project": {"type": "string", "description": "å‹˜æ¢é¡¹ç›®"},
                                "year": {"type": "integer", "description": "å®æ–½å¹´åº¦"},
                                "well_id": {"type": "string", "description": "äº•å·"},
                                "limit": {"type": "integer", "default": 50, "description": "è¿”å›ç»“æœæ•°é‡é™åˆ¶"}
                            },
                            "required": []
                        }
                    },
                    {
                        "name": "get_key_well_daily",
                        "description": "æŸ¥è¯¢é‡ç‚¹äº•è¯•é‡‡æ—¥æŠ¥æ•°æ® - æ”¯æŒæŒ‰äº•å·ã€æ—¥æœŸèŒƒå›´ã€åŒºå—æŸ¥è¯¢ï¼ŒåŒ…æ‹¬ç”Ÿäº§æ•°æ®å’Œå‹åŠ›å‚æ•°",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "well_id": {"type": "string", "description": "äº•å·"},
                                "start_date": {"type": "string", "description": "å¼€å§‹æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰"},
                                "end_date": {"type": "string", "description": "ç»“æŸæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰"},
                                "block": {"type": "string", "description": "åŒºå—"},
                                "limit": {"type": "integer", "default": 100, "description": "è¿”å›ç»“æœæ•°é‡é™åˆ¶"}
                            },
                            "required": []
                        }
                    }
                ]
                
                response = {
                    "jsonrpc": "2.0",
                    "id": body_json.get("id"),
                    "result": {
                        "tools": tools_list
                    }
                }
                logger.info(f"âœ… Toolsåˆ—è¡¨å“åº”: {len(tools_list)} ä¸ªå·¥å…·")
                return JSONResponse(content=response)
            
            # å¤„ç† tools/call è¯·æ±‚
            elif body_json.get("method") == "tools/call":
                params = body_json.get("params", {})
                tool_name = params.get("name")
                tool_args = params.get("arguments", {})
                
                logger.info(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}, å‚æ•°: {tool_args}")
                logger.info(f"ğŸ‘¤ è°ƒç”¨ç”¨æˆ·: {user_email} ({user_role})")
                
                # è°ƒç”¨å¯¹åº”çš„ä¸šåŠ¡é€»è¾‘å‡½æ•°
                try:
                    result_text = None
                    
                    if tool_name == "search_wells":
                        result_text = search_wells(
                            keywords=tool_args.get('keywords'),
                            keyword=tool_args.get('keyword', ''),
                            limit=tool_args.get('limit', 500),
                            user_role=user_role,
                            user_id=user_id,
                            user_email=user_email
                        )
                    elif tool_name == "get_well_details":
                        result_text = get_well_details(
                            well_ids=tool_args.get('well_ids'),
                            well_id=tool_args.get('well_id', ''),
                            user_role=user_role,
                            user_id=user_id,
                            user_email=user_email
                        )
                    elif tool_name == "get_wells_by_block":
                        result_text = get_wells_by_block(
                            block=tool_args.get('block', ''),
                            limit=tool_args.get('limit', 50),
                            user_role=user_role,
                            user_id=user_id,
                            user_email=user_email
                        )
                    elif tool_name == "get_wells_by_project":
                        result_text = get_wells_by_project(
                            project=tool_args.get('project', ''),
                            limit=tool_args.get('limit', 50),
                            user_role=user_role,
                            user_id=user_id,
                            user_email=user_email
                        )
                    elif tool_name == "get_statistics":
                        result_text = get_statistics(
                            group_by=tool_args.get('group_by', 'block'),
                            user_role=user_role,
                            user_id=user_id,
                            user_email=user_email
                        )
                    elif tool_name == "get_drilling_daily":
                        result_text = get_drilling_daily(
                            well_id=tool_args.get('well_id', ''),
                            start_date=tool_args.get('start_date', ''),
                            end_date=tool_args.get('end_date', ''),
                            limit=tool_args.get('limit', 100),
                            user_role=user_role,
                            user_id=user_id,
                            user_email=user_email
                        )
                    elif tool_name == "get_drilling_pre_daily":
                        result_text = get_drilling_pre_daily(
                            project=tool_args.get('project', ''),
                            year=tool_args.get('year'),
                            well_id=tool_args.get('well_id', ''),
                            limit=tool_args.get('limit', 50),
                            user_role=user_role,
                            user_id=user_id,
                            user_email=user_email
                        )
                    elif tool_name == "get_key_well_daily":
                        result_text = get_key_well_daily(
                            well_id=tool_args.get('well_id', ''),
                            start_date=tool_args.get('start_date', ''),
                            end_date=tool_args.get('end_date', ''),
                            block=tool_args.get('block', ''),
                            limit=tool_args.get('limit', 100),
                            user_role=user_role,
                            user_id=user_id,
                            user_email=user_email
                        )
                    else:
                        raise ValueError(f"æœªçŸ¥å·¥å…·: {tool_name}")
                    
                    response = {
                        "jsonrpc": "2.0",
                        "id": body_json.get("id"),
                        "result": {
                            "content": [
                                {
                                    "type": "text",
                                    "text": result_text
                                }
                            ]
                        }
                    }
                    logger.info(f"âœ… å·¥å…·è°ƒç”¨æˆåŠŸ: {tool_name}")
                    return JSONResponse(content=response)
                    
                except Exception as tool_error:
                    logger.error(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {tool_error}", exc_info=True)
                    response = {
                        "jsonrpc": "2.0",
                        "id": body_json.get("id"),
                        "error": {
                            "code": -32603,
                            "message": str(tool_error)
                        }
                    }
                    return JSONResponse(content=response)
            
            # æœªçŸ¥æ–¹æ³•
            else:
                response = {
                    "jsonrpc": "2.0",
                    "id": body_json.get("id"),
                    "error": {
                        "code": -32601,
                        "message": f"Method not found: {body_json.get('method')}"
                    }
                }
                return JSONResponse(content=response)
        
        # æœ‰ session_id çš„æƒ…å†µï¼Œä½¿ç”¨æ ‡å‡† SSE transport
        else:
            logger.info(f"ğŸ”— æœ‰çŠ¶æ€æ¨¡å¼ - ä½¿ç”¨session: {session_id}")
            response_data = {}
            response_status = 200
            
            async def receive():
                return {
                    "type": "http.request",
                    "body": body,
                    "more_body": False
                }
            
            async def send(message):
                nonlocal response_data, response_status
                if message["type"] == "http.response.start":
                    response_status = message.get("status", 200)
                elif message["type"] == "http.response.body":
                    body = message.get("body", b"")
                    if body:
                        try:
                            response_data = json.loads(body.decode())
                        except:
                            response_data = {"body": body.decode()}
            
            await sse_transport.handle_post_message(
                request.scope,
                receive,
                send
            )
            
            return JSONResponse(
                status_code=response_status,
                content=response_data if response_data else {"jsonrpc": "2.0", "result": {}}
            )
            
    except json.JSONDecodeError as e:
        logger.error(f"âŒ JSONè§£æé”™è¯¯: {e}")
        return JSONResponse(
            status_code=400,
            content={
                "jsonrpc": "2.0",
                "error": {
                    "code": -32700,
                    "message": "Parse error"
                }
            }
        )
    except Exception as e:
        logger.error(f"âŒ SSE POSTé”™è¯¯: {e}", exc_info=True)
        return JSONResponse(
            status_code=500,
            content={
                "jsonrpc": "2.0",
                "error": {
                    "code": -32603,
                    "message": str(e)
                }
            }
        )

# ==========================================
# MCP Server Handlers
# ==========================================

@mcp_server.list_tools()
async def handle_list_tools():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å·¥å…·"""
    return [
        Tool(
            name="search_wells",
            description="æœç´¢æ²¹äº•ï¼ˆçœŸå®æ•°æ®åº“ï¼‰ï¼Œæ”¯æŒæ‰¹é‡æœç´¢ã€‚ğŸ’¡é‡è¦ï¼šæŸ¥è¯¢æ‰€æœ‰æ²¹äº•æ—¶ï¼Œå°†keywordè®¾ä¸ºç©ºå­—ç¬¦ä¸²''æˆ–ä¸ä¼ é€’keywordå‚æ•°å³å¯ã€‚",
            inputSchema={
                "type": "object",
                "properties": {
                    "keywords": {"type": "array", "items": {"type": "string"}, "description": "æœç´¢å…³é”®è¯åˆ—è¡¨ã€‚ç•™ç©ºå¯è¿”å›æ‰€æœ‰æ²¹äº•"},
                    "keyword": {"type": "string", "description": "å•ä¸ªæœç´¢å…³é”®è¯ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰ã€‚è®¾ä¸ºç©ºå­—ç¬¦ä¸²''å¯è¿”å›æ‰€æœ‰æ²¹äº•"},
                    "limit": {"type": "integer", "default": 500, "description": "è¿”å›ç»“æœæ•°é‡é™åˆ¶ï¼ˆé»˜è®¤500ï¼Œæœ€å¤§10000ï¼‰"}
                },
                "required": []
            }
        ),
        Tool(
            name="get_well_details",
            description="è·å–å•äº•æˆ–å¤šäº•è¯¦ç»†ä¿¡æ¯ï¼ˆçœŸå®æ•°æ®ï¼‰ï¼ŒåŒ…æ‹¬æ‰€æœ‰å­—æ®µ",
            inputSchema={
                "type": "object",
                "properties": {
                    "well_ids": {"type": "array", "items": {"type": "string"}, "description": "äº•ååˆ—è¡¨"},
                    "well_id": {"type": "string", "description": "å•ä¸ªäº•åï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"}
                },
                "required": []
            }
        ),
        Tool(
            name="get_wells_by_block",
            description="æŒ‰åŒºå—æŸ¥è¯¢æ²¹äº•ï¼ˆçœŸå®æ•°æ®ï¼‰",
            inputSchema={
                "type": "object",
                "properties": {
                    "block": {"type": "string", "description": "åŒºå—åç§°"},
                    "limit": {"type": "integer", "default": 50}
                },
                "required": ["block"]
            }
        ),
        Tool(
            name="get_wells_by_project",
            description="æŒ‰é¡¹ç›®æŸ¥è¯¢æ²¹äº•ï¼ˆçœŸå®æ•°æ®ï¼‰",
            inputSchema={
                "type": "object",
                "properties": {
                    "project": {"type": "string", "description": "é¡¹ç›®åç§°ï¼ˆktxmå­—æ®µï¼‰"},
                    "limit": {"type": "integer", "default": 50}
                },
                "required": ["project"]
            }
        ),
        Tool(
            name="get_statistics",
            description="è·å–æ²¹äº•ç»Ÿè®¡ä¿¡æ¯ï¼ˆçœŸå®æ•°æ®ï¼‰",
            inputSchema={
                "type": "object",
                "properties": {
                    "group_by": {"type": "string", "enum": ["block", "project", "well_type"], "default": "block"}
                },
                "required": []
            }
        ),
        Tool(
            name="get_drilling_daily",
            description="æŸ¥è¯¢é’»äº•å·¥ç¨‹æ—¥æŠ¥æ•°æ® - æ”¯æŒæŒ‰äº•å·ã€æ—¥æœŸèŒƒå›´æŸ¥è¯¢",
            inputSchema={
                "type": "object",
                "properties": {
                    "well_id": {"type": "string", "description": "äº•å·"},
                    "start_date": {"type": "string", "description": "å¼€å§‹æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰"},
                    "end_date": {"type": "string", "description": "ç»“æŸæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰"},
                    "limit": {"type": "integer", "default": 100, "description": "è¿”å›ç»“æœæ•°é‡é™åˆ¶"}
                },
                "required": []
            }
        ),
        Tool(
            name="get_drilling_pre_daily",
            description="æŸ¥è¯¢é’»å‰å·¥ç¨‹æ—¥æŠ¥æ•°æ® - æ”¯æŒæŒ‰é¡¹ç›®ã€å¹´åº¦ã€äº•å·æŸ¥è¯¢",
            inputSchema={
                "type": "object",
                "properties": {
                    "project": {"type": "string", "description": "å‹˜æ¢é¡¹ç›®"},
                    "year": {"type": "integer", "description": "å®æ–½å¹´åº¦"},
                    "well_id": {"type": "string", "description": "äº•å·"},
                    "limit": {"type": "integer", "default": 50, "description": "è¿”å›ç»“æœæ•°é‡é™åˆ¶"}
                },
                "required": []
            }
        ),
        Tool(
            name="get_key_well_daily",
            description="æŸ¥è¯¢é‡ç‚¹äº•è¯•é‡‡æ—¥æŠ¥æ•°æ® - æ”¯æŒæŒ‰äº•å·ã€æ—¥æœŸèŒƒå›´ã€åŒºå—æŸ¥è¯¢ï¼ŒåŒ…æ‹¬ç”Ÿäº§æ•°æ®å’Œå‹åŠ›å‚æ•°",
            inputSchema={
                "type": "object",
                "properties": {
                    "well_id": {"type": "string", "description": "äº•å·"},
                    "start_date": {"type": "string", "description": "å¼€å§‹æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰"},
                    "end_date": {"type": "string", "description": "ç»“æŸæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰"},
                    "block": {"type": "string", "description": "åŒºå—"},
                    "limit": {"type": "integer", "default": 100, "description": "è¿”å›ç»“æœæ•°é‡é™åˆ¶"}
                },
                "required": []
            }
        )
    ]

@mcp_server.call_tool()
async def handle_call_tool(name: str, arguments: dict):
    """å¤„ç†å·¥å…·è°ƒç”¨"""
    logger.info(f"ğŸ”§ MCPå·¥å…·è°ƒç”¨: {name}")
    logger.debug(f"ğŸ“ å‚æ•°: {json.dumps(arguments, ensure_ascii=False)}")
    
    # ä»ContextVarè·å–ç”¨æˆ·ä¸Šä¸‹æ–‡
    user_ctx = current_user_context.get()
    user_role = user_ctx.role
    user_id = user_ctx.user_id
    user_email = user_ctx.email
    
    logger.info(f"ğŸ‘¤ è°ƒç”¨ç”¨æˆ·: {user_email} ({user_role})")
    
    try:
        result = None
        
        if name == "search_wells":
            result = search_wells(
                keywords=arguments.get('keywords'),
                keyword=arguments.get('keyword', ''),
                limit=arguments.get('limit', 500),
                user_role=user_role,
                user_id=user_id,
                user_email=user_email
            )
        elif name == "get_well_details":
            result = get_well_details(
                well_ids=arguments.get('well_ids'),
                well_id=arguments.get('well_id', ''),
                user_role=user_role,
                user_id=user_id,
                user_email=user_email
            )
        elif name == "get_wells_by_block":
            result = get_wells_by_block(
                block=arguments.get('block', ''),
                limit=arguments.get('limit', 50),
                user_role=user_role,
                user_id=user_id,
                user_email=user_email
            )
        elif name == "get_wells_by_project":
            result = get_wells_by_project(
                project=arguments.get('project', ''),
                limit=arguments.get('limit', 50),
                user_role=user_role,
                user_id=user_id,
                user_email=user_email
            )
        elif name == "get_statistics":
            result = get_statistics(
                group_by=arguments.get('group_by', 'block'),
                user_role=user_role,
                user_id=user_id,
                user_email=user_email
            )
        elif name == "get_drilling_daily":
            result = get_drilling_daily(
                well_id=arguments.get('well_id', ''),
                start_date=arguments.get('start_date', ''),
                end_date=arguments.get('end_date', ''),
                limit=arguments.get('limit', 100),
                user_role=user_role,
                user_id=user_id,
                user_email=user_email
            )
        elif name == "get_drilling_pre_daily":
            result = get_drilling_pre_daily(
                project=arguments.get('project', ''),
                year=arguments.get('year'),
                well_id=arguments.get('well_id', ''),
                limit=arguments.get('limit', 50),
                user_role=user_role,
                user_id=user_id,
                user_email=user_email
            )
        elif name == "get_key_well_daily":
            result = get_key_well_daily(
                well_id=arguments.get('well_id', ''),
                start_date=arguments.get('start_date', ''),
                end_date=arguments.get('end_date', ''),
                block=arguments.get('block', ''),
                limit=arguments.get('limit', 100),
                user_role=user_role,
                user_id=user_id,
                user_email=user_email
            )
        else:
            raise ValueError(f"æœªçŸ¥å·¥å…·: {name}")
        
        logger.info(f"âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ: {name}")
        return [TextContent(type="text", text=result)]
        
    except Exception as e:
        logger.error(f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {name} - {str(e)}")
        return [TextContent(type="text", text=f"âš ï¸ æ‰§è¡Œé”™è¯¯: {str(e)}")]

# ==========================================
# ä¸šåŠ¡é€»è¾‘å‡½æ•°ï¼ˆçœŸå®æ•°æ®åº“æŸ¥è¯¢ï¼‰
# ==========================================

@AuditLog.trace("search_wells")
def search_wells(keywords: List[str] = None, keyword: str = None, limit: int = 500, user_role: str = "GUEST", user_id: str = "unknown", user_email: str = "unknown") -> str:
    """æœç´¢æ²¹äº• - çœŸå®æ•°æ®åº“"""
    # å…¼å®¹æ—§æ¥å£
    if keywords is None:
        if keyword:
            keywords = [keyword]
        else:
            keywords = []
    
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        # åˆ¤æ–­æ˜¯å¦ä¸º"æŸ¥è¯¢æ‰€æœ‰"ï¼ˆæ— å…³é”®è¯æˆ–ç©ºå…³é”®è¯ï¼‰
        is_query_all = not keywords or (len(keywords) == 1 and not keywords[0])
        
        # å¦‚æœæ˜¯æŸ¥è¯¢æ‰€æœ‰ï¼Œå…ˆæ£€æŸ¥æ€»æ•°
        if is_query_all:
            cursor.execute("SELECT COUNT(*) as count FROM oil_wells WHERE is_deleted = false")
            total_count = cursor.fetchone()['count']
            
            # å¦‚æœæ€»æ•°è¶…è¿‡200ï¼Œè¿”å›ç»Ÿè®¡æ‘˜è¦è€Œä¸æ˜¯è¯¦ç»†åˆ—è¡¨
            if total_count > 200:
                logger.info(f"ğŸ“Š æ•°æ®é‡è¾ƒå¤§({total_count}å£äº•)ï¼Œè¿”å›ç»Ÿè®¡æ‘˜è¦")
                
                # 1. æŒ‰åŒºå—ç»Ÿè®¡
                cursor.execute("""
                    SELECT qk, COUNT(*) as count, AVG(sjjs) as avg_depth
                    FROM oil_wells 
                    WHERE is_deleted = false AND qk IS NOT NULL AND qk != ''
                    GROUP BY qk
                    ORDER BY count DESC
                    LIMIT 10
                """)
                block_stats = cursor.fetchall()
                
                # 2. æŒ‰é¡¹ç›®ç»Ÿè®¡
                cursor.execute("""
                    SELECT ktxm, COUNT(*) as count
                    FROM oil_wells 
                    WHERE is_deleted = false AND ktxm IS NOT NULL AND ktxm != ''
                    GROUP BY ktxm
                    ORDER BY count DESC
                    LIMIT 10
                """)
                project_stats = cursor.fetchall()
                
                # 3. æŒ‰äº•å‹ç»Ÿè®¡
                cursor.execute("""
                    SELECT jx, COUNT(*) as count
                    FROM oil_wells 
                    WHERE is_deleted = false AND jx IS NOT NULL AND jx != ''
                    GROUP BY jx
                    ORDER BY count DESC
                """)
                well_type_stats = cursor.fetchall()
                
                # 4. æŒ‰å¹´ä»½ç»Ÿè®¡
                cursor.execute("""
                    SELECT EXTRACT(YEAR FROM sjrq) as year, COUNT(*) as count
                    FROM oil_wells 
                    WHERE is_deleted = false AND sjrq IS NOT NULL
                    GROUP BY EXTRACT(YEAR FROM sjrq)
                    ORDER BY year DESC
                    LIMIT 10
                """)
                year_stats = cursor.fetchall()
                
                # æ„å»ºç»Ÿè®¡æŠ¥å‘Š
                report = f"""### ğŸ“Š æ²¹äº•æ•°æ®ç»Ÿè®¡æ‘˜è¦

**ğŸ’¡ æç¤º**ï¼šç”±äºæ•°æ®é‡è¾ƒå¤§ï¼ˆå…± **{total_count}** å£äº•ï¼‰ï¼Œä¸ºæé«˜æŸ¥è¯¢æ•ˆç‡ï¼Œè¿™é‡Œå±•ç¤ºç»Ÿè®¡æ‘˜è¦ã€‚å¦‚éœ€æŸ¥çœ‹è¯¦ç»†åˆ—è¡¨ï¼Œè¯·ä½¿ç”¨æ›´å…·ä½“çš„æŸ¥è¯¢æ¡ä»¶ï¼ˆå¦‚æŒ‡å®šåŒºå—ã€é¡¹ç›®æˆ–äº•å·ï¼‰ã€‚

---

#### ğŸ“ˆ æ€»ä½“æ¦‚å†µ
- **æ€»äº•æ•°**ï¼š{total_count} å£
- **æ•°æ®å®Œæ•´æ€§**ï¼š{len(block_stats)} ä¸ªåŒºå—ï¼Œ{len(project_stats)} ä¸ªé¡¹ç›®

---

#### ğŸ—ºï¸ åŒºå—åˆ†å¸ƒï¼ˆå‰10åï¼‰

"""
                if block_stats:
                    block_data = []
                    for row in block_stats:
                        block_data.append({
                            "åŒºå—": row['qk'],
                            "äº•æ•°": row['count'],
                            "å¹³å‡äº•æ·±(m)": round(float(row['avg_depth']), 2) if row['avg_depth'] else 0
                        })
                    report += df_to_markdown(pd.DataFrame(block_data)) + "\n\n"
                else:
                    report += "æ— åŒºå—æ•°æ®\n\n"
                
                report += "---\n\n#### ğŸ“‹ é¡¹ç›®åˆ†å¸ƒï¼ˆå‰10åï¼‰\n\n"
                if project_stats:
                    project_data = []
                    for row in project_stats:
                        project_data.append({
                            "é¡¹ç›®åç§°": row['ktxm'],
                            "äº•æ•°": row['count']
                        })
                    report += df_to_markdown(pd.DataFrame(project_data)) + "\n\n"
                else:
                    report += "æ— é¡¹ç›®æ•°æ®\n\n"
                
                report += "---\n\n#### ğŸ”§ äº•å‹åˆ†å¸ƒ\n\n"
                if well_type_stats:
                    well_type_data = []
                    for row in well_type_stats:
                        well_type_data.append({
                            "äº•å‹": row['jx'],
                            "äº•æ•°": row['count'],
                            "å æ¯”": f"{round(row['count']/total_count*100, 1)}%"
                        })
                    report += df_to_markdown(pd.DataFrame(well_type_data)) + "\n\n"
                else:
                    report += "æ— äº•å‹æ•°æ®\n\n"
                
                report += "---\n\n#### ğŸ“… å¹´ä»½åˆ†å¸ƒï¼ˆå‰10å¹´ï¼‰\n\n"
                if year_stats:
                    year_data = []
                    for row in year_stats:
                        year_data.append({
                            "å¹´ä»½": int(row['year']) if row['year'] else 'æœªçŸ¥',
                            "äº•æ•°": row['count']
                        })
                    report += df_to_markdown(pd.DataFrame(year_data)) + "\n\n"
                else:
                    report += "æ— å¹´ä»½æ•°æ®\n\n"
                
                report += """---

#### ğŸ’¡ æŸ¥è¯¢å»ºè®®

å¦‚éœ€æŸ¥çœ‹è¯¦ç»†äº•åˆ—è¡¨ï¼Œè¯·å°è¯•ï¼š
- **æŒ‰åŒºå—æŸ¥è¯¢**ï¼šä½¿ç”¨ `get_wells_by_block` å·¥å…·
- **æŒ‰é¡¹ç›®æŸ¥è¯¢**ï¼šä½¿ç”¨ `get_wells_by_project` å·¥å…·
- **æŒ‰äº•å·æœç´¢**ï¼šä½¿ç”¨ `search_wells` å¹¶æŒ‡å®šäº•å·å…³é”®è¯
- **æŸ¥çœ‹è¯¦æƒ…**ï¼šä½¿ç”¨ `get_well_details` æŸ¥è¯¢ç‰¹å®šäº•çš„å®Œæ•´ä¿¡æ¯
"""
                
                return report
        
        # æ­£å¸¸æŸ¥è¯¢æµç¨‹ï¼ˆæœ‰å…³é”®è¯æˆ–æ€»æ•°â‰¤200ï¼‰
        if is_query_all:
            query = f"""
                SELECT well_name, qk, jx, sjjs, sjrq, ktxm
                FROM oil_wells 
                WHERE is_deleted = false
                ORDER BY created_at DESC
                LIMIT %s
            """
            cursor.execute(query, (limit,))
        else:
            # æœ‰å…³é”®è¯çš„æœç´¢
            conditions = []
            params = []
            
            for kw in keywords:
                if not kw:
                    continue
                conditions.append("""
                    (well_name ILIKE %s OR qk ILIKE %s OR ktxm ILIKE %s)
                """)
                like_pattern = f"%{kw}%"
                params.extend([like_pattern, like_pattern, like_pattern])
            
            if not conditions:
                # æ‰€æœ‰å…³é”®è¯éƒ½æ˜¯ç©ºçš„ï¼ŒæŒ‰æŸ¥è¯¢æ‰€æœ‰å¤„ç†
                query = f"""
                    SELECT well_name, qk, jx, sjjs, sjrq, ktxm
                    FROM oil_wells 
                    WHERE is_deleted = false
                    ORDER BY created_at DESC
                    LIMIT %s
                """
                cursor.execute(query, (limit,))
            else:
                query = f"""
                    SELECT well_name, qk, jx, sjjs, sjrq, ktxm
                    FROM oil_wells 
                    WHERE is_deleted = false AND ({' OR '.join(conditions)})
                    ORDER BY created_at DESC
                    LIMIT %s
                """
                params.append(limit)
                cursor.execute(query, params)
        
        results = cursor.fetchall()
        
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        wells = [dict(row) for row in results]
        
        # æƒé™è¿‡æ»¤
        wells = filter_wells_by_permission(wells, user_role, user_id, user_email)
        
        if not wells:
            keywords_str = "ã€".join([k for k in keywords if k]) if keywords else "å…¨éƒ¨"
            return f"æœªæ‰¾åˆ°åŒ¹é…å…³é”®è¯ '{keywords_str}' çš„äº•ã€‚"
        
        # æ ¼å¼åŒ–è¾“å‡º
        data = []
        for w in wells:
            data.append({
                "äº•å": w.get('well_name', ''),
                "åŒºå—": w.get('qk', ''),
                "äº•å‹": w.get('jx', ''),
                "è®¾è®¡äº•æ·±(m)": float(w.get('sjjs', 0)) if w.get('sjjs') else 0,
                "è®¾è®¡æ—¥æœŸ": str(w.get('sjrq', '')) if w.get('sjrq') else '',
                "é¡¹ç›®": w.get('ktxm', '')
            })
        
        keywords_str = "ã€".join([k for k in keywords if k]) if keywords else "å…¨éƒ¨"
        return f"### ğŸ” æœç´¢ç»“æœï¼ˆå…³é”®è¯ï¼š{keywords_str}ï¼Œå…± {len(wells)} å£äº•ï¼‰\n\n{df_to_markdown(pd.DataFrame(data))}"
    
    finally:
        cursor.close()
        conn.close()

@AuditLog.trace("get_well_details")
def get_well_details(well_ids: List[str] = None, well_id: str = None, user_role: str = "GUEST", user_id: str = "unknown", user_email: str = "unknown") -> str:
    """è·å–äº•è¯¦ç»†ä¿¡æ¯ - çœŸå®æ•°æ®åº“"""
    # å…¼å®¹æ—§æ¥å£
    if well_ids is None:
        if well_id:
            well_ids = [well_id]
        else:
            return "âŒ è¯·æä¾›äº•å"
    
    well_ids = [normalize_well_id(wid) for wid in well_ids]
    
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        results = []
        
        for wid in well_ids:
            query = """
                SELECT * FROM oil_wells 
                WHERE well_name = %s AND is_deleted = false
            """
            cursor.execute(query, (wid,))
            result = cursor.fetchone()
            
            if not result:
                results.append(f"âŒ æœªæ‰¾åˆ°äº•å: {wid}")
                continue
            
            well = dict(result)
            
            # æƒé™æ£€æŸ¥
            filtered = filter_wells_by_permission([well], user_role, user_id, user_email)
            if not filtered:
                results.append(f"ğŸš« æƒé™æ‹’ç»ï¼šæ— æƒè®¿é—®äº•å {wid}ã€‚")
                continue
            
            # æ ¼å¼åŒ–è¾“å‡º
            well_info = f"""
### ğŸ­ äº•è¯¦ç»†ä¿¡æ¯ï¼š{well.get('well_name', '')}

#### åŸºæœ¬ä¿¡æ¯
- **äº•å**: {well.get('well_name', '')}
- **åŒºå—**: {well.get('qk', '')}
- **åŒºå—ä»£ç **: {well.get('qkdm', '')}
- **äº•å‹**: {well.get('jx', '')}
- **äº•åˆ«**: {well.get('jb', '')}
- **å±‚ä½**: {well.get('cw', '')}

#### é¡¹ç›®ä¿¡æ¯
- **å‹˜æ¢é¡¹ç›®ç±»åˆ«**: {well.get('ktxmlb', '')}
- **å‹˜æ¢é¡¹ç›®**: {well.get('ktxm', '')}
- **å‹˜æ¢å­é¡¹ç›®**: {well.get('ktzxm', '')}

#### è®¾è®¡å‚æ•°
- **è®¾è®¡æ—¥æœŸ**: {well.get('sjrq', '')}
- **è®¾è®¡äº•æ·±**: {well.get('sjjs', '')} ç±³
- **è®¾è®¡é’»è‡³æ ‡é«˜**: {well.get('sjzzbx', '')}
- **è®¾è®¡æµ·æ‹”æ ‡é«˜**: {well.get('sjhzby', '')}
- **è®¾è®¡ç›®çš„å±‚**: {well.get('sjmdc', '')}
- **è®¾è®¡å®Œé’»å±‚ä½**: {well.get('sjwzcw', '')}

#### é’»æ¢ä¿¡æ¯
- **é’»æ¢ç›®çš„**: {well.get('ztmd', '')}
- **å®Œé’»åŸåˆ™**: {well.get('wzyz', '')}

#### åœ°ç†ä½ç½®
- **åœ°è²Œæµ·æ‹”**: {well.get('dmhb', '')}
- **æ‰€åœ¨çœå¸‚**: {well.get('ss', '')}
- **å®æœ‰ä½ç½®**: {well.get('sywz', '')}

#### å…¶ä»–ä¿¡æ¯
- **åˆåŒæœŸå·**: {well.get('htqh', '')}
- **æ“ä½œäºº**: {well.get('czr', '')}
- **å½•å…¥äºº**: {well.get('lrr', '')}
- **å¤‡æ³¨**: {well.get('bz', '')}
"""
            results.append(well_info)
        
        if len(results) == 1:
            return results[0]
        else:
            return "\n\n---\n\n".join(results)
    
    finally:
        cursor.close()
        conn.close()

@AuditLog.trace("get_wells_by_block")
def get_wells_by_block(block: str, limit: int = 50, user_role: str = "GUEST", user_id: str = "unknown", user_email: str = "unknown") -> str:
    """æŒ‰åŒºå—æŸ¥è¯¢æ²¹äº• - çœŸå®æ•°æ®åº“"""
    if not block:
        return "âŒ è¯·æä¾›åŒºå—åç§°"
    
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        query = """
            SELECT well_name, qk, jx, sjjs, sjrq, ktxm
            FROM oil_wells 
            WHERE qk ILIKE %s AND is_deleted = false
            ORDER BY created_at DESC
            LIMIT %s
        """
        cursor.execute(query, (f"%{block}%", limit))
        results = cursor.fetchall()
        
        wells = [dict(row) for row in results]
        
        # æƒé™è¿‡æ»¤
        wells = filter_wells_by_permission(wells, user_role, user_id, user_email)
        
        if not wells:
            return f"æœªæ‰¾åˆ°åŒºå— '{block}' çš„æ²¹äº•ã€‚"
        
        data = []
        for w in wells:
            data.append({
                "äº•å": w.get('well_name', ''),
                "åŒºå—": w.get('qk', ''),
                "äº•å‹": w.get('jx', ''),
                "è®¾è®¡äº•æ·±(m)": float(w.get('sjjs', 0)) if w.get('sjjs') else 0,
                "è®¾è®¡æ—¥æœŸ": str(w.get('sjrq', '')) if w.get('sjrq') else '',
                "é¡¹ç›®": w.get('ktxm', '')
            })
        
        return f"### ğŸ” åŒºå— '{block}' çš„æ²¹äº•ï¼ˆå…± {len(wells)} å£ï¼‰\n\n{df_to_markdown(pd.DataFrame(data))}"
    
    finally:
        cursor.close()
        conn.close()

@AuditLog.trace("get_wells_by_project")
def get_wells_by_project(project: str, limit: int = 50, user_role: str = "GUEST", user_id: str = "unknown", user_email: str = "unknown") -> str:
    """æŒ‰é¡¹ç›®æŸ¥è¯¢æ²¹äº• - çœŸå®æ•°æ®åº“"""
    if not project:
        return "âŒ è¯·æä¾›é¡¹ç›®åç§°"
    
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        query = """
            SELECT well_name, qk, jx, sjjs, sjrq, ktxm
            FROM oil_wells 
            WHERE ktxm ILIKE %s AND is_deleted = false
            ORDER BY created_at DESC
            LIMIT %s
        """
        cursor.execute(query, (f"%{project}%", limit))
        results = cursor.fetchall()
        
        wells = [dict(row) for row in results]
        
        # æƒé™è¿‡æ»¤
        wells = filter_wells_by_permission(wells, user_role, user_id, user_email)
        
        if not wells:
            return f"æœªæ‰¾åˆ°é¡¹ç›® '{project}' çš„æ²¹äº•ã€‚"
        
        data = []
        for w in wells:
            data.append({
                "äº•å": w.get('well_name', ''),
                "åŒºå—": w.get('qk', ''),
                "äº•å‹": w.get('jx', ''),
                "è®¾è®¡äº•æ·±(m)": float(w.get('sjjs', 0)) if w.get('sjjs') else 0,
                "è®¾è®¡æ—¥æœŸ": str(w.get('sjrq', '')) if w.get('sjrq') else '',
                "é¡¹ç›®": w.get('ktxm', '')
            })
        
        return f"### ğŸ” é¡¹ç›® '{project}' çš„æ²¹äº•ï¼ˆå…± {len(wells)} å£ï¼‰\n\n{df_to_markdown(pd.DataFrame(data))}"
    
    finally:
        cursor.close()
        conn.close()

@AuditLog.trace("get_statistics")
def get_statistics(group_by: str = "block", user_role: str = "GUEST", user_id: str = "unknown", user_email: str = "unknown") -> str:
    """è·å–ç»Ÿè®¡ä¿¡æ¯ - çœŸå®æ•°æ®åº“ï¼ˆå¸¦å¯è§†åŒ–æç¤ºï¼‰"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        if group_by == "block":
            query = """
                SELECT qk as name, COUNT(*) as count, AVG(sjjs) as avg_depth
                FROM oil_wells 
                WHERE is_deleted = false AND qk IS NOT NULL
                GROUP BY qk
                ORDER BY count DESC
            """
        elif group_by == "project":
            query = """
                SELECT ktxm as name, COUNT(*) as count, AVG(sjjs) as avg_depth
                FROM oil_wells 
                WHERE is_deleted = false AND ktxm IS NOT NULL
                GROUP BY ktxm
                ORDER BY count DESC
            """
        elif group_by == "well_type":
            query = """
                SELECT jx as name, COUNT(*) as count, AVG(sjjs) as avg_depth
                FROM oil_wells 
                WHERE is_deleted = false AND jx IS NOT NULL
                GROUP BY jx
                ORDER BY count DESC
            """
        else:
            return "âŒ ä¸æ”¯æŒçš„åˆ†ç»„æ–¹å¼"
        
        cursor.execute(query)
        results = cursor.fetchall()
        
        if not results:
            return f"æš‚æ— ç»Ÿè®¡æ•°æ®ï¼ˆæŒ‰{group_by}åˆ†ç»„ï¼‰"
        
        data = []
        for row in results:
            data.append({
                "åç§°": row['name'],
                "äº•æ•°": row['count'],
                "å¹³å‡è®¾è®¡äº•æ·±(m)": round(float(row['avg_depth']), 2) if row['avg_depth'] else 0
            })
        
        group_name_map = {
            "block": "åŒºå—",
            "project": "é¡¹ç›®",
            "well_type": "äº•å‹"
        }
        
        # åˆ¤æ–­æœ€ä½³å›¾è¡¨ç±»å‹
        data_count = len(data)
        if group_by == "well_type" and data_count <= 6:
            chart_type = "é¥¼å›¾"
            chart_description = "é€‚åˆå±•ç¤ºå„äº•å‹çš„å æ¯”åˆ†å¸ƒ"
        else:
            chart_type = "æŸ±çŠ¶å›¾"
            chart_description = f"é€‚åˆå¯¹æ¯”ä¸åŒ{group_name_map.get(group_by)}çš„æ²¹äº•æ•°é‡"
        
        # æ·»åŠ å¯è§†åŒ–æç¤º
        return f"""### ğŸ“Š æ²¹äº•ç»Ÿè®¡ï¼ˆæŒ‰{group_name_map.get(group_by, group_by)}åˆ†ç»„ï¼‰

{df_to_markdown(pd.DataFrame(data))}

---
ğŸ’¡ **å¯è§†åŒ–å»ºè®®**ï¼šæ­¤æ•°æ®é€‚åˆç”¨ **{chart_type}** å±•ç¤ºï¼Œå¯ä»¥æ›´ç›´è§‚åœ°{chart_description}ã€‚"""
    
    finally:
        cursor.close()
        conn.close()

@AuditLog.trace("get_drilling_daily")
def get_drilling_daily(well_id: str = "", start_date: str = "", end_date: str = "", limit: int = 100, user_role: str = "GUEST", user_id: str = "unknown", user_email: str = "unknown") -> str:
    """æŸ¥è¯¢é’»äº•å·¥ç¨‹æ—¥æŠ¥æ•°æ® - çœŸå®æ•°æ®åº“"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        query = "SELECT * FROM drilling_daily WHERE is_deleted = false"
        params = []
        
        # äº•å·è¿‡æ»¤
        if well_id:
            # å…ˆæ£€æŸ¥æƒé™
            if not PermissionService.check_well_access(user_role, well_id):
                return f"ğŸš« æƒé™æ‹’ç»ï¼šæ— æƒè®¿é—®äº•å· {well_id} çš„æ—¥æŠ¥æ•°æ®ã€‚"
            query += " AND jh = %s"
            params.append(well_id)
        
        # æ—¥æœŸèŒƒå›´è¿‡æ»¤
        if start_date:
            query += " AND rq >= %s"
            params.append(start_date)
        
        if end_date:
            query += " AND rq <= %s"
            params.append(end_date)
        
        query += " ORDER BY rq DESC LIMIT %s"
        params.append(limit)
        
        cursor.execute(query, params)
        results = cursor.fetchall()
        
        if not results:
            well_filter = f"äº•å· '{well_id}'" if well_id else ""
            date_filter = f"æ—¥æœŸ {start_date} åˆ° {end_date}" if start_date or end_date else ""
            filter_str = " & ".join([f for f in [well_filter, date_filter] if f])
            return f"âŒ æœªæ‰¾åˆ°åŒ¹é…æ¡ä»¶çš„é’»äº•æ—¥æŠ¥æ•°æ®ã€‚ï¼ˆ{filter_str}ï¼‰"
        
        # æ ¼å¼åŒ–è¾“å‡º
        data = []
        for row in results:
            data.append({
                "æ—¥æœŸ": str(row['rq']) if row['rq'] else '',
                "äº•å·": row['jh'] or 'æœªè®°å½•',
                "å½“æ—¥äº•æ·±(m)": float(row['drjs']) if row['drjs'] else '',
                "æ—¥è¿›å°º(m)": float(row['zjrjc']) if row['zjrjc'] else '',
                "é’»å¤´ç±»å‹": row['ztlx'] or '',
                "é’»é€Ÿ(m/h)": float(row['zs']) if row['zs'] else '',
                "æ³µå‹(MPa)": float(row['bya']) if row['bya'] else '',
                "é’»äº•æ¶²å¯†åº¦": float(row['zjymd']) if row['zjymd'] else ''
            })
        
        title = f"ğŸ”¨ é’»äº•å·¥ç¨‹æ—¥æŠ¥"
        if well_id:
            title += f" - äº•å·: {well_id}"
        if start_date or end_date:
            title += f" ({start_date} è‡³ {end_date})"
        
        return f"### {title}\n\n**å…± {len(data)} æ¡è®°å½•**\n\n{df_to_markdown(pd.DataFrame(data))}"
    
    finally:
        cursor.close()
        conn.close()

@AuditLog.trace("get_drilling_pre_daily")
def get_drilling_pre_daily(project: str = "", year: int = None, well_id: str = "", limit: int = 50, user_role: str = "GUEST", user_id: str = "unknown", user_email: str = "unknown") -> str:
    """æŸ¥è¯¢é’»å‰å·¥ç¨‹æ—¥æŠ¥æ•°æ® - çœŸå®æ•°æ®åº“"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        query = "SELECT * FROM drilling_pre_daily WHERE is_deleted = false"
        params = []
        
        # é¡¹ç›®è¿‡æ»¤
        if project:
            query += " AND ktxm ILIKE %s"
            params.append(f"%{project}%")
        
        # å¹´åº¦è¿‡æ»¤
        if year is not None:
            query += " AND ssnd = %s"
            params.append(year)
        
        # äº•å·è¿‡æ»¤
        if well_id:
            # å…ˆæ£€æŸ¥æƒé™
            if not PermissionService.check_well_access(user_role, well_id):
                return f"ğŸš« æƒé™æ‹’ç»ï¼šæ— æƒè®¿é—®äº•å· {well_id} çš„é’»å‰æ—¥æŠ¥æ•°æ®ã€‚"
            query += " AND jh = %s"
            params.append(well_id)
        
        query += " ORDER BY ssnd DESC, ktxm LIMIT %s"
        params.append(limit)
        
        cursor.execute(query, params)
        results = cursor.fetchall()
        
        if not results:
            filter_str = []
            if project:
                filter_str.append(f"é¡¹ç›® '{project}'")
            if year:
                filter_str.append(f"å¹´åº¦ {year}")
            if well_id:
                filter_str.append(f"äº•å· '{well_id}'")
            filter_text = " & ".join(filter_str) if filter_str else "æ¡ä»¶"
            return f"âŒ æœªæ‰¾åˆ°åŒ¹é… {filter_text} çš„é’»å‰æ—¥æŠ¥æ•°æ®ã€‚"
        
        # æ ¼å¼åŒ–è¾“å‡º - æ˜¾ç¤ºå…³é”®æ—¶é—´èŠ‚ç‚¹
        data = []
        for row in results:
            data.append({
                "äº•å·": row['jh'] or 'æœªè®°å½•',
                "é¡¹ç›®": row['ktxm'] or '',
                "å¹´åº¦": row['ssnd'] or '',
                "äº•ä½è®ºè¯": str(row['jwzysj']) if row['jwzysj'] else 'â€”',
                "å·¥ç¨‹è®¾è®¡å®¡æ‰¹": str(row['zjgcsjspsj']) if row['zjgcsjspsj'] else 'â€”',
                "ç¯è¯„ä¸‹è¾¾": str(row['hpxdsj']) if row['hpxdsj'] else 'â€”',
                "æ¬å®¶å®‰è£…": f"{row['bjkssj']} è‡³ {row['bjjssj']}" if row['bjkssj'] and row['bjjssj'] else 'â€”'
            })
        
        title = "ğŸ—ï¸ é’»å‰å·¥ç¨‹æ—¥æŠ¥"
        filters = []
        if project:
            filters.append(f"é¡¹ç›®: {project}")
        if year:
            filters.append(f"å¹´åº¦: {year}")
        if well_id:
            filters.append(f"äº•å·: {well_id}")
        if filters:
            title += f" ({' | '.join(filters)})"
        
        return f"### {title}\n\n**å…± {len(data)} æ¡è®°å½•**\n\n{df_to_markdown(pd.DataFrame(data))}"
    
    finally:
        cursor.close()
        conn.close()

@AuditLog.trace("get_key_well_daily")
def get_key_well_daily(well_id: str = "", start_date: str = "", end_date: str = "", block: str = "", limit: int = 100, user_role: str = "GUEST", user_id: str = "unknown", user_email: str = "unknown") -> str:
    """æŸ¥è¯¢é‡ç‚¹äº•è¯•é‡‡æ—¥æŠ¥æ•°æ® - çœŸå®æ•°æ®åº“"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        query = "SELECT * FROM key_well_daily WHERE is_deleted = false"
        params = []
        
        # äº•å·è¿‡æ»¤
        if well_id:
            # å…ˆæ£€æŸ¥æƒé™
            if not PermissionService.check_well_access(user_role, well_id):
                return f"ğŸš« æƒé™æ‹’ç»ï¼šæ— æƒè®¿é—®äº•å· {well_id} çš„é‡ç‚¹äº•æ—¥æŠ¥æ•°æ®ã€‚"
            query += " AND jh = %s"
            params.append(well_id)
        
        # åŒºå—è¿‡æ»¤
        if block:
            if not PermissionService.check_block_access(user_role, block):
                return f"ğŸš« æƒé™æ‹’ç»ï¼šæ— æƒè®¿é—®åŒºå— {block} çš„é‡ç‚¹äº•æ—¥æŠ¥æ•°æ®ã€‚"
            query += " AND qk ILIKE %s"
            params.append(f"%{block}%")
        
        # æ—¥æœŸèŒƒå›´è¿‡æ»¤
        if start_date:
            query += " AND rq >= %s"
            params.append(start_date)
        
        if end_date:
            query += " AND rq <= %s"
            params.append(end_date)
        
        query += " ORDER BY rq DESC LIMIT %s"
        params.append(limit)
        
        cursor.execute(query, params)
        results = cursor.fetchall()
        
        if not results:
            filter_items = []
            if well_id:
                filter_items.append(f"äº•å· '{well_id}'")
            if block:
                filter_items.append(f"åŒºå— '{block}'")
            if start_date or end_date:
                date_range = f"{start_date or 'â€”'} åˆ° {end_date or 'â€”'}"
                filter_items.append(f"æ—¥æœŸ {date_range}")
            filter_str = " & ".join(filter_items) if filter_items else "æ¡ä»¶"
            return f"âŒ æœªæ‰¾åˆ°åŒ¹é… {filter_str} çš„é‡ç‚¹äº•æ—¥æŠ¥æ•°æ®ã€‚"
        
        # æ ¼å¼åŒ–è¾“å‡º - åŒ…æ‹¬ç”Ÿäº§æ•°æ®å’Œå‹åŠ›å‚æ•°
        data = []
        for row in results:
            pressure_info = []
            if row['yysx'] is not None or row['yyxx'] is not None:
                pressure_info.append(f"æ²¹å‹: {row['yysx']}-{row['yyxx']}MPa")
            if row['tysx'] is not None or row['tyxx'] is not None:
                pressure_info.append(f"å¥—å‹: {row['tysx']}-{row['tyxx']}MPa")
            if row['hysx'] is not None or row['hyxx'] is not None:
                pressure_info.append(f"å›å‹: {row['hysx']}-{row['hyxx']}MPa")
            
            data.append({
                "æ—¥æœŸ": str(row['rq']) if row['rq'] else '',
                "äº•å·": row['jh'] or 'æœªè®°å½•',
                "åŒºå—": row['qk'] or '',
                "å±‚ä½": row['cw'] or '',
                "çŠ¶æ€": row['zt'] or '',
                "æ—¥äº§æ°”é‡(ä¸‡æ–¹)": float(row['rcql']) if row['rcql'] else '',
                "å«æ°´(%)": float(row['hs']) if row['hs'] else '',
                "æ²¹å˜´": row['yz'] or '',
                "å‹åŠ›å‚æ•°": ' | '.join(pressure_info) if pressure_info else 'â€”'
            })
        
        title = "â›½ é‡ç‚¹äº•è¯•é‡‡æ—¥æŠ¥"
        filters = []
        if well_id:
            filters.append(f"äº•å·: {well_id}")
        if block:
            filters.append(f"åŒºå—: {block}")
        if start_date or end_date:
            date_range = f"{start_date or 'â€”'} è‡³ {end_date or 'â€”'}"
            filters.append(f"æ—¥æœŸ: {date_range}")
        if filters:
            title += f" ({' | '.join(filters)})"
        
        return f"### {title}\n\n**å…± {len(data)} æ¡è®°å½•**\n\n{df_to_markdown(pd.DataFrame(data))}"
    
    finally:
        cursor.close()
        conn.close()

# ==========================================
# ä¸»ç¨‹åºå…¥å£
# ==========================================

if __name__ == "__main__":
    import sys
    import io
    
    # Windowsæ§åˆ¶å°UTF-8æ”¯æŒ
    if sys.platform == "win32":
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    
    print("=" * 60)
    print("ğŸš€ æ²¹ç”°é’»äº•æ™ºèƒ½æŸ¥è¯¢ MCP Server (çœŸå®æ•°æ®åº“ç‰ˆæœ¬)")
    print("=" * 60)
    print("\nğŸ“Œ ç³»ç»ŸåŠŸèƒ½ï¼š")
    print("  âœ“ è¿æ¥PostgreSQLçœŸå®æ•°æ®åº“")
    print("  âœ“ æ²¹äº•æœç´¢å’Œè¯¦ç»†ä¿¡æ¯æŸ¥è¯¢")
    print("  âœ“ æŒ‰åŒºå—ã€é¡¹ç›®æŸ¥è¯¢")
    print("  âœ“ ç»Ÿè®¡åˆ†æåŠŸèƒ½")
    print("  âœ“ åŸºäºè§’è‰²çš„æƒé™æ§åˆ¶")
    print("  âœ“ æ™ºèƒ½ç»Ÿè®¡ï¼ˆæ•°æ®é‡>200æ—¶è‡ªåŠ¨åˆ‡æ¢ï¼‰")
    print("\nğŸ“Š æ—¥æŠ¥æŸ¥è¯¢ï¼š")
    print("  âœ“ é’»äº•å·¥ç¨‹æ—¥æŠ¥ï¼ˆdrilling_dailyï¼‰")
    print("  âœ“ é’»å‰å·¥ç¨‹æ—¥æŠ¥ï¼ˆdrilling_pre_dailyï¼‰")
    print("  âœ“ é‡ç‚¹äº•è¯•é‡‡æ—¥æŠ¥ï¼ˆkey_well_dailyï¼‰")
    
    # æ˜¾ç¤ºå½“å‰æƒé™æ¨¡å¼
    if DEV_MODE:
        print("\nğŸ”“ æƒé™æ¨¡å¼ï¼šå¼€å‘æ¨¡å¼ (è·³è¿‡æƒé™æ£€æŸ¥)")
        print("   æç¤ºï¼šç”Ÿäº§ç¯å¢ƒè¯·è®¾ç½®ç¯å¢ƒå˜é‡ DEV_MODE=false")
    else:
        print("\nğŸ”’ æƒé™æ¨¡å¼ï¼šç”Ÿäº§æ¨¡å¼ (åŸºäºè§’è‰²çš„æƒé™æ§åˆ¶)")
    
    print(f"\nğŸ—„ï¸  æ•°æ®åº“é…ç½®ï¼š")
    print(f"  ä¸»æœº: {DB_CONFIG['host']}")
    print(f"  ç«¯å£: {DB_CONFIG['port']}")
    print(f"  æ•°æ®åº“: {DB_CONFIG['database']}")
    print(f"  ç”¨æˆ·: {DB_CONFIG['user']}")
    
    print("\nğŸ“Œ HTTPç«¯ç‚¹ï¼š")
    print("  GET  /         - æœåŠ¡çŠ¶æ€")
    print("  GET  /health   - å¥åº·æ£€æŸ¥")
    print("  GET  /sse      - SSEè¿æ¥")
    print("  POST /sse      - SSEæ¶ˆæ¯å¤„ç†")
    
    print("\nğŸŒ è®¿é—®åœ°å€: http://0.0.0.0:8081")
    print("\nâ³ æœåŠ¡å™¨å¯åŠ¨ä¸­...\n")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8081,
        log_level="info"
    )
